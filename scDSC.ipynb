{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c1932c",
   "metadata": {},
   "source": [
    "1. Data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "4c6e50da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lowet/Documents/000-Files/02-study/01-University/04-MSU/2023 Summer/01-STT_490/04-Project/02-Data\n"
     ]
    }
   ],
   "source": [
    "# Set working directory:\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/lowet/Documents/000-Files/02-study/01-University/04-MSU/2023 Summer/01-STT_490/04-Project/02-Data/')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faed5083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 5105 × 21209\n",
      "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'integrated_snn_res.0.5', 'seurat_clusters'\n",
      "    var: 'features'\n",
      "    obsm: 'X_umap'\n",
      "(5105, 21209)\n",
      "(5105,)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc \n",
    "\n",
    "### Cases dataset\n",
    "cases_data = sc.read_h5ad(\"../02-Data/Cases/cases.h5ad\")\n",
    "print(cases_data)\n",
    "\n",
    "cases_data.write_csvs(dirname = '../02-Data/Cases', skip_data = False, sep = ',')\n",
    "\n",
    "# cases_X and cases_y\n",
    "cases_X = pd.read_csv(\"../02-Data/Cases/X.csv\", header=None)\n",
    "print(cases_X.shape)\n",
    "\n",
    "cases_y = pd.read_csv(\"../02-Data/Cases/obs.csv\")\n",
    "cases_y = cases_y['seurat_clusters']\n",
    "print(cases_y.shape)\n",
    "\n",
    "# Convert csv file to txt file\n",
    "def convert_csv_to_txt(csv_file, txt_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.to_csv(txt_file, sep='\\t', header = False, index=False)\n",
    "\n",
    "cases_X.to_csv(\"../02-Data/Cases/cases_X.csv\")\n",
    "csv_file = '../02-Data/Cases/cases_X.csv'\n",
    "txt_file = '../02-Data/Cases/cases_X0.txt'\n",
    "convert_csv_to_txt(csv_file, txt_file)\n",
    "\n",
    "cases_y.to_csv(\"../02-Data/Cases/cases_y.csv\")\n",
    "csv_file = '../02-Data/Cases/cases_y.csv'\n",
    "txt_file = '../02-Data/Cases/cases_y0.txt'\n",
    "convert_csv_to_txt(csv_file, txt_file)\n",
    "\n",
    "# Delete the first column of txt files\n",
    "f = open(\"../02-Data/Cases/cases_X0.txt\", \"r\")\n",
    "g = open(\"../02-Data/Cases/cases_X.txt\", \"w\")\n",
    "\n",
    "for line in f:\n",
    "    if line.strip():\n",
    "        g.write(\"\\t\".join(line.split()[1:]) + \"\\n\")\n",
    "\n",
    "f.close()\n",
    "g.close()\n",
    "\n",
    "f = open(\"../02-Data/Cases/cases_y0.txt\", \"r\")\n",
    "g = open(\"../02-Data/Cases/cases_y.txt\", \"w\")\n",
    "\n",
    "for line in f:\n",
    "    if line.strip():\n",
    "        g.write(\"\\t\".join(line.split()[1:]) + \"\\n\")\n",
    "\n",
    "f.close()\n",
    "g.close()\n",
    "\n",
    "# Convert txt file to csv file for checking:\n",
    "read_file = pd.read_csv (r'../02-Data/Cases/cases_X.txt')\n",
    "read_file.to_csv (r'../02-Data/Cases/cases_X1.csv', index=None)\n",
    "\n",
    "read_file = pd.read_csv (r'../02-Data/Cases/cases_y.txt')\n",
    "read_file.to_csv (r'../02-Data/Cases/cases_y1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c5031a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lowet/mambaforge/envs/AI/lib/python3.10/site-packages/anndata/compat/__init__.py:229: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 1548 × 2000\n",
      "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'integrated_snn_res.0.5', 'seurat_clusters'\n",
      "    var: 'features'\n",
      "    uns: 'neighbors'\n",
      "    obsm: 'X_pca', 'X_umap'\n",
      "    varm: 'PCs'\n",
      "    obsp: 'distances'\n",
      "(1548, 2000)\n",
      "(1548,)\n"
     ]
    }
   ],
   "source": [
    "### Controls dataset\n",
    "controls_data = sc.read_h5ad(\"../02-Data/Controls/controls.h5ad\")\n",
    "print(controls_data)\n",
    "\n",
    "controls_data.write_csvs(dirname = '../02-Data/Controls', skip_data = False, sep = ',')\n",
    "\n",
    "# controls_X and controls_y\n",
    "controls_X = pd.read_csv(\"../02-Data/Controls/X.csv\", header=None)\n",
    "print(controls_X.shape)\n",
    "\n",
    "controls_y = pd.read_csv(\"../02-Data/Controls/obs.csv\")\n",
    "controls_y = controls_y['seurat_clusters']\n",
    "print(controls_y.shape)\n",
    "\n",
    "# Convert csv file to txt file\n",
    "def convert_csv_to_txt(csv_file, txt_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.to_csv(txt_file, sep='\\t', header = False, index=False)\n",
    "\n",
    "controls_X.to_csv(\"../02-Data/Controls/controls_X.csv\")\n",
    "csv_file = '../02-Data/Controls/controls_X.csv'\n",
    "txt_file = '../02-Data/Controls/controls_X0.txt'\n",
    "convert_csv_to_txt(csv_file, txt_file)\n",
    "\n",
    "controls_y.to_csv(\"../02-Data/Controls/controls_y.csv\")\n",
    "csv_file = '../02-Data/Controls/controls_y.csv'\n",
    "txt_file = '../02-Data/Controls/controls_y0.txt'\n",
    "convert_csv_to_txt(csv_file, txt_file)\n",
    "\n",
    "# Delete the first column of txt files\n",
    "f = open(\"../02-Data/Controls/controls_X0.txt\", \"r\")\n",
    "g = open(\"../02-Data/Controls/controls_X.txt\", \"w\")\n",
    "\n",
    "for line in f:\n",
    "    if line.strip():\n",
    "        g.write(\"\\t\".join(line.split()[1:]) + \"\\n\")\n",
    "\n",
    "f.close()\n",
    "g.close()\n",
    "\n",
    "f = open(\"../02-Data/Controls/controls_y0.txt\", \"r\")\n",
    "g = open(\"../02-Data/Controls/controls_y.txt\", \"w\")\n",
    "\n",
    "for line in f:\n",
    "    if line.strip():\n",
    "        g.write(\"\\t\".join(line.split()[1:]) + \"\\n\")\n",
    "\n",
    "f.close()\n",
    "g.close()\n",
    "\n",
    "# Convert txt file to csv file for checking:\n",
    "read_file = pd.read_csv (r'../02-Data/Controls/controls_X.txt')\n",
    "read_file.to_csv (r'../02-Data/Controls/controls_X1.csv', index=None)\n",
    "\n",
    "read_file = pd.read_csv (r'../02-Data/Controls/controls_y.txt')\n",
    "read_file.to_csv (r'../02-Data/Controls/controls_y1.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb88300",
   "metadata": {},
   "source": [
    "2. Generate graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "58529245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances as pair\n",
    "from sklearn.preprocessing import normalize\n",
    "topk = 10\n",
    "\n",
    "\n",
    "def construct_graph(features, label, method):\n",
    "#     fname = '../02-Data/Cases/cases_graph.txt'\n",
    "    fname = '../02-Data/Controls/controls_graph.txt'\n",
    "    num = len(label)\n",
    "\n",
    "    dist = None\n",
    "    # Several methods of calculating the similarity relationship between samples i and j (similarity matrix Sij)\n",
    "    if method == 'heat':\n",
    "        dist = -0.5 * pair(features, metric='manhattan') ** 2\n",
    "        dist = np.exp(dist)\n",
    "\n",
    "    elif method == 'cos':\n",
    "        features[features > 0] = 1\n",
    "        dist = np.dot(features, features.T)\n",
    "\n",
    "    elif method == 'ncos':\n",
    "        features[features > 0] = 1\n",
    "        features = normalize(features, axis=1, norm='l1')\n",
    "        dist = np.dot(features, features.T)\n",
    "\n",
    "    # elif method == 'cos':\n",
    "    #     dist = np.dot(features, features.T) / (np.linalg.norm(features) * np.linalg.norm(features.T))\n",
    "\n",
    "    elif method == 'p':\n",
    "        y = features.T - np.mean(features.T)\n",
    "        features = features - np.mean(features)\n",
    "        dist = np.dot(features, features.T) / (np.linalg.norm(features) * np.linalg.norm(y))\n",
    "\n",
    "    inds = []\n",
    "    for i in range(dist.shape[0]):\n",
    "        ind = np.argpartition(dist[i, :], -(topk + 1))[-(topk + 1):]\n",
    "        inds.append(ind)\n",
    "\n",
    "    f = open(fname, 'w')\n",
    "    counter = 0\n",
    "    A = np.zeros_like(dist)\n",
    "    for i, v in enumerate(inds):\n",
    "        mutual_knn = False\n",
    "        for vv in v:\n",
    "            if vv == i:\n",
    "                pass\n",
    "            else:\n",
    "                if label[vv] != label[i]:\n",
    "                    counter += 1\n",
    "                f.write('{} {}\\n'.format(i, vv))\n",
    "    f.close()\n",
    "    print('error rate: {}'.format(counter / (num * topk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "74f7a9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate: 0.43800195886385895\n"
     ]
    }
   ],
   "source": [
    "### For cases:\n",
    "# File = [Pre-training file,]\n",
    "File = ['../02-Data/Cases/cases_X.txt', '../02-Data/Cases/cases_y.txt']\n",
    "# Para = [batch_size, lr, epoch, n_cluster, n_init]\n",
    "Para = [1024, 1e-3, 200, 5, 20]\n",
    "# method = ['heat', 'cos', 'ncos' ,'p']\n",
    "method = ['heat', 'cos', 'ncos', 'p']\n",
    "\n",
    "number = np.loadtxt(File[0], dtype=float)\n",
    "label = np.loadtxt(File[1], dtype=int)\n",
    "construct_graph(number, label, method[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2e7e9dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51049, 1)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert txt file to csv file for checking:\n",
    "read_file = pd.read_csv (r'../02-Data/Cases/cases_graph.txt')\n",
    "read_file.to_csv (r'../02-Data/Cases/cases_graph.csv', index=None)\n",
    "\n",
    "df = pd.read_csv('../02-Data/Cases/cases_graph.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e776d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate: 0.13837209302325582\n"
     ]
    }
   ],
   "source": [
    "### For controlsS:\n",
    "# File = [Pre-training file,]\n",
    "File = ['../02-Data/Controls/controls_X.txt', '../02-Data/Controls/controls_y.txt']\n",
    "# Para = [batch_size, lr, epoch, n_cluster, n_init]\n",
    "Para = [1024, 1e-3, 200, 5, 20]\n",
    "# method = ['heat', 'cos', 'ncos' ,'p']\n",
    "method = ['heat', 'cos', 'ncos', 'p']\n",
    "\n",
    "number = np.loadtxt(File[0], dtype=float)\n",
    "label = np.loadtxt(File[1], dtype=int)\n",
    "construct_graph(number, label, method[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8d9f2461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15482, 1)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert txt file to csv file for checking:\n",
    "read_file = pd.read_csv (r'../02-Data/Controls/controls_graph.txt')\n",
    "read_file.to_csv (r'../02-Data/Controls/controls_graph.csv', index=None)\n",
    "\n",
    "df = pd.read_csv('../02-Data/Controls/controls_graph.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816f7f9",
   "metadata": {},
   "source": [
    "3. Pre-training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a0a30208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "import numpy as np\n",
    "from munkres import Munkres\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    y_true = y_true - np.min(y_true)\n",
    "    l1 = list(set(y_true))\n",
    "    numclass1 = len(l1)\n",
    "    l2 = list(set(y_pred))\n",
    "    numclass2 = len(l2)\n",
    "\n",
    "    ind = 0\n",
    "    if numclass1 != numclass2:\n",
    "        for i in l1:\n",
    "            if i in l2:\n",
    "                pass\n",
    "            else:\n",
    "                y_pred[ind] = i\n",
    "                ind += 1\n",
    "\n",
    "    l2 = list(set(y_pred))\n",
    "    numclass2 = len(l2)\n",
    "\n",
    "    if numclass1 != numclass2:\n",
    "        print('error')\n",
    "        return\n",
    "\n",
    "    cost = np.zeros((numclass1, numclass2), dtype=int)\n",
    "    for i, c1 in enumerate(l1):\n",
    "        mps = [i1 for i1, e1 in enumerate(y_true) if e1 == c1]\n",
    "        for j, c2 in enumerate(l2):\n",
    "            mps_d = [i1 for i1 in mps if y_pred[i1] == c2]\n",
    "            cost[i][j] = len(mps_d)\n",
    "\n",
    "    m = Munkres()\n",
    "    cost = cost.__neg__().tolist()\n",
    "    indexes = m.compute(cost)\n",
    "\n",
    "    new_predict = np.zeros(len(y_pred))\n",
    "    for i, c in enumerate(l1):\n",
    "        c2 = l2[indexes[i][1]]\n",
    "        ai = [ind for ind, elm in enumerate(y_pred) if elm == c2]\n",
    "        new_predict[ai] = c\n",
    "\n",
    "    acc = metrics.accuracy_score(y_true, new_predict)\n",
    "    # y_true：Like 1d array or label indicator array/sparse matrix (correct) label\n",
    "    # y_pred：Like a one-dimensional array or label indicator array/sparse matrix predicted labels, returned by the classifier\n",
    "    f1_macro = metrics.f1_score(y_true, new_predict, average='macro')\n",
    "    return acc, f1_macro\n",
    "\n",
    "\n",
    "def eva(y_true, y_pred, epoch=0):\n",
    "    acc, f1 = cluster_acc(y_true, y_pred)\n",
    "    nmi = nmi_score(y_true, y_pred)\n",
    "    ari = ari_score(y_true, y_pred)\n",
    "    print(epoch, ':acc {:.4f}'.format(acc), ', nmi {:.4f}'.format(nmi), ', ari {:.4f}'.format(ari),\n",
    "          ', f1 {:.4f}'.format(f1))\n",
    "    return acc, f1, nmi, ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e223dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n",
    "                 n_input, n_z):\n",
    "        super(AE, self).__init__()\n",
    "        # encoder\n",
    "        self.enc_1 = Linear(n_input, n_enc_1)\n",
    "        self.BN1 = nn.BatchNorm1d(n_enc_1)\n",
    "        self.enc_2 = Linear(n_enc_1, n_enc_2)\n",
    "        self.BN2 = nn.BatchNorm1d(n_enc_2)\n",
    "        self.enc_3 = Linear(n_enc_2, n_enc_3)\n",
    "        self.BN3 = nn.BatchNorm1d(n_enc_3)\n",
    "        self.z_layer = Linear(n_enc_3, n_z)\n",
    "\n",
    "        # decoder\n",
    "        self.dec_1 = Linear(n_z, n_dec_1)\n",
    "        self.BN4 = nn.BatchNorm1d(n_dec_1)\n",
    "        self.dec_2 = Linear(n_dec_1, n_dec_2)\n",
    "        self.BN5 = nn.BatchNorm1d(n_dec_2)\n",
    "        self.dec_3 = Linear(n_dec_2, n_dec_3)\n",
    "        self.BN6 = nn.BatchNorm1d(n_dec_3)\n",
    "        self.x_bar_layer = Linear(n_dec_3, n_input)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_h1 = F.relu(self.BN1(self.enc_1(x)))\n",
    "        enc_h2 = F.relu(self.BN2(self.enc_2(enc_h1)))\n",
    "        enc_h3 = F.relu(self.BN3(self.enc_3(enc_h2)))\n",
    "\n",
    "        z = self.z_layer(enc_h3)\n",
    "\n",
    "        dec_h1 = F.relu(self.BN4(self.dec_1(z)))\n",
    "        dec_h2 = F.relu(self.BN5(self.dec_2(dec_h1)))\n",
    "        dec_h3 = F.relu(self.BN6(self.dec_3(dec_h2)))\n",
    "        x_bar = self.x_bar_layer(dec_h3)\n",
    "\n",
    "        return x_bar,  z\n",
    "\n",
    "\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.x[idx])).float(), \\\n",
    "               torch.from_numpy(np.array(idx))\n",
    "\n",
    "\n",
    "def pretrain_ae(model, dataset, y):\n",
    "    train_loader = DataLoader(dataset, batch_size=Para[0], shuffle=True)\n",
    "    print(model)\n",
    "    \n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    nmi_list = []\n",
    "    ari_list = []\n",
    "    \n",
    "    # Adam\n",
    "    optimizer = Adam(model.parameters(), lr=Para[1])\n",
    "    for epoch in range(Para[2]):\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            x = x\n",
    "            x_bar, _ = model(x)\n",
    "\n",
    "            x_bar = x_bar.cpu()\n",
    "            x = x.cpu()\n",
    "            loss = F.mse_loss(x_bar, x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.Tensor(dataset.x).float()\n",
    "            x_bar, z = model(x)\n",
    "            loss = F.mse_loss(x_bar, x)\n",
    "            loss_list.append(loss.item())\n",
    "            print('{} loss: {}'.format(epoch, loss))\n",
    "            kmeans = KMeans(n_clusters=Cluster_para[0], n_init=Cluster_para[1]).fit(z.data.cpu().numpy())\n",
    "            acc, f1, nmi, ari = eva(y, kmeans.labels_, epoch)\n",
    "            acc_list.append(acc)\n",
    "            f1_list.append(f1)\n",
    "            nmi_list.append(nmi)\n",
    "            ari_list.append(ari)\n",
    "        # Generate a pre-trained model\n",
    "        torch.save(model.state_dict(), File[0])\n",
    "        \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(range(Para[2]), loss_list)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Epoch vs Loss')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(range(Para[2]), acc_list)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Epoch vs Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(range(Para[2]), f1_list)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Epoch vs F1 Score')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(range(Para[2]), nmi_list, label='NMI')\n",
    "    plt.plot(range(Para[2]), ari_list, label='ARI')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Epoch vs NMI/ARI')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b42dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE(\n",
      "  (enc_1): Linear(in_features=21209, out_features=500, bias=True)\n",
      "  (BN1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (enc_2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (BN2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (enc_3): Linear(in_features=500, out_features=2000, bias=True)\n",
      "  (BN3): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (z_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  (dec_1): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (BN4): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dec_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (BN5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dec_3): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (BN6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (x_bar_layer): Linear(in_features=500, out_features=21209, bias=True)\n",
      ")\n",
      "0 loss: 0.1744907945394516\n",
      "0 :acc 0.3882 , nmi 0.2168 , ari 0.1306 , f1 0.1530\n",
      "1 loss: 0.15103648602962494\n",
      "1 :acc 0.3933 , nmi 0.2035 , ari 0.1286 , f1 0.1542\n",
      "2 loss: 0.13845191895961761\n",
      "2 :acc 0.3976 , nmi 0.2145 , ari 0.1404 , f1 0.1546\n",
      "3 loss: 0.13227057456970215\n",
      "3 :acc 0.3973 , nmi 0.2296 , ari 0.1518 , f1 0.1457\n",
      "4 loss: 0.12898001074790955\n",
      "4 :acc 0.3933 , nmi 0.2301 , ari 0.1492 , f1 0.1447\n",
      "5 loss: 0.12723851203918457\n",
      "5 :acc 0.3904 , nmi 0.2271 , ari 0.1440 , f1 0.1443\n",
      "6 loss: 0.125918909907341\n",
      "6 :acc 0.3898 , nmi 0.2273 , ari 0.1430 , f1 0.1413\n",
      "7 loss: 0.1248977780342102\n",
      "7 :acc 0.3949 , nmi 0.2301 , ari 0.1454 , f1 0.1472\n",
      "8 loss: 0.12394502013921738\n",
      "8 :acc 0.3982 , nmi 0.2370 , ari 0.1471 , f1 0.1480\n",
      "9 loss: 0.12306257337331772\n",
      "9 :acc 0.4029 , nmi 0.2424 , ari 0.1500 , f1 0.1492\n",
      "10 loss: 0.12218521535396576\n",
      "10 :acc 0.4106 , nmi 0.2495 , ari 0.1583 , f1 0.1488\n",
      "11 loss: 0.12125367671251297\n",
      "11 :acc 0.4100 , nmi 0.2487 , ari 0.1578 , f1 0.1492\n",
      "12 loss: 0.12043028324842453\n",
      "12 :acc 0.4086 , nmi 0.2454 , ari 0.1563 , f1 0.1471\n",
      "13 loss: 0.11971836537122726\n",
      "13 :acc 0.4225 , nmi 0.2522 , ari 0.1539 , f1 0.1706\n",
      "14 loss: 0.11922311037778854\n",
      "14 :acc 0.4223 , nmi 0.2516 , ari 0.1528 , f1 0.1686\n",
      "15 loss: 0.11879756301641464\n",
      "15 :acc 0.4208 , nmi 0.2516 , ari 0.1522 , f1 0.1661\n",
      "16 loss: 0.11847499758005142\n",
      "16 :acc 0.4168 , nmi 0.2521 , ari 0.1486 , f1 0.1653\n",
      "17 loss: 0.11818144470453262\n",
      "17 :acc 0.4456 , nmi 0.2813 , ari 0.1707 , f1 0.1736\n",
      "18 loss: 0.1180085763335228\n",
      "18 :acc 0.4466 , nmi 0.2829 , ari 0.1721 , f1 0.1741\n",
      "19 loss: 0.11786721646785736\n",
      "19 :acc 0.4458 , nmi 0.2790 , ari 0.1716 , f1 0.1736\n",
      "20 loss: 0.11769676953554153\n",
      "20 :acc 0.4456 , nmi 0.2807 , ari 0.1719 , f1 0.1730\n",
      "21 loss: 0.11745818704366684\n",
      "21 :acc 0.4466 , nmi 0.2826 , ari 0.1717 , f1 0.1740\n",
      "22 loss: 0.11727607995271683\n",
      "22 :acc 0.4472 , nmi 0.2835 , ari 0.1737 , f1 0.1741\n",
      "23 loss: 0.11708739399909973\n",
      "23 :acc 0.4474 , nmi 0.2851 , ari 0.1747 , f1 0.1741\n",
      "24 loss: 0.11690526455640793\n",
      "24 :acc 0.4474 , nmi 0.2862 , ari 0.1751 , f1 0.1741\n",
      "25 loss: 0.11673683673143387\n",
      "25 :acc 0.4474 , nmi 0.2862 , ari 0.1751 , f1 0.1741\n",
      "26 loss: 0.1165953204035759\n",
      "26 :acc 0.4476 , nmi 0.2869 , ari 0.1754 , f1 0.1742\n",
      "27 loss: 0.11641370505094528\n",
      "27 :acc 0.3931 , nmi 0.2412 , ari 0.1388 , f1 0.1388\n",
      "28 loss: 0.11630645394325256\n",
      "28 :acc 0.3931 , nmi 0.2410 , ari 0.1382 , f1 0.1389\n",
      "29 loss: 0.11615689098834991\n",
      "29 :acc 0.3937 , nmi 0.2414 , ari 0.1374 , f1 0.1394\n",
      "30 loss: 0.115953728556633\n",
      "30 :acc 0.3931 , nmi 0.2410 , ari 0.1382 , f1 0.1389\n",
      "31 loss: 0.11583901196718216\n",
      "31 :acc 0.3931 , nmi 0.2410 , ari 0.1379 , f1 0.1390\n",
      "32 loss: 0.11569821834564209\n",
      "32 :acc 0.3941 , nmi 0.2412 , ari 0.1376 , f1 0.1402\n",
      "33 loss: 0.11555014550685883\n",
      "33 :acc 0.3926 , nmi 0.2408 , ari 0.1412 , f1 0.1387\n",
      "34 loss: 0.11544963717460632\n",
      "34 :acc 0.3931 , nmi 0.2402 , ari 0.1378 , f1 0.1396\n",
      "35 loss: 0.11527691781520844\n",
      "35 :acc 0.3928 , nmi 0.2410 , ari 0.1370 , f1 0.1392\n",
      "36 loss: 0.11517881602048874\n",
      "36 :acc 0.3926 , nmi 0.2418 , ari 0.1388 , f1 0.1386\n",
      "37 loss: 0.11515747755765915\n",
      "37 :acc 0.3926 , nmi 0.2407 , ari 0.1371 , f1 0.1389\n",
      "38 loss: 0.11495574563741684\n",
      "38 :acc 0.3928 , nmi 0.2406 , ari 0.1369 , f1 0.1397\n",
      "39 loss: 0.11506592482328415\n",
      "39 :acc 0.4468 , nmi 0.2865 , ari 0.1739 , f1 0.1737\n",
      "40 loss: 0.11481533199548721\n",
      "40 :acc 0.3926 , nmi 0.2408 , ari 0.1373 , f1 0.1389\n",
      "41 loss: 0.1147046759724617\n",
      "41 :acc 0.4460 , nmi 0.2843 , ari 0.1730 , f1 0.1733\n",
      "42 loss: 0.1146218329668045\n",
      "42 :acc 0.4460 , nmi 0.2843 , ari 0.1728 , f1 0.1732\n",
      "43 loss: 0.11457063257694244\n",
      "43 :acc 0.4460 , nmi 0.2832 , ari 0.1733 , f1 0.1739\n",
      "44 loss: 0.11451952904462814\n",
      "44 :acc 0.4460 , nmi 0.2841 , ari 0.1728 , f1 0.1737\n",
      "45 loss: 0.11483195424079895\n",
      "45 :acc 0.4449 , nmi 0.2834 , ari 0.1720 , f1 0.1726\n",
      "46 loss: 0.11455036699771881\n",
      "46 :acc 0.3924 , nmi 0.2406 , ari 0.1368 , f1 0.1388\n",
      "47 loss: 0.11440478265285492\n",
      "47 :acc 0.4449 , nmi 0.2830 , ari 0.1714 , f1 0.1724\n",
      "48 loss: 0.11433760076761246\n",
      "48 :acc 0.4447 , nmi 0.2818 , ari 0.1721 , f1 0.1723\n",
      "49 loss: 0.11424928158521652\n",
      "49 :acc 0.4449 , nmi 0.2822 , ari 0.1719 , f1 0.1725\n",
      "50 loss: 0.11421285569667816\n",
      "50 :acc 0.4447 , nmi 0.2816 , ari 0.1717 , f1 0.1724\n",
      "51 loss: 0.11414304375648499\n",
      "51 :acc 0.4449 , nmi 0.2815 , ari 0.1722 , f1 0.1725\n",
      "52 loss: 0.1141391471028328\n",
      "52 :acc 0.4447 , nmi 0.2814 , ari 0.1722 , f1 0.1725\n",
      "53 loss: 0.1142200455069542\n",
      "53 :acc 0.4447 , nmi 0.2821 , ari 0.1721 , f1 0.1727\n",
      "54 loss: 0.11400775611400604\n",
      "54 :acc 0.3931 , nmi 0.2430 , ari 0.1372 , f1 0.1392\n",
      "55 loss: 0.11393439024686813\n",
      "55 :acc 0.4445 , nmi 0.2812 , ari 0.1721 , f1 0.1720\n",
      "56 loss: 0.11397150158882141\n",
      "56 :acc 0.4449 , nmi 0.2808 , ari 0.1727 , f1 0.1727\n",
      "57 loss: 0.11390066146850586\n",
      "57 :acc 0.4445 , nmi 0.2829 , ari 0.1707 , f1 0.1728\n",
      "58 loss: 0.11385351419448853\n",
      "58 :acc 0.4439 , nmi 0.2801 , ari 0.1718 , f1 0.1715\n",
      "59 loss: 0.11374673247337341\n",
      "59 :acc 0.4445 , nmi 0.2811 , ari 0.1714 , f1 0.1720\n",
      "60 loss: 0.11368750035762787\n",
      "60 :acc 0.4449 , nmi 0.2802 , ari 0.1721 , f1 0.1724\n",
      "61 loss: 0.11364207416772842\n",
      "61 :acc 0.4447 , nmi 0.2818 , ari 0.1712 , f1 0.1718\n",
      "62 loss: 0.11352387815713882\n",
      "62 :acc 0.4449 , nmi 0.2798 , ari 0.1721 , f1 0.1719\n",
      "63 loss: 0.11348690837621689\n",
      "63 :acc 0.4451 , nmi 0.2809 , ari 0.1720 , f1 0.1726\n",
      "64 loss: 0.1134476512670517\n",
      "64 :acc 0.4451 , nmi 0.2804 , ari 0.1722 , f1 0.1726\n",
      "65 loss: 0.11334330588579178\n",
      "65 :acc 0.4449 , nmi 0.2813 , ari 0.1725 , f1 0.1725\n",
      "66 loss: 0.11331933736801147\n",
      "66 :acc 0.4449 , nmi 0.2811 , ari 0.1729 , f1 0.1723\n",
      "67 loss: 0.11319976300001144\n",
      "67 :acc 0.4445 , nmi 0.2808 , ari 0.1724 , f1 0.1721\n",
      "68 loss: 0.11315185576677322\n",
      "68 :acc 0.4449 , nmi 0.2808 , ari 0.1734 , f1 0.1723\n",
      "69 loss: 0.11311831325292587\n",
      "69 :acc 0.4449 , nmi 0.2810 , ari 0.1716 , f1 0.1723\n",
      "70 loss: 0.11303513497114182\n",
      "70 :acc 0.4449 , nmi 0.2805 , ari 0.1727 , f1 0.1722\n",
      "71 loss: 0.11293427646160126\n",
      "71 :acc 0.4451 , nmi 0.2806 , ari 0.1728 , f1 0.1723\n",
      "72 loss: 0.1128849983215332\n",
      "72 :acc 0.4451 , nmi 0.2803 , ari 0.1728 , f1 0.1724\n",
      "73 loss: 0.11283490061759949\n",
      "73 :acc 0.4445 , nmi 0.2816 , ari 0.1721 , f1 0.1722\n",
      "74 loss: 0.11295945942401886\n",
      "74 :acc 0.4447 , nmi 0.2804 , ari 0.1709 , f1 0.1735\n",
      "75 loss: 0.11282838881015778\n",
      "75 :acc 0.4451 , nmi 0.2801 , ari 0.1719 , f1 0.1725\n",
      "76 loss: 0.11279331147670746\n",
      "76 :acc 0.4441 , nmi 0.2820 , ari 0.1712 , f1 0.1722\n",
      "77 loss: 0.1126529723405838\n",
      "77 :acc 0.4447 , nmi 0.2800 , ari 0.1718 , f1 0.1723\n",
      "78 loss: 0.11257312446832657\n",
      "78 :acc 0.4454 , nmi 0.2807 , ari 0.1721 , f1 0.1731\n",
      "79 loss: 0.11253950744867325\n",
      "79 :acc 0.4451 , nmi 0.2800 , ari 0.1717 , f1 0.1724\n",
      "80 loss: 0.11246169358491898\n",
      "80 :acc 0.4449 , nmi 0.2801 , ari 0.1717 , f1 0.1723\n",
      "81 loss: 0.11241989582777023\n",
      "81 :acc 0.4452 , nmi 0.2803 , ari 0.1719 , f1 0.1726\n",
      "82 loss: 0.11236178874969482\n",
      "82 :acc 0.4454 , nmi 0.2804 , ari 0.1718 , f1 0.1732\n",
      "83 loss: 0.11235323548316956\n",
      "83 :acc 0.4451 , nmi 0.2803 , ari 0.1713 , f1 0.1725\n",
      "84 loss: 0.11248482018709183\n",
      "84 :acc 0.4454 , nmi 0.2810 , ari 0.1712 , f1 0.1738\n",
      "85 loss: 0.11222674697637558\n",
      "85 :acc 0.4456 , nmi 0.2810 , ari 0.1713 , f1 0.1740\n",
      "86 loss: 0.1122034341096878\n",
      "86 :acc 0.4452 , nmi 0.2802 , ari 0.1711 , f1 0.1738\n",
      "87 loss: 0.11213928461074829\n",
      "87 :acc 0.4456 , nmi 0.2811 , ari 0.1713 , f1 0.1740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 loss: 0.11210519820451736\n",
      "88 :acc 0.4456 , nmi 0.2813 , ari 0.1714 , f1 0.1740\n",
      "89 loss: 0.11206584423780441\n",
      "89 :acc 0.4452 , nmi 0.2812 , ari 0.1713 , f1 0.1727\n",
      "90 loss: 0.11209238320589066\n",
      "90 :acc 0.4452 , nmi 0.2825 , ari 0.1715 , f1 0.1728\n",
      "91 loss: 0.11200768500566483\n",
      "91 :acc 0.4454 , nmi 0.2812 , ari 0.1714 , f1 0.1734\n",
      "92 loss: 0.11194116622209549\n",
      "92 :acc 0.4458 , nmi 0.2815 , ari 0.1716 , f1 0.1740\n",
      "93 loss: 0.1120600700378418\n",
      "93 :acc 0.4452 , nmi 0.2818 , ari 0.1714 , f1 0.1728\n",
      "94 loss: 0.11190753430128098\n",
      "94 :acc 0.4452 , nmi 0.2818 , ari 0.1714 , f1 0.1728\n",
      "95 loss: 0.11184767633676529\n",
      "95 :acc 0.4451 , nmi 0.2824 , ari 0.1712 , f1 0.1728\n",
      "96 loss: 0.11191868782043457\n",
      "96 :acc 0.4451 , nmi 0.2812 , ari 0.1711 , f1 0.1727\n",
      "97 loss: 0.11188826709985733\n",
      "97 :acc 0.4451 , nmi 0.2837 , ari 0.1715 , f1 0.1725\n",
      "98 loss: 0.11173588037490845\n",
      "98 :acc 0.4449 , nmi 0.2817 , ari 0.1709 , f1 0.1724\n",
      "99 loss: 0.11172914505004883\n",
      "99 :acc 0.4449 , nmi 0.2816 , ari 0.1714 , f1 0.1722\n",
      "100 loss: 0.11171229928731918\n",
      "100 :acc 0.4447 , nmi 0.2811 , ari 0.1709 , f1 0.1723\n",
      "101 loss: 0.11163709312677383\n",
      "101 :acc 0.4452 , nmi 0.2832 , ari 0.1713 , f1 0.1726\n",
      "102 loss: 0.11162086576223373\n",
      "102 :acc 0.4451 , nmi 0.2822 , ari 0.1713 , f1 0.1725\n",
      "103 loss: 0.11157546192407608\n",
      "103 :acc 0.4458 , nmi 0.2825 , ari 0.1712 , f1 0.1752\n",
      "104 loss: 0.11154218018054962\n",
      "104 :acc 0.4451 , nmi 0.2829 , ari 0.1712 , f1 0.1726\n",
      "105 loss: 0.11151554435491562\n",
      "105 :acc 0.4449 , nmi 0.2819 , ari 0.1713 , f1 0.1724\n",
      "106 loss: 0.11149849742650986\n",
      "106 :acc 0.4447 , nmi 0.2817 , ari 0.1712 , f1 0.1723\n",
      "107 loss: 0.11139804869890213\n",
      "107 :acc 0.4456 , nmi 0.2824 , ari 0.1712 , f1 0.1746\n",
      "108 loss: 0.11133716255426407\n",
      "108 :acc 0.4462 , nmi 0.2811 , ari 0.1712 , f1 0.1770\n",
      "109 loss: 0.11133399605751038\n",
      "109 :acc 0.4454 , nmi 0.2798 , ari 0.1708 , f1 0.1760\n",
      "110 loss: 0.1112731322646141\n",
      "110 :acc 0.4451 , nmi 0.2809 , ari 0.1708 , f1 0.1747\n",
      "111 loss: 0.11119428277015686\n",
      "111 :acc 0.4449 , nmi 0.2806 , ari 0.1706 , f1 0.1745\n",
      "112 loss: 0.11122444272041321\n",
      "112 :acc 0.4462 , nmi 0.2816 , ari 0.1717 , f1 0.1768\n",
      "113 loss: 0.11114748567342758\n",
      "113 :acc 0.4458 , nmi 0.2807 , ari 0.1711 , f1 0.1777\n",
      "114 loss: 0.11109603196382523\n",
      "114 :acc 0.4441 , nmi 0.2820 , ari 0.1707 , f1 0.1719\n",
      "115 loss: 0.11107034236192703\n",
      "115 :acc 0.4454 , nmi 0.2818 , ari 0.1710 , f1 0.1752\n",
      "116 loss: 0.11099021136760712\n",
      "116 :acc 0.4464 , nmi 0.2812 , ari 0.1710 , f1 0.1786\n",
      "117 loss: 0.11095374822616577\n",
      "117 :acc 0.4464 , nmi 0.2815 , ari 0.1711 , f1 0.1783\n",
      "118 loss: 0.11096863448619843\n",
      "118 :acc 0.4441 , nmi 0.2804 , ari 0.1705 , f1 0.1717\n",
      "119 loss: 0.11094013601541519\n",
      "119 :acc 0.4452 , nmi 0.2799 , ari 0.1706 , f1 0.1756\n",
      "120 loss: 0.11093208938837051\n",
      "120 :acc 0.4464 , nmi 0.2801 , ari 0.1709 , f1 0.1786\n",
      "121 loss: 0.11077311635017395\n",
      "121 :acc 0.4460 , nmi 0.2805 , ari 0.1710 , f1 0.1774\n",
      "122 loss: 0.11072508245706558\n",
      "122 :acc 0.4474 , nmi 0.2817 , ari 0.1727 , f1 0.1795\n",
      "123 loss: 0.11067181825637817\n",
      "123 :acc 0.4464 , nmi 0.2805 , ari 0.1711 , f1 0.1785\n",
      "124 loss: 0.11062753200531006\n",
      "124 :acc 0.4466 , nmi 0.2810 , ari 0.1712 , f1 0.1787\n",
      "125 loss: 0.11058972775936127\n",
      "125 :acc 0.4464 , nmi 0.2810 , ari 0.1721 , f1 0.1773\n",
      "126 loss: 0.11052063852548599\n",
      "126 :acc 0.4460 , nmi 0.2809 , ari 0.1711 , f1 0.1777\n",
      "127 loss: 0.11046542227268219\n",
      "127 :acc 0.4466 , nmi 0.2810 , ari 0.1716 , f1 0.1790\n",
      "128 loss: 0.11057953536510468\n",
      "128 :acc 0.4464 , nmi 0.2816 , ari 0.1720 , f1 0.1779\n",
      "129 loss: 0.11044567823410034\n",
      "129 :acc 0.4460 , nmi 0.2809 , ari 0.1715 , f1 0.1772\n",
      "130 loss: 0.11040972173213959\n",
      "130 :acc 0.4460 , nmi 0.2801 , ari 0.1708 , f1 0.1783\n",
      "131 loss: 0.110337033867836\n",
      "131 :acc 0.4464 , nmi 0.2808 , ari 0.1717 , f1 0.1793\n",
      "132 loss: 0.11026997119188309\n",
      "132 :acc 0.4456 , nmi 0.2812 , ari 0.1718 , f1 0.1757\n",
      "133 loss: 0.11020033061504364\n",
      "133 :acc 0.4466 , nmi 0.2824 , ari 0.1718 , f1 0.1797\n",
      "134 loss: 0.11012952774763107\n",
      "134 :acc 0.4460 , nmi 0.2797 , ari 0.1709 , f1 0.1794\n",
      "135 loss: 0.11011799424886703\n",
      "135 :acc 0.4456 , nmi 0.2805 , ari 0.1716 , f1 0.1768\n",
      "136 loss: 0.11006586253643036\n",
      "136 :acc 0.4452 , nmi 0.2800 , ari 0.1708 , f1 0.1761\n",
      "137 loss: 0.10998700559139252\n",
      "137 :acc 0.4460 , nmi 0.2806 , ari 0.1716 , f1 0.1779\n",
      "138 loss: 0.10993007570505142\n",
      "138 :acc 0.4472 , nmi 0.2808 , ari 0.1725 , f1 0.1802\n",
      "139 loss: 0.10987997055053711\n",
      "139 :acc 0.4478 , nmi 0.2818 , ari 0.1728 , f1 0.1816\n",
      "140 loss: 0.10993621498346329\n",
      "140 :acc 0.4472 , nmi 0.2818 , ari 0.1731 , f1 0.1798\n",
      "141 loss: 0.10978647321462631\n",
      "141 :acc 0.4476 , nmi 0.2819 , ari 0.1724 , f1 0.1816\n",
      "142 loss: 0.10972557961940765\n",
      "142 :acc 0.4474 , nmi 0.2807 , ari 0.1723 , f1 0.1805\n",
      "143 loss: 0.10978800803422928\n",
      "143 :acc 0.4468 , nmi 0.2818 , ari 0.1729 , f1 0.1777\n",
      "144 loss: 0.10964671522378922\n",
      "144 :acc 0.4472 , nmi 0.2814 , ari 0.1721 , f1 0.1806\n",
      "145 loss: 0.10973373055458069\n",
      "145 :acc 0.4451 , nmi 0.2811 , ari 0.1713 , f1 0.1757\n",
      "146 loss: 0.10955295711755753\n",
      "146 :acc 0.4456 , nmi 0.2813 , ari 0.1720 , f1 0.1758\n",
      "147 loss: 0.10961058735847473\n",
      "147 :acc 0.4470 , nmi 0.2811 , ari 0.1747 , f1 0.1773\n",
      "148 loss: 0.10946124792098999\n",
      "148 :acc 0.4468 , nmi 0.2817 , ari 0.1727 , f1 0.1788\n",
      "149 loss: 0.10938818752765656\n",
      "149 :acc 0.4468 , nmi 0.2816 , ari 0.1724 , f1 0.1803\n",
      "150 loss: 0.10934732109308243\n",
      "150 :acc 0.4468 , nmi 0.2827 , ari 0.1732 , f1 0.1792\n",
      "151 loss: 0.10930013656616211\n",
      "151 :acc 0.4466 , nmi 0.2813 , ari 0.1729 , f1 0.1785\n",
      "152 loss: 0.10923018306493759\n",
      "152 :acc 0.4466 , nmi 0.2826 , ari 0.1731 , f1 0.1784\n",
      "153 loss: 0.1092827320098877\n",
      "153 :acc 0.4458 , nmi 0.2817 , ari 0.1730 , f1 0.1759\n",
      "154 loss: 0.10916335135698318\n",
      "154 :acc 0.4468 , nmi 0.2825 , ari 0.1732 , f1 0.1790\n",
      "155 loss: 0.1090974509716034\n",
      "155 :acc 0.4458 , nmi 0.2823 , ari 0.1732 , f1 0.1760\n",
      "156 loss: 0.10911638289690018\n",
      "156 :acc 0.4452 , nmi 0.2804 , ari 0.1736 , f1 0.1752\n",
      "157 loss: 0.10899917036294937\n",
      "157 :acc 0.4466 , nmi 0.2806 , ari 0.1741 , f1 0.1788\n",
      "158 loss: 0.10887330025434494\n",
      "158 :acc 0.4468 , nmi 0.2815 , ari 0.1732 , f1 0.1788\n",
      "159 loss: 0.10882154852151871\n",
      "159 :acc 0.4460 , nmi 0.2801 , ari 0.1732 , f1 0.1773\n",
      "160 loss: 0.10892070084810257\n",
      "160 :acc 0.4456 , nmi 0.2812 , ari 0.1727 , f1 0.1764\n",
      "161 loss: 0.10873118042945862\n",
      "161 :acc 0.4458 , nmi 0.2803 , ari 0.1735 , f1 0.1755\n",
      "162 loss: 0.10875972360372543\n",
      "162 :acc 0.4458 , nmi 0.2815 , ari 0.1741 , f1 0.1752\n",
      "163 loss: 0.1086864173412323\n",
      "163 :acc 0.4460 , nmi 0.2811 , ari 0.1739 , f1 0.1767\n",
      "164 loss: 0.10880279541015625\n",
      "164 :acc 0.4466 , nmi 0.2810 , ari 0.1737 , f1 0.1800\n",
      "165 loss: 0.10855990648269653\n",
      "165 :acc 0.4468 , nmi 0.2812 , ari 0.1740 , f1 0.1805\n",
      "166 loss: 0.10857868939638138\n",
      "166 :acc 0.4472 , nmi 0.2802 , ari 0.1738 , f1 0.1811\n",
      "167 loss: 0.10855179280042648\n",
      "167 :acc 0.4470 , nmi 0.2823 , ari 0.1741 , f1 0.1781\n",
      "168 loss: 0.10841257125139236\n",
      "168 :acc 0.4464 , nmi 0.2832 , ari 0.1737 , f1 0.1778\n",
      "169 loss: 0.10827630758285522\n",
      "169 :acc 0.4466 , nmi 0.2814 , ari 0.1747 , f1 0.1780\n",
      "170 loss: 0.10823288559913635\n",
      "170 :acc 0.4468 , nmi 0.2816 , ari 0.1743 , f1 0.1785\n",
      "171 loss: 0.10811584442853928\n",
      "171 :acc 0.4484 , nmi 0.2825 , ari 0.1755 , f1 0.1820\n",
      "172 loss: 0.10810256004333496\n",
      "172 :acc 0.4478 , nmi 0.2807 , ari 0.1758 , f1 0.1818\n",
      "173 loss: 0.10811367630958557\n",
      "173 :acc 0.4482 , nmi 0.2817 , ari 0.1762 , f1 0.1814\n",
      "174 loss: 0.10795287787914276\n",
      "174 :acc 0.4480 , nmi 0.2804 , ari 0.1757 , f1 0.1820\n",
      "175 loss: 0.1078355610370636\n",
      "175 :acc 0.4480 , nmi 0.2813 , ari 0.1749 , f1 0.1812\n",
      "176 loss: 0.10776429623365402\n",
      "176 :acc 0.4478 , nmi 0.2811 , ari 0.1753 , f1 0.1816\n",
      "177 loss: 0.10771241784095764\n",
      "177 :acc 0.4476 , nmi 0.2821 , ari 0.1741 , f1 0.1810\n",
      "178 loss: 0.10763195157051086\n",
      "178 :acc 0.4472 , nmi 0.2810 , ari 0.1749 , f1 0.1802\n",
      "179 loss: 0.107655830681324\n",
      "179 :acc 0.4468 , nmi 0.2804 , ari 0.1755 , f1 0.1801\n",
      "180 loss: 0.10774312913417816\n",
      "180 :acc 0.4470 , nmi 0.2815 , ari 0.1763 , f1 0.1800\n",
      "181 loss: 0.10755794495344162\n",
      "181 :acc 0.4468 , nmi 0.2786 , ari 0.1749 , f1 0.1806\n",
      "182 loss: 0.10758037865161896\n",
      "182 :acc 0.4474 , nmi 0.2806 , ari 0.1745 , f1 0.1817\n",
      "183 loss: 0.10747482627630234\n",
      "183 :acc 0.4472 , nmi 0.2794 , ari 0.1759 , f1 0.1806\n",
      "184 loss: 0.10728972405195236\n",
      "184 :acc 0.4474 , nmi 0.2804 , ari 0.1757 , f1 0.1808\n",
      "185 loss: 0.10728755593299866\n",
      "185 :acc 0.4476 , nmi 0.2804 , ari 0.1756 , f1 0.1810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 loss: 0.10731138288974762\n",
      "186 :acc 0.4470 , nmi 0.2802 , ari 0.1743 , f1 0.1808\n",
      "187 loss: 0.10709702968597412\n",
      "187 :acc 0.4476 , nmi 0.2825 , ari 0.1754 , f1 0.1810\n",
      "188 loss: 0.10699781775474548\n",
      "188 :acc 0.4472 , nmi 0.2790 , ari 0.1759 , f1 0.1802\n",
      "189 loss: 0.1068955585360527\n",
      "189 :acc 0.4476 , nmi 0.2800 , ari 0.1759 , f1 0.1809\n",
      "190 loss: 0.10683655738830566\n",
      "190 :acc 0.4474 , nmi 0.2812 , ari 0.1761 , f1 0.1810\n",
      "191 loss: 0.10682404786348343\n",
      "191 :acc 0.4472 , nmi 0.2810 , ari 0.1761 , f1 0.1812\n",
      "192 loss: 0.10671262443065643\n",
      "192 :acc 0.4472 , nmi 0.2795 , ari 0.1755 , f1 0.1812\n",
      "193 loss: 0.10671503096818924\n",
      "193 :acc 0.4476 , nmi 0.2820 , ari 0.1759 , f1 0.1812\n",
      "194 loss: 0.10656605660915375\n",
      "194 :acc 0.4470 , nmi 0.2798 , ari 0.1765 , f1 0.1810\n",
      "195 loss: 0.10665702819824219\n",
      "195 :acc 0.4468 , nmi 0.2780 , ari 0.1759 , f1 0.1809\n",
      "196 loss: 0.10641881823539734\n",
      "196 :acc 0.4470 , nmi 0.2782 , ari 0.1755 , f1 0.1810\n",
      "197 loss: 0.10640719532966614\n",
      "197 :acc 0.4472 , nmi 0.2806 , ari 0.1755 , f1 0.1806\n",
      "198 loss: 0.10629261285066605\n",
      "198 :acc 0.4466 , nmi 0.2771 , ari 0.1756 , f1 0.1807\n",
      "199 loss: 0.10626707971096039\n",
      "199 :acc 0.4464 , nmi 0.2766 , ari 0.1755 , f1 0.1807\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Cases:\n",
    "# File = [Pre-training file, gene_expresion data file, labels file]\n",
    "File = ['../02-Data/Cases/cases_pre_train.pkl', '../02-Data/Cases/cases_X.txt', '../02-Data/Cases/cases_y.txt']\n",
    "# Para = [batch_size, lr, epoch]\n",
    "Para = [1024, 1e-3, 200]\n",
    "# model_para = [n_enc_1(n_dec_3), n_enc_2(n_dec_2), n_enc_3(n_dec_1)]\n",
    "model_para = [500, 500, 2000]\n",
    "# Cluster_para = [n_cluster, n_init, n_input, n_z]\n",
    "Cluster_para = [5, 20, 21209, 10]\n",
    "\n",
    "model = AE(\n",
    "            n_enc_1=model_para[0], n_enc_2=model_para[1], n_enc_3=model_para[2],\n",
    "            n_dec_1=model_para[2], n_dec_2=model_para[1], n_dec_3=model_para[0], n_input=Cluster_para[2], n_z=Cluster_para[3], )\n",
    "\n",
    "\n",
    "x = np.loadtxt(File[1], dtype=float)\n",
    "y = np.loadtxt(File[2], dtype=int)\n",
    "\n",
    "dataset = LoadDataset(x)\n",
    "pretrain_ae(model, dataset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d653b795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('enc_1.weight',\n",
       "              tensor([[ 0.0091,  0.0100,  0.0012,  ..., -0.0026,  0.0083, -0.0022],\n",
       "                      [ 0.0111,  0.0030,  0.0056,  ...,  0.0063,  0.0028, -0.0039],\n",
       "                      [-0.0006,  0.0072,  0.0025,  ...,  0.0027, -0.0005, -0.0065],\n",
       "                      ...,\n",
       "                      [-0.0102,  0.0006, -0.0072,  ..., -0.0060, -0.0164, -0.0005],\n",
       "                      [-0.0061, -0.0048, -0.0026,  ..., -0.0060, -0.0012, -0.0012],\n",
       "                      [ 0.0046, -0.0039, -0.0050,  ..., -0.0031,  0.0197, -0.0058]])),\n",
       "             ('enc_1.bias',\n",
       "              tensor([-5.7544e-03,  2.2069e-03,  2.1292e-03, -2.2168e-03, -4.2936e-03,\n",
       "                      -2.5729e-03,  1.0041e-03, -4.4309e-03, -2.5717e-03, -4.3909e-04,\n",
       "                       2.7025e-03,  4.3569e-03,  1.6243e-03, -5.0390e-04,  2.4936e-03,\n",
       "                      -3.0999e-03,  2.3555e-03,  9.4081e-04, -5.5145e-03,  4.6323e-03,\n",
       "                       1.4934e-03,  2.8210e-03,  2.7554e-04,  3.1426e-03,  7.2786e-05,\n",
       "                      -1.8147e-03, -2.9976e-03,  3.2388e-03, -6.6347e-03, -5.4338e-03,\n",
       "                       5.8895e-03,  5.5951e-03,  6.7553e-03,  6.4060e-03, -4.8924e-04,\n",
       "                      -1.5926e-03,  3.2957e-03, -8.7523e-04, -4.5857e-03, -5.4531e-03,\n",
       "                       6.1411e-03, -3.5412e-03, -1.3880e-03, -4.4760e-03,  1.6548e-03,\n",
       "                      -5.9231e-03, -5.1379e-03,  1.5643e-03,  4.7239e-03, -4.4591e-03,\n",
       "                      -6.2366e-03, -4.5146e-03,  5.9032e-03,  1.9101e-03, -3.2015e-03,\n",
       "                      -1.9849e-07,  3.0278e-03,  2.4052e-03, -4.5513e-03,  5.8201e-03,\n",
       "                       1.8591e-03,  1.3707e-03,  2.1378e-03,  1.0024e-03, -6.2140e-03,\n",
       "                      -5.6194e-03, -4.6834e-03,  1.3615e-03, -4.2585e-03,  1.9091e-04,\n",
       "                      -3.8497e-03,  1.0125e-03,  1.7749e-03, -3.1067e-03, -5.5720e-03,\n",
       "                       2.4334e-03,  7.9974e-04, -2.8313e-04,  3.1677e-03, -6.5477e-03,\n",
       "                       2.3744e-03, -1.9039e-03,  6.7919e-03,  6.3978e-03,  3.7487e-03,\n",
       "                       9.7725e-04, -3.9890e-03, -5.1629e-03, -3.5708e-03, -1.8478e-03,\n",
       "                      -2.8918e-03,  4.3708e-03,  1.1719e-03,  1.7461e-03, -6.8959e-04,\n",
       "                       5.2529e-04, -1.6238e-03,  3.0942e-03, -1.9958e-03, -5.8796e-03,\n",
       "                      -2.1432e-03, -3.0342e-03,  7.1635e-04, -6.0363e-03,  3.7404e-03,\n",
       "                      -2.3293e-03, -3.8471e-03, -3.0240e-04, -3.5927e-03,  6.2713e-03,\n",
       "                      -1.1844e-03,  4.5870e-03,  7.5451e-04, -1.3061e-04, -5.2373e-03,\n",
       "                       2.8823e-04,  1.3638e-03, -1.9960e-03, -6.6594e-03,  3.0257e-03,\n",
       "                       4.1191e-03,  3.4617e-03,  1.2170e-03, -1.6299e-04,  4.5274e-03,\n",
       "                      -5.0783e-04,  5.6600e-03, -5.6672e-03, -4.6765e-03,  5.2554e-03,\n",
       "                       5.5886e-03,  5.7831e-03, -5.3344e-03,  1.4750e-03, -2.8781e-03,\n",
       "                      -5.3370e-03, -2.3626e-03, -4.7331e-03, -3.7138e-03,  1.6777e-03,\n",
       "                      -2.4477e-03,  1.0765e-04,  3.9550e-03, -5.2222e-03, -6.6646e-03,\n",
       "                       4.0100e-03,  5.4601e-03,  6.1152e-03,  2.4097e-03,  4.0715e-03,\n",
       "                       9.7993e-04,  3.0116e-03, -1.2286e-03, -5.6498e-03,  3.9937e-03,\n",
       "                      -2.2735e-03,  6.2551e-03,  6.8148e-03, -3.7099e-03,  5.1890e-03,\n",
       "                      -4.1591e-03,  2.9726e-03, -5.5040e-03, -1.9829e-03,  6.6676e-03,\n",
       "                      -6.4874e-03,  3.6931e-03, -5.3296e-03,  3.5412e-03, -1.6274e-03,\n",
       "                      -3.0194e-03, -2.6134e-03, -3.4230e-03,  4.2915e-04,  4.3657e-03,\n",
       "                      -4.8593e-03, -5.8054e-03, -2.0811e-03,  2.1011e-04, -6.4364e-03,\n",
       "                      -6.0216e-03, -2.8105e-03,  5.5244e-03,  6.2370e-03, -5.6707e-03,\n",
       "                       5.5126e-03,  2.9882e-04, -5.8016e-03,  6.6649e-03, -1.4806e-04,\n",
       "                       5.7391e-03, -2.7169e-03,  1.0318e-03,  2.3174e-04, -4.2037e-03,\n",
       "                       8.6588e-04,  1.1259e-03, -5.9823e-03,  2.7204e-03,  3.7470e-03,\n",
       "                       5.5728e-03,  3.8796e-03, -2.7272e-03, -6.5436e-03,  6.2754e-03,\n",
       "                       5.0397e-03, -1.3379e-03, -3.8025e-03, -5.4855e-03,  5.8200e-03,\n",
       "                       3.0879e-04,  4.7237e-03,  4.8358e-03,  6.6628e-03,  2.3157e-03,\n",
       "                      -9.6503e-04,  7.0246e-04,  5.4740e-03,  1.9754e-03, -6.0547e-03,\n",
       "                       4.6329e-03,  6.5144e-03, -6.4135e-03,  6.6281e-03,  1.1346e-03,\n",
       "                      -3.8999e-03, -1.1907e-03,  1.5254e-03,  6.7416e-03,  1.9671e-03,\n",
       "                      -4.4585e-03, -3.4563e-03,  9.6636e-04,  2.4805e-03, -4.5691e-03,\n",
       "                       6.0457e-03, -2.5606e-03, -3.4155e-03, -1.0174e-03,  4.4704e-03,\n",
       "                      -5.9707e-03,  4.1408e-03,  9.5501e-04, -1.3119e-04, -5.0426e-03,\n",
       "                      -4.6639e-03,  5.9362e-03, -2.1355e-03, -4.2655e-03, -4.7511e-03,\n",
       "                      -1.1776e-03, -4.9757e-03,  4.6952e-03, -3.9960e-04,  5.1065e-04,\n",
       "                       3.5475e-03, -8.9206e-06,  4.9346e-03, -3.6497e-03, -2.3553e-03,\n",
       "                       3.8914e-03,  2.5170e-04, -3.3009e-03,  1.4623e-03,  2.4672e-03,\n",
       "                      -8.5060e-04, -4.3969e-03, -3.2408e-03, -6.5285e-03,  6.4680e-03,\n",
       "                       4.6572e-03, -6.3664e-05,  5.3440e-04,  1.3376e-03, -4.6365e-03,\n",
       "                      -3.6244e-03, -4.8474e-03, -6.7062e-03,  5.2470e-03,  1.5052e-03,\n",
       "                       9.4034e-04, -3.3210e-03, -6.2988e-03, -1.7353e-03,  4.6807e-03,\n",
       "                       4.5510e-03, -2.5970e-03, -2.3935e-03, -2.2092e-03,  3.6382e-03,\n",
       "                       3.0561e-03,  4.5678e-04, -1.8960e-03, -3.2112e-03, -1.5486e-04,\n",
       "                      -1.4090e-03, -6.5050e-04,  3.8911e-03,  1.5937e-03, -2.9074e-03,\n",
       "                       5.4379e-03, -3.6009e-03, -5.9718e-03, -5.7844e-03,  1.4267e-03,\n",
       "                      -1.2789e-04, -1.9308e-03,  5.8526e-03,  3.0029e-03, -3.9914e-04,\n",
       "                       1.5173e-03, -6.5234e-03, -3.2862e-03, -1.4083e-03, -5.5853e-03,\n",
       "                      -5.1319e-03, -1.7596e-03, -4.6219e-03, -6.6675e-03, -3.4660e-03,\n",
       "                      -1.6450e-03, -6.0248e-03,  6.7561e-03, -8.0404e-04,  3.9507e-03,\n",
       "                      -3.3589e-03, -4.9784e-03, -4.0497e-03,  6.1871e-03, -4.6785e-03,\n",
       "                      -6.1507e-03,  4.7687e-03,  4.1746e-03, -1.8166e-03,  4.4108e-03,\n",
       "                       2.7332e-04, -9.8325e-04,  1.6566e-03, -2.8310e-03,  2.8206e-03,\n",
       "                      -6.1388e-03, -4.8112e-03,  2.4490e-03, -1.9383e-03,  1.0692e-03,\n",
       "                      -1.0605e-03,  3.6938e-03, -3.6654e-03,  6.5927e-03,  1.4824e-03,\n",
       "                       9.2818e-04,  2.8028e-03, -6.1109e-03, -3.0509e-03,  1.6013e-03,\n",
       "                      -1.3389e-03,  6.5363e-03, -6.2259e-03,  1.5941e-03, -2.2033e-03,\n",
       "                       4.0896e-03, -2.7708e-03, -7.5417e-04, -1.8765e-04,  2.2529e-03,\n",
       "                      -6.5976e-03, -4.3944e-03, -1.0841e-03,  6.4056e-03,  3.9557e-03,\n",
       "                      -3.3028e-03,  4.3662e-03, -3.4270e-03,  2.4515e-04, -8.9555e-04,\n",
       "                      -6.2265e-03, -2.0700e-03, -4.1508e-03,  4.0840e-03,  3.7654e-03,\n",
       "                      -3.0255e-03, -3.2153e-03,  4.9191e-03,  5.4909e-03,  6.8842e-05,\n",
       "                      -6.5135e-03,  6.7250e-03,  3.7241e-03,  4.7056e-03, -6.5464e-03,\n",
       "                      -4.8362e-05, -1.2254e-03, -6.7960e-03,  1.9087e-03, -2.3939e-03,\n",
       "                      -5.4308e-03,  3.6446e-03,  1.5272e-03, -5.7470e-03, -3.6143e-03,\n",
       "                       5.0790e-03,  2.8115e-03, -6.0769e-03, -1.8185e-03, -1.4727e-03,\n",
       "                       1.6228e-03,  2.6577e-04, -1.4675e-03, -1.2576e-03,  2.8123e-03,\n",
       "                      -3.4638e-03, -1.1936e-03, -4.2179e-03, -8.5981e-05,  6.0917e-04,\n",
       "                       3.1842e-03,  8.8436e-04, -6.0103e-03,  2.1371e-03,  1.5414e-03,\n",
       "                       3.0011e-03,  2.3812e-03,  6.7316e-03, -4.8673e-03, -5.5308e-03,\n",
       "                      -2.7299e-03, -4.2612e-03, -4.6883e-04,  5.7623e-03, -2.6492e-04,\n",
       "                       5.5512e-03, -4.1715e-03, -4.2877e-03,  3.5531e-03,  3.6388e-03,\n",
       "                       5.9886e-03, -6.3067e-03, -4.7912e-03,  4.8380e-03,  9.5740e-05,\n",
       "                      -7.4138e-04,  6.1018e-03, -3.1577e-03,  3.9162e-03, -6.2031e-03,\n",
       "                       2.6837e-03,  5.2368e-03,  6.2928e-03, -8.7952e-04,  4.1587e-03,\n",
       "                      -3.9504e-03,  2.8657e-03,  4.9771e-03, -9.3674e-05, -5.7766e-03,\n",
       "                      -4.2264e-03,  1.7940e-04, -6.5368e-03,  5.5804e-03,  1.9031e-03,\n",
       "                      -3.6149e-03,  5.8029e-03,  2.9459e-03, -6.1356e-03, -5.3343e-03,\n",
       "                       2.2473e-03, -5.9615e-03,  3.0109e-03,  4.9504e-03,  7.2174e-04,\n",
       "                       3.5463e-03, -1.5086e-03, -4.4301e-03, -5.3881e-03,  2.1258e-04,\n",
       "                       2.3832e-03, -1.3079e-03,  3.4989e-03, -2.1453e-03, -4.6842e-03,\n",
       "                       3.6004e-03, -2.4183e-03, -8.0061e-04, -5.1673e-03, -3.8082e-03,\n",
       "                      -3.2925e-05, -2.1847e-03,  3.0861e-03, -3.6439e-03, -2.6432e-03,\n",
       "                      -4.4520e-03,  1.0489e-03,  6.3073e-03, -5.4550e-03,  4.8983e-03,\n",
       "                       3.4194e-04,  4.5692e-03, -6.8817e-04,  5.7163e-03, -5.5638e-03])),\n",
       "             ('BN1.weight',\n",
       "              tensor([0.9971, 0.9925, 0.9959, 1.0065, 0.9977, 0.9890, 0.9859, 0.9938, 1.0086,\n",
       "                      0.9905, 1.0150, 1.0097, 1.0281, 1.0060, 0.9959, 1.0165, 1.0404, 1.0094,\n",
       "                      0.9948, 0.9971, 0.9868, 0.9914, 0.9970, 0.9983, 1.0072, 0.9978, 1.0082,\n",
       "                      1.0056, 1.0095, 0.9889, 0.9966, 1.0063, 0.9884, 1.0307, 0.9897, 0.9999,\n",
       "                      1.0106, 1.0027, 0.9949, 1.0068, 1.0108, 1.0197, 0.9998, 0.9946, 1.0052,\n",
       "                      1.0073, 0.9914, 1.0053, 1.0113, 1.0071, 0.9899, 1.0102, 1.0062, 0.9822,\n",
       "                      1.0040, 0.9975, 0.9963, 1.0160, 0.9922, 0.9936, 0.9934, 0.9960, 0.9992,\n",
       "                      1.0019, 1.0045, 1.0039, 1.0100, 1.0118, 1.0167, 0.9978, 0.9946, 0.9931,\n",
       "                      0.9900, 1.0141, 1.0043, 0.9917, 0.9799, 1.0064, 1.0288, 1.0009, 1.0039,\n",
       "                      1.0005, 1.0010, 0.9982, 0.9879, 1.0096, 1.0069, 1.0014, 1.0103, 1.0128,\n",
       "                      0.9990, 0.9893, 0.9875, 0.9909, 0.9981, 0.9838, 0.9872, 0.9920, 1.0159,\n",
       "                      0.9770, 1.0157, 0.9847, 1.0156, 1.0036, 1.0122, 0.9940, 0.9893, 0.9967,\n",
       "                      1.0109, 1.0168, 1.0060, 1.0149, 0.9898, 1.0021, 1.0010, 1.0096, 1.0044,\n",
       "                      1.0023, 0.9928, 1.0072, 1.0020, 1.0002, 0.9961, 0.9979, 0.9863, 1.0129,\n",
       "                      0.9810, 1.0067, 1.0103, 0.9955, 0.9952, 1.0139, 0.9839, 1.0119, 0.9779,\n",
       "                      1.0117, 0.9996, 1.0011, 0.9892, 1.0063, 0.9882, 0.9859, 0.9932, 1.0113,\n",
       "                      0.9905, 1.0110, 0.9986, 0.9884, 1.0003, 1.0135, 0.9998, 1.0022, 1.0010,\n",
       "                      0.9993, 1.0243, 1.0020, 1.0017, 1.0053, 1.0082, 0.9869, 0.9975, 0.9969,\n",
       "                      0.9693, 0.9861, 1.0042, 0.9748, 1.0048, 1.0206, 1.0055, 1.0099, 1.0005,\n",
       "                      1.0008, 0.9925, 1.0119, 0.9871, 1.0200, 1.0006, 0.9838, 1.0042, 0.9871,\n",
       "                      1.0117, 0.9801, 1.0053, 1.0385, 1.0171, 1.0170, 0.9955, 0.9997, 0.9940,\n",
       "                      1.0024, 0.9955, 0.9773, 0.9974, 1.0046, 1.0012, 0.9961, 1.0078, 0.9942,\n",
       "                      1.0024, 1.0019, 0.9895, 0.9852, 1.0001, 1.0035, 1.0055, 0.9929, 1.0327,\n",
       "                      0.9898, 1.0201, 0.9648, 1.0244, 1.0030, 1.0071, 0.9971, 1.0021, 0.9847,\n",
       "                      1.0104, 0.9954, 1.0088, 0.9801, 1.0189, 0.9811, 0.9862, 1.0090, 1.0143,\n",
       "                      0.9998, 0.9972, 1.0023, 1.0010, 0.9858, 0.9940, 1.0027, 0.9734, 1.0004,\n",
       "                      0.9901, 1.0069, 0.9891, 1.0107, 0.9837, 0.9989, 1.0082, 1.0131, 0.9798,\n",
       "                      0.9853, 1.0004, 1.0155, 1.0254, 0.9978, 1.0142, 0.9986, 0.9999, 0.9871,\n",
       "                      1.0039, 0.9943, 0.9957, 0.9843, 1.0123, 0.9924, 1.0119, 0.9797, 0.9967,\n",
       "                      1.0087, 0.9881, 1.0030, 0.9908, 0.9872, 1.0013, 1.0113, 1.0337, 0.9940,\n",
       "                      0.9933, 1.0376, 1.0029, 1.0014, 0.9899, 1.0065, 1.0028, 0.9977, 0.9985,\n",
       "                      0.9876, 0.9993, 0.9950, 0.9918, 1.0096, 0.9982, 1.0265, 0.9844, 0.9935,\n",
       "                      1.0043, 1.0089, 0.9954, 0.9881, 0.9689, 1.0081, 0.9781, 1.0036, 0.9980,\n",
       "                      1.0041, 0.9996, 1.0101, 0.9625, 1.0147, 0.9967, 0.9925, 1.0051, 1.0011,\n",
       "                      0.9961, 1.0064, 0.9901, 0.9821, 0.9856, 0.9905, 1.0361, 1.0166, 1.0257,\n",
       "                      1.0019, 1.0000, 1.0051, 1.0010, 1.0033, 1.0032, 1.0079, 0.9971, 0.9903,\n",
       "                      0.9978, 0.9965, 1.0055, 1.0117, 0.9875, 0.9931, 1.0026, 1.0047, 1.0324,\n",
       "                      0.9835, 0.9962, 1.0008, 0.9926, 1.0084, 0.9929, 0.9895, 0.9804, 0.9883,\n",
       "                      1.0091, 0.9890, 1.0085, 1.0135, 1.0037, 1.0077, 0.9962, 1.0050, 0.9712,\n",
       "                      0.9851, 0.9751, 1.0021, 1.0069, 0.9860, 1.0091, 0.9945, 0.9883, 1.0023,\n",
       "                      1.0133, 0.9961, 0.9983, 1.0073, 0.9899, 0.9801, 1.0056, 0.9972, 0.9977,\n",
       "                      1.0034, 0.9946, 0.9976, 1.0098, 0.9889, 1.0118, 1.0490, 1.0115, 1.0211,\n",
       "                      1.0023, 0.9975, 0.9976, 1.0288, 1.0401, 0.9924, 1.0058, 1.0142, 0.9844,\n",
       "                      1.0067, 0.9971, 0.9953, 0.9817, 0.9994, 1.0088, 1.0004, 1.0015, 1.0069,\n",
       "                      1.0071, 0.9999, 0.9975, 1.0009, 0.9937, 1.0063, 1.0072, 0.9983, 0.9948,\n",
       "                      1.0157, 1.0174, 1.0032, 0.9952, 0.9988, 0.9788, 0.9819, 1.0174, 0.9843,\n",
       "                      0.9903, 1.0252, 1.0027, 0.9886, 0.9893, 0.9961, 1.0009, 1.0277, 0.9904,\n",
       "                      0.9935, 0.9909, 1.0370, 1.0388, 0.9993, 0.9977, 1.0100, 0.9804, 0.9960,\n",
       "                      1.0453, 1.0054, 1.0228, 1.0139, 0.9875, 0.9965, 1.0178, 0.9843, 0.9971,\n",
       "                      0.9943, 0.9825, 0.9941, 1.0112, 0.9889, 1.0055, 1.0040, 1.0061, 0.9919,\n",
       "                      1.0009, 1.0135, 1.0519, 1.0087, 0.9958, 0.9995, 0.9841, 1.0021, 0.9757,\n",
       "                      0.9911, 0.9955, 0.9773, 0.9952, 0.9942, 1.0025, 0.9981, 0.9923, 0.9996,\n",
       "                      1.0123, 0.9942, 1.0135, 1.0035, 0.9874, 1.0037, 0.9947, 0.9885, 1.0018,\n",
       "                      1.0294, 1.0060, 0.9954, 0.9836, 0.9960, 0.9959, 0.9952, 1.0034, 1.0004,\n",
       "                      0.9991, 1.0293, 0.9993, 0.9925, 0.9988, 1.0040, 1.0095, 1.0315, 0.9968,\n",
       "                      1.0018, 1.0148, 0.9918, 1.0053, 1.0061])),\n",
       "             ('BN1.bias',\n",
       "              tensor([ 4.0594e-03, -5.0318e-03, -1.5793e-02,  9.0514e-05, -9.6159e-04,\n",
       "                      -5.2232e-03, -1.5745e-02, -7.3779e-03, -7.5603e-03, -7.1534e-03,\n",
       "                       3.5455e-02,  8.6431e-03,  4.5637e-02, -6.1586e-03, -6.3898e-03,\n",
       "                       2.3381e-02,  2.7713e-02, -3.6709e-03,  6.9433e-04, -5.8733e-03,\n",
       "                       5.3535e-03, -7.4743e-03, -2.8736e-03, -8.4768e-04,  1.0668e-02,\n",
       "                       1.0346e-03, -4.1251e-03,  2.5104e-02, -5.7669e-03, -1.1310e-02,\n",
       "                       2.5937e-04, -7.5826e-03, -8.9967e-03,  2.8161e-02, -1.6228e-02,\n",
       "                      -6.2561e-03,  3.3754e-02,  1.2459e-03, -3.9843e-03,  3.6756e-03,\n",
       "                       2.4281e-02,  2.2958e-02,  9.1913e-04, -1.7585e-02, -9.5284e-03,\n",
       "                      -2.4926e-02, -1.3698e-02,  6.6237e-03,  9.7742e-03,  6.0404e-03,\n",
       "                      -1.1168e-02,  5.8107e-03,  1.7588e-02, -9.9554e-03,  3.0549e-03,\n",
       "                       4.5431e-03,  1.7637e-04, -1.1724e-02, -2.4099e-04, -1.6974e-02,\n",
       "                      -2.7894e-03,  8.4667e-03,  4.2854e-03,  3.6983e-03,  4.6833e-03,\n",
       "                       7.7968e-03,  5.7502e-02, -5.3188e-03,  2.3179e-02, -5.1754e-03,\n",
       "                       7.0332e-03, -1.5013e-02, -2.5964e-02,  1.7775e-02,  1.0720e-02,\n",
       "                      -4.4635e-03, -1.1509e-02,  1.6037e-03,  2.7195e-02,  2.6064e-03,\n",
       "                      -5.4839e-03, -1.3173e-02, -8.2739e-04, -1.7331e-02, -1.7864e-02,\n",
       "                      -3.0349e-03, -3.2225e-03,  9.5169e-03,  1.5073e-02,  3.9193e-03,\n",
       "                       9.4370e-04, -1.2426e-02, -2.2087e-03, -1.0107e-02, -9.3971e-03,\n",
       "                      -1.1512e-02, -7.4574e-04, -8.8388e-03, -1.1263e-02, -1.7553e-02,\n",
       "                       3.2086e-04, -4.6305e-03,  1.0587e-02, -7.4947e-03,  2.4596e-02,\n",
       "                      -6.2768e-03, -1.6608e-02, -9.9991e-03, -2.2010e-02,  3.0802e-02,\n",
       "                      -9.6905e-03,  2.3917e-03, -2.3992e-02, -1.3486e-03, -8.0692e-03,\n",
       "                       1.4648e-02,  8.0382e-03,  1.2126e-02,  8.3352e-03, -3.7901e-03,\n",
       "                       2.3228e-03, -1.2158e-02, -1.6096e-03, -2.4430e-03, -9.4939e-03,\n",
       "                       2.4778e-02, -3.0134e-02,  5.1621e-02,  1.3621e-02, -5.1696e-03,\n",
       "                      -1.0495e-02,  1.7757e-04,  2.0578e-02,  1.9193e-02, -1.5350e-02,\n",
       "                      -5.8736e-04, -1.5672e-02, -1.4462e-02, -2.6980e-02,  9.1320e-03,\n",
       "                      -1.2870e-02, -1.7951e-03, -4.1660e-03, -4.9851e-03, -1.7529e-02,\n",
       "                      -2.8083e-03, -1.7757e-02, -4.8636e-03, -3.7770e-03, -2.6678e-03,\n",
       "                       4.4149e-03,  4.1547e-02, -8.4857e-03, -2.2295e-03,  1.6434e-02,\n",
       "                       1.0471e-02,  8.8881e-03,  8.3571e-03,  3.1730e-02, -1.2786e-02,\n",
       "                       1.2878e-02,  1.4993e-02, -1.4064e-02, -2.1409e-02,  1.7448e-02,\n",
       "                      -7.4335e-03, -1.1226e-02,  1.4355e-02,  2.2685e-02,  2.8976e-02,\n",
       "                       1.4831e-02,  1.2995e-02, -2.5700e-03,  2.5325e-02, -1.0786e-02,\n",
       "                       1.3004e-02,  4.3818e-04, -1.1153e-02, -1.0904e-02, -1.5592e-02,\n",
       "                       7.0602e-03, -1.1018e-02, -5.5402e-03,  3.4182e-02,  3.7426e-02,\n",
       "                       2.8854e-03, -1.5559e-02,  6.8362e-03,  6.2999e-03, -3.5610e-03,\n",
       "                      -2.7714e-03,  2.5754e-03,  2.0355e-03, -2.9285e-03,  4.9572e-03,\n",
       "                      -3.8254e-03,  1.3284e-02, -8.3978e-04, -1.3444e-02,  2.0391e-04,\n",
       "                      -1.5755e-02,  6.9095e-04, -8.0448e-04, -6.0238e-03,  5.0560e-03,\n",
       "                       2.9094e-03,  2.8107e-02, -2.1358e-02,  4.7936e-02, -2.0861e-02,\n",
       "                       1.5492e-02,  1.4426e-02, -2.5051e-03, -1.3663e-04, -3.1559e-04,\n",
       "                      -1.0894e-02,  4.1048e-02, -3.4041e-03,  4.5017e-02, -1.9688e-03,\n",
       "                       1.7280e-02, -7.4791e-03, -3.6666e-03,  2.3357e-03,  3.2881e-02,\n",
       "                       6.8436e-03, -3.9348e-03,  9.0235e-03, -2.1210e-02, -2.4025e-02,\n",
       "                       4.0461e-03, -1.7768e-03, -1.8268e-02,  7.4908e-03, -7.7202e-03,\n",
       "                      -1.7597e-04, -2.2935e-03,  2.0209e-02, -1.8251e-02, -4.8218e-03,\n",
       "                       2.4431e-03, -2.4755e-03,  2.2238e-03, -1.7090e-02, -7.0996e-03,\n",
       "                       2.9855e-02,  2.1227e-02,  3.7102e-03,  1.4305e-02,  4.5382e-03,\n",
       "                       2.8491e-03,  3.3522e-03,  5.4064e-03,  3.2605e-04, -1.0318e-02,\n",
       "                      -1.5519e-02,  1.1807e-02,  3.8816e-03, -3.1090e-03, -2.4769e-02,\n",
       "                       1.2699e-03,  7.7746e-03, -5.6316e-03,  9.0590e-03, -8.0822e-03,\n",
       "                      -3.4180e-03,  7.9405e-03,  1.1153e-02,  3.5991e-02, -1.0608e-02,\n",
       "                      -1.1090e-02,  4.0743e-02, -7.4985e-03,  1.0126e-04,  9.3918e-03,\n",
       "                       2.6829e-02,  1.2417e-02, -2.4577e-03, -9.9617e-04, -9.6344e-03,\n",
       "                      -1.9459e-03,  7.3721e-04,  3.8104e-03, -1.1509e-02, -1.2261e-02,\n",
       "                       4.6930e-02, -6.6054e-03, -2.1555e-03, -8.0045e-03,  2.3775e-02,\n",
       "                       1.6336e-03, -1.0828e-02, -4.3718e-03,  4.0190e-03, -9.7443e-03,\n",
       "                       2.7163e-02, -8.9155e-03,  7.7455e-03,  1.4243e-02,  1.0554e-02,\n",
       "                      -3.2611e-02,  3.3487e-02,  1.9630e-02, -1.4139e-02, -1.6922e-02,\n",
       "                      -5.8303e-03, -5.7436e-03,  4.3156e-03, -5.2195e-04, -1.0493e-02,\n",
       "                      -1.1251e-02, -1.0911e-02,  1.1276e-02,  3.5221e-02,  2.2192e-02,\n",
       "                       2.2638e-02,  1.8907e-02, -1.6122e-02,  1.1588e-02, -1.0568e-02,\n",
       "                      -7.0857e-03,  4.8500e-02, -6.1112e-03, -4.7439e-03,  1.0851e-02,\n",
       "                      -3.8915e-03,  3.7462e-03,  1.9526e-03,  4.1480e-02, -5.5533e-06,\n",
       "                      -3.0722e-03, -1.6980e-03,  2.5256e-02, -2.3236e-02, -1.9411e-02,\n",
       "                       4.9162e-03, -1.6520e-02, -1.3899e-02, -1.0378e-03,  1.0046e-02,\n",
       "                       5.0061e-03, -1.1879e-02,  8.4992e-04, -9.2278e-03, -3.3933e-03,\n",
       "                       3.9563e-02, -5.9437e-03, -3.4242e-04, -9.2646e-04,  1.5635e-02,\n",
       "                      -2.7571e-02, -1.3822e-02, -4.2327e-03,  8.0171e-03,  2.4179e-02,\n",
       "                       5.8971e-03, -1.1321e-02, -9.1618e-04, -1.5339e-02,  1.8384e-02,\n",
       "                       1.6855e-02, -1.2112e-02, -1.3439e-02,  4.2908e-02, -1.6259e-02,\n",
       "                      -1.8414e-02, -4.2421e-03,  7.5873e-03, -5.7805e-03,  7.1854e-03,\n",
       "                      -4.2634e-03, -1.2079e-02,  8.1937e-03, -1.9491e-02, -5.0133e-03,\n",
       "                       6.9344e-02,  1.4948e-02,  3.3829e-02,  2.0790e-02,  6.0429e-03,\n",
       "                      -3.8615e-03,  5.5416e-02,  3.6186e-02, -3.7592e-03,  1.0102e-03,\n",
       "                      -6.5046e-03, -1.4611e-02,  6.6348e-04, -3.7167e-03,  3.5503e-03,\n",
       "                      -8.3632e-03,  1.4139e-02, -6.0016e-03,  1.1595e-03, -1.3094e-03,\n",
       "                       9.7593e-03,  2.2169e-02, -3.4479e-03,  2.5096e-03,  3.1956e-03,\n",
       "                      -1.6961e-02,  6.4165e-03, -2.6551e-03,  3.2680e-03,  4.3894e-03,\n",
       "                       2.2595e-03,  2.8166e-02,  1.2012e-02, -6.1478e-03, -1.1072e-02,\n",
       "                      -1.8820e-02, -6.0673e-03,  1.6666e-02, -6.0699e-03, -7.6628e-03,\n",
       "                       1.5293e-02, -4.1584e-05,  2.3221e-03,  5.7097e-03, -6.2556e-03,\n",
       "                       1.6377e-02,  2.3825e-02,  1.2987e-03,  2.0180e-03, -6.6633e-03,\n",
       "                       3.8143e-02,  3.0196e-02,  3.4153e-03, -4.1226e-03,  1.4690e-02,\n",
       "                      -2.1418e-02, -7.0367e-03,  8.0378e-02,  1.5395e-02,  2.6277e-02,\n",
       "                      -6.5328e-03,  2.8636e-03,  2.5340e-02, -6.9383e-03, -8.1701e-03,\n",
       "                      -9.9435e-03, -2.2051e-02, -1.1318e-02,  1.8702e-02,  2.9626e-02,\n",
       "                      -5.0186e-03,  6.1312e-04, -2.9819e-02,  8.0456e-03,  7.2852e-03,\n",
       "                       7.6587e-03,  1.1433e-02,  7.5114e-02,  1.8047e-02, -9.9897e-03,\n",
       "                      -2.1822e-03,  3.4482e-03,  8.2373e-03,  1.2539e-03, -1.3024e-02,\n",
       "                      -6.9816e-03, -2.0613e-02, -2.8970e-03, -1.5187e-03,  1.1167e-02,\n",
       "                      -9.4235e-03, -1.2954e-02,  2.7797e-03, -7.6660e-03,  3.4421e-03,\n",
       "                       2.6286e-04, -1.2033e-02, -4.5323e-03, -8.7031e-04,  6.3329e-03,\n",
       "                      -9.0894e-03,  1.6936e-02,  1.0476e-02,  3.3068e-03, -2.5128e-05,\n",
       "                      -9.2873e-03, -1.3943e-04,  1.4135e-04, -9.8489e-03,  2.3040e-02,\n",
       "                      -4.5003e-03, -5.6171e-06,  6.9942e-02, -3.2855e-03, -3.4134e-03,\n",
       "                       9.1650e-03, -1.3727e-02,  2.3860e-02,  9.8522e-03,  1.6869e-03,\n",
       "                      -1.1479e-02, -1.2388e-03, -8.6275e-05,  2.5283e-03,  7.8813e-03])),\n",
       "             ('BN1.running_mean',\n",
       "              tensor([-2.1862,  3.3365, -3.3607,  1.1547,  3.3319,  7.6709, -1.9891,  5.5397,\n",
       "                      -0.6624, -1.0285,  1.3875, -0.0573,  0.3676, -0.8872,  3.7942,  3.0026,\n",
       "                      -0.8233, -3.3333,  1.1919, -0.7810,  1.9944, -1.3144,  3.0930, -3.1855,\n",
       "                       2.7280, -0.6106, -2.8229,  0.2346, -3.5508,  2.5038,  4.6208, -2.2166,\n",
       "                       3.4918,  1.4401, -1.7948, -1.3094, -0.2422,  2.1147,  1.4632, -1.5312,\n",
       "                      -3.0530, -1.6862,  7.5922, -3.2960, -1.6003, -1.8238, -3.2360,  2.4807,\n",
       "                       1.3933,  2.4510, -0.7976,  0.3009,  6.5492, -2.6022, -2.3122,  3.0958,\n",
       "                      -0.5627, -2.9837, -2.8188, -0.5143, -1.8463, -4.0064,  0.0838, -1.4192,\n",
       "                      -1.4066, -2.3623, -1.7661, -3.4354,  1.0899, -5.5180,  0.7566,  0.7546,\n",
       "                      -6.3718,  0.6093,  0.8723, -0.9914, -3.1391, -2.7338, -1.6540, -3.0254,\n",
       "                       7.0361, -0.5746, -1.6290, -3.2313,  1.2088, -0.8327, -4.0045,  2.8843,\n",
       "                       1.7007,  1.7807, -3.3396,  5.2340, -4.2490, -0.5723, -2.5467, -6.9446,\n",
       "                       1.3364, -1.9350, -2.3452, -3.1345, -2.2763, -0.6033,  0.1067,  3.8897,\n",
       "                       1.3221,  4.9318, -2.8568,  3.3916, -2.5928, -0.7490, -2.7082,  8.2572,\n",
       "                      -0.5533, -3.0475, -0.4801,  3.6401,  5.7808, -1.4695, -2.7257, -3.2282,\n",
       "                      -0.4523, -2.3046,  0.2246, -1.6733,  3.0891,  6.8817, -2.4093, -0.1536,\n",
       "                       1.8009,  0.7801, -1.7794,  2.2477, -3.0537,  2.0171, -4.2974,  2.9233,\n",
       "                       6.8258, -2.3285, -1.9034,  0.7508,  2.4336,  2.5311, -1.7473, -3.3549,\n",
       "                      -6.0310, -1.1411, -0.5645,  1.1052, -0.5490, -0.3127,  3.9499,  2.8126,\n",
       "                      -0.9797,  1.8891, -0.3978, -4.2369,  0.5511,  1.9206,  0.0638, -4.6852,\n",
       "                       3.1675, -2.8720,  3.7571, -3.0123,  1.5667, -5.5342,  0.5370, -2.9124,\n",
       "                       2.7035, -0.9836,  1.0668,  0.1858, -4.5801, -0.3864, -6.6732,  0.3863,\n",
       "                      -1.7478, -5.2081, -3.4200, -0.6620,  0.2989,  2.1508,  1.6347,  0.6819,\n",
       "                      -4.3857,  0.0340, -2.0155,  1.8956,  0.0115, -1.5209, -2.0657, -5.5204,\n",
       "                       1.6473, -2.0837, -1.6201,  4.1223, -0.2116, -0.0328, -4.6300, -0.4506,\n",
       "                       3.7662, -1.0813, -3.8778, -3.1275,  6.8974,  6.2472,  2.6237,  0.6821,\n",
       "                      -2.3015, -4.6571, -2.6556, -4.7046, -2.4352, -0.7750,  0.4780, -0.2480,\n",
       "                       1.7321,  2.5518,  0.0731, -4.1077,  0.7335,  2.6174,  2.7383, -3.1363,\n",
       "                       1.2607,  1.7498, -2.1545,  1.7661, -0.4360,  3.8911, -7.0249,  4.1037,\n",
       "                       2.5096, -4.3569, -4.2454, -1.8038,  7.4278, -1.2756,  0.9641,  3.3982,\n",
       "                       0.3058, -0.9940, -6.6554, -0.3838,  2.9718,  0.4188, -2.2129, -2.6271,\n",
       "                      -3.8503, -3.0903, -0.9887, -7.4269,  0.7437,  3.6967,  2.9730,  1.6348,\n",
       "                       0.2174,  5.9491, -4.2827, -1.4582,  2.3415,  0.8483, -5.7119, -3.8608,\n",
       "                      -2.4366,  2.2060,  1.3615,  1.4840, -0.3831, -2.7500, -6.4609, -0.1301,\n",
       "                      -2.3679, -2.3910,  3.7783, -2.4469, -0.4907, -1.9273,  0.5861,  3.8292,\n",
       "                      -2.1766,  3.7976,  1.0916, -3.4095, -1.8802,  1.1789,  2.2261, -2.2304,\n",
       "                      -2.4881, -1.0544,  1.7758, -1.6417, -0.2427, -1.6694, -2.2079, -1.9395,\n",
       "                      -2.9483,  1.2781, -0.7081, -4.8210, -5.1433,  0.0236,  2.7296,  1.0007,\n",
       "                      -2.9096, -0.9746,  0.6422,  2.7674,  2.7739, -0.5572, -2.8118,  4.0741,\n",
       "                       0.2158, -2.2605,  1.4022,  0.2949,  1.3826, -3.1976, -0.7515, -3.0822,\n",
       "                      -1.8416,  0.8256, -3.3963, -6.6212,  1.9242,  2.6386,  8.8070,  0.9436,\n",
       "                       2.1200, -3.0512, -2.4542, -0.8101, -1.5045, -1.2530,  0.9435,  3.9979,\n",
       "                      -5.0532, -1.5030,  0.4104,  1.1587, -4.4054,  4.4555, -0.7542, -4.2733,\n",
       "                      -3.0554,  3.3014,  2.8610,  0.7921, -2.1353, -3.0158, -0.1221,  0.5370,\n",
       "                      -5.3879,  0.3925, -5.0504, -7.0158,  5.0635, -2.1815,  1.5670,  1.0486,\n",
       "                       3.5952, -4.0085, -2.0910,  0.2706,  2.9362, -0.2834,  1.4890, -1.1013,\n",
       "                       1.5716,  3.1420, -2.9364, -2.4141,  2.8182, -0.2815, -3.4925,  0.9639,\n",
       "                      -1.6602,  1.9341,  4.0074,  2.2251, -3.3015, -0.8857,  3.4625, -0.2928,\n",
       "                       7.5290,  1.2543, -0.8561, -0.4744,  2.7639,  0.4517, -4.3466,  0.1612,\n",
       "                      -2.9434, -1.0465, -2.5282,  1.8343,  0.5660,  1.8190, -5.0652, -1.3912,\n",
       "                      -2.2933,  2.9098, -4.0296,  1.4821,  0.7164,  3.0273,  0.7387, -0.1259,\n",
       "                      -1.7711,  2.8738,  3.5772, -2.9412,  1.4774,  1.0380, -2.3007, -0.2226,\n",
       "                       3.8889, -2.7495, -0.0146, -2.8929, -2.7103,  2.7317, -2.2705, -2.9864,\n",
       "                       1.9216,  2.4287,  3.3893,  0.3692, -3.4878,  4.2343, -2.1773, -2.1252,\n",
       "                       0.9760, -2.3800, -0.9582, -2.3456, -1.4426, -1.2736, -3.4976, -0.2239,\n",
       "                      -3.7606, -2.0805, -0.4835, -4.5682,  6.2729, -1.2930, -0.7157, -2.3036,\n",
       "                      -0.3074,  2.4543,  4.0207,  1.5440, -0.5729,  2.1492, -3.3048,  1.9494,\n",
       "                      -0.6815, -0.6238, -5.6369, -3.1056,  2.0838,  5.9696,  1.9853, -4.4700,\n",
       "                      -4.5291, -2.9517,  0.8080,  3.7088, -2.0645, -5.6589, -2.4057, -3.8915,\n",
       "                      -1.9419, -4.8793,  7.6671, -0.0778,  2.1264, -1.3696,  1.3952, -0.7824,\n",
       "                      -6.8134,  1.2407, -0.7441,  1.9471,  0.4775, -0.6374,  1.2630,  0.4389,\n",
       "                      -1.7671,  3.7186,  4.2855, -3.8845, -0.8633, -0.2663,  0.2673, -2.9362,\n",
       "                      -2.4175,  3.2293, -0.7193,  0.4799])),\n",
       "             ('BN1.running_var',\n",
       "              tensor([ 2.2382,  3.3967,  8.4070,  2.3787,  3.0603,  5.2277,  4.1396,  3.1884,\n",
       "                       1.9596,  2.3631,  2.0656,  2.8106,  1.3782,  7.2797,  2.5201,  1.8638,\n",
       "                       1.5938,  9.7557,  2.1029,  6.5550,  2.0789,  5.6674,  3.4186,  3.8702,\n",
       "                       2.7269,  7.1297,  9.8493,  1.4105,  6.8759,  4.4081,  4.1501,  6.0596,\n",
       "                       4.0170,  1.5069,  7.1072,  2.2372,  1.3331,  2.0394,  2.4093,  5.8780,\n",
       "                       1.3652,  1.3140,  7.8034,  5.0420,  9.3355,  7.5503,  7.6611,  2.0474,\n",
       "                       3.3841,  4.8057,  1.7333,  2.0877,  4.6825,  1.2900,  4.3151,  2.0341,\n",
       "                       5.6446, 10.1874,  1.9789,  4.4283,  2.1992,  2.5243,  1.6029,  7.9171,\n",
       "                       2.3581,  1.7570,  1.7197,  7.7993,  1.6090,  4.5349,  1.7113,  5.0447,\n",
       "                       6.5255,  2.2700,  1.6716,  2.1338,  4.4338, 10.1256,  1.3683,  5.1221,\n",
       "                       5.7631,  3.5706,  1.5244,  4.1581,  1.4341,  2.7863,  6.4900,  2.1741,\n",
       "                       3.3602,  2.2478,  2.0641,  5.2361,  8.7926,  2.7534,  7.8190,  5.7077,\n",
       "                       1.9258,  1.3457,  9.3473,  3.8306,  7.8880,  4.2809,  3.4637,  4.6543,\n",
       "                       1.5675,  3.8936,  1.5971,  3.1732,  9.5046,  1.1623,  6.2999,  7.4954,\n",
       "                       6.8875,  6.1101,  9.8608,  4.1850,  6.4214,  1.2685,  2.0822,  8.4090,\n",
       "                       3.5342,  4.3721,  1.9739,  2.4475,  3.3617,  4.9155,  2.2107,  1.8766,\n",
       "                       3.3337,  2.3356,  3.7899,  3.7001,  2.5264,  1.6571,  5.7877,  5.7120,\n",
       "                       6.2196,  6.2587,  6.1570,  1.0972,  1.8779,  1.8221,  5.7761,  8.4200,\n",
       "                       3.1002,  2.3783,  6.9021,  5.2975,  2.5550,  8.0699,  4.0296,  1.9789,\n",
       "                       3.2925,  1.8159,  2.6550,  2.7576,  2.7668,  1.8900,  1.1360,  5.9685,\n",
       "                       2.9519,  1.7728,  2.9107,  5.3335,  1.7616,  7.0654,  5.3659,  1.1195,\n",
       "                       2.1015,  1.8985,  1.2934,  2.2107,  6.6221,  2.6397,  5.9253,  1.7395,\n",
       "                       4.6190,  7.1150,  9.6536,  3.2470,  1.2306,  2.2047,  3.0932,  1.2387,\n",
       "                       3.5462,  2.6421,  6.4600,  3.5153,  1.2074,  6.4682,  2.3192,  6.2414,\n",
       "                       2.2822,  7.4383,  2.5456,  2.9268,  1.7976,  5.0380,  5.7857,  1.3564,\n",
       "                       4.5810,  2.0948,  2.3465,  8.3160,  4.8371,  4.9352,  1.2667,  2.4629,\n",
       "                       1.7764,  5.6587,  1.5928,  2.2543,  9.1639,  5.5451,  3.6364,  2.8944,\n",
       "                       3.0206,  3.8281,  1.0258,  2.4315,  0.8220,  1.3015,  2.5848,  1.4386,\n",
       "                       1.7132,  3.8146,  5.0617,  1.2605,  5.7057,  3.6195,  6.7354,  4.6675,\n",
       "                       5.6907,  2.5254,  3.1541,  7.5251,  5.9649,  2.8033,  3.7700,  2.3787,\n",
       "                       2.4027,  1.9754,  5.7814,  2.0936,  2.7328,  1.8846,  1.3293,  1.5510,\n",
       "                       1.6669,  3.6469,  1.7476,  8.2900,  2.8534,  3.3111,  2.2607,  3.1920,\n",
       "                       1.8643,  3.4613,  8.1835,  5.0791,  2.7287,  2.5394,  5.8055,  2.7130,\n",
       "                       1.5072,  2.3190,  3.3537,  1.9217,  1.1189,  6.4566,  7.3944,  1.9008,\n",
       "                       6.8843,  8.6913,  2.1740,  1.1792,  1.8685,  1.9510,  5.7954,  4.2058,\n",
       "                       5.7554,  3.9335,  2.1608,  8.9828,  5.0513,  1.4623,  1.9941,  4.4615,\n",
       "                       1.4335,  1.3043,  1.3748,  5.6515,  3.8296,  6.1892,  4.3425,  2.3770,\n",
       "                       1.3169,  4.1034,  2.4162,  2.2478,  7.6056,  2.4304,  3.4959,  2.1297,\n",
       "                       4.1137,  1.2636,  2.6368,  3.3675,  3.8374,  2.4790,  5.0388,  6.2849,\n",
       "                       7.0011,  2.2314,  2.3333,  2.8246,  2.4683,  7.3642,  2.0191, 10.1353,\n",
       "                       7.1327,  2.1526,  4.3779,  7.7233,  4.1517,  5.1879,  8.0707,  1.9465,\n",
       "                       2.2762,  2.7476,  8.9014,  1.6154,  1.4303,  6.8365,  2.3909,  1.8317,\n",
       "                       5.5554,  5.9344,  3.2884,  3.3637,  2.8866,  4.5125,  1.6042,  2.1498,\n",
       "                       7.5918,  2.7623,  3.1023,  3.4492,  1.6270,  2.7819,  1.2862,  2.6739,\n",
       "                       5.9802,  2.3497,  2.3833,  8.5263,  6.3769,  1.1584,  3.8938,  1.0380,\n",
       "                       2.2702,  6.8247,  3.3947,  1.5931,  4.3569,  2.7408,  0.7868,  1.4006,\n",
       "                       2.3355,  1.9238,  1.8514,  5.8262,  1.7539,  6.8736,  6.9907,  2.1407,\n",
       "                       1.3705,  1.9355,  2.5890,  2.3274,  2.0608,  1.5349,  1.5820,  0.8235,\n",
       "                       6.4290,  5.8300,  2.6182,  2.9037,  4.0934,  1.5557,  6.1690,  1.7318,\n",
       "                       7.3833,  2.9021,  3.6973,  2.8535,  1.4238,  1.8092,  4.5866,  1.8472,\n",
       "                       3.4693,  3.5104,  7.5223,  1.3871,  1.8545,  2.6718,  1.4938,  3.7462,\n",
       "                       4.2266,  3.0286,  5.0062,  4.4816,  3.4057,  4.7341,  5.2033,  2.8345,\n",
       "                       2.9404,  2.4946,  1.1337,  4.8851,  2.7952,  1.4048,  6.1283,  2.4990,\n",
       "                       2.9191,  1.4627,  1.8793,  2.3881,  3.6998,  2.0737,  4.8572,  2.9913,\n",
       "                       1.2902,  1.9500,  2.7186,  9.8297,  3.5641,  3.3761,  8.5700,  4.0435,\n",
       "                       3.5282,  6.9027,  2.5490,  1.9397,  4.4158,  3.6700,  3.1746,  9.0040,\n",
       "                       3.4972,  2.2273,  3.5470,  1.1034,  1.6874,  1.3157,  6.7604,  1.6561,\n",
       "                       3.7193,  6.1470,  7.1413,  4.2201,  2.7279,  7.4462,  3.3635,  6.7557,\n",
       "                       2.1535,  4.3774,  5.2748,  4.6793, 10.1812,  4.9753,  9.8430,  9.2847,\n",
       "                       1.8496,  2.0310,  3.9477,  3.3743,  2.3240,  0.8771,  2.1866,  1.4501,\n",
       "                       4.2008,  2.0392,  6.5246,  4.3170,  3.3155,  4.0749,  2.3995,  1.0712,\n",
       "                       6.7112,  2.7654,  3.3549,  3.7935,  1.3210,  3.5612,  1.0010,  6.5859,\n",
       "                       1.5901,  2.8709,  1.8058,  2.0255])),\n",
       "             ('BN1.num_batches_tracked', tensor(1200)),\n",
       "             ('enc_2.weight',\n",
       "              tensor([[ 0.0496,  0.0029,  0.0058,  ...,  0.0019,  0.0376,  0.0110],\n",
       "                      [ 0.0142,  0.0465, -0.0299,  ..., -0.0091, -0.0417, -0.0047],\n",
       "                      [-0.0194, -0.0277,  0.0362,  ...,  0.0318,  0.0054,  0.0316],\n",
       "                      ...,\n",
       "                      [-0.0465,  0.0252,  0.0446,  ...,  0.0104,  0.0264,  0.0269],\n",
       "                      [ 0.0472, -0.0025, -0.0031,  ..., -0.0488, -0.0432, -0.0034],\n",
       "                      [ 0.0340,  0.0426,  0.0315,  ...,  0.0201, -0.0306, -0.0061]])),\n",
       "             ('enc_2.bias',\n",
       "              tensor([-1.4415e-02,  2.1237e-02,  4.1713e-02, -2.4895e-02,  1.8002e-02,\n",
       "                       1.4994e-02, -1.9784e-02, -1.5067e-02,  3.7294e-02,  2.4813e-02,\n",
       "                       3.6349e-02, -2.9194e-02, -3.5121e-02, -1.7502e-03, -1.6131e-02,\n",
       "                       4.3338e-03,  1.0765e-02, -2.5112e-02, -2.5538e-02,  5.4832e-03,\n",
       "                       7.5228e-03,  1.9223e-02,  2.7629e-02, -3.6453e-02, -3.4665e-02,\n",
       "                      -4.4058e-02, -2.3226e-02, -3.5929e-02,  1.9177e-02,  3.0235e-02,\n",
       "                      -9.5448e-03,  3.1309e-02, -4.1024e-02,  4.3089e-02,  5.7403e-03,\n",
       "                      -3.6617e-02,  2.2528e-02,  2.1797e-02,  2.8683e-02, -7.0661e-03,\n",
       "                      -3.2766e-02, -4.0858e-02,  3.6133e-03, -2.4872e-03, -4.2915e-02,\n",
       "                      -2.5152e-03, -2.1488e-02,  3.7499e-02, -1.6773e-02,  2.6637e-02,\n",
       "                       4.0861e-02,  4.0212e-02, -2.2397e-02, -1.1981e-02,  1.9558e-02,\n",
       "                      -1.3828e-02,  3.5424e-02, -3.8781e-02,  4.1341e-02,  3.2908e-02,\n",
       "                       1.7561e-02, -4.6601e-04, -1.3778e-02, -3.9510e-02, -2.9558e-02,\n",
       "                      -4.3020e-02, -1.2132e-02,  1.2315e-02,  5.7874e-03, -1.9374e-02,\n",
       "                      -1.4296e-02, -3.5643e-02, -2.6873e-02,  1.5092e-02, -3.9592e-02,\n",
       "                       1.1342e-02,  4.2495e-02,  4.6721e-03,  3.0560e-02, -1.2839e-02,\n",
       "                       2.3922e-02,  1.0254e-02,  4.3404e-02, -1.1612e-02,  3.6173e-02,\n",
       "                      -4.8305e-03, -4.0752e-03,  2.9112e-03,  4.0391e-02,  3.7892e-02,\n",
       "                       1.5999e-02,  1.6037e-02, -3.8050e-03, -4.2223e-02, -2.4316e-02,\n",
       "                      -1.1172e-02,  4.1963e-02, -3.4210e-02,  2.7876e-02,  6.7103e-03,\n",
       "                       3.6222e-02, -7.8014e-03,  1.9732e-02, -7.9437e-03,  4.3204e-02,\n",
       "                      -7.3169e-03,  4.1011e-02, -3.6669e-02, -3.6881e-03, -1.7394e-02,\n",
       "                      -6.7814e-03,  3.8365e-02,  2.7748e-02, -1.4670e-02,  2.8067e-02,\n",
       "                      -2.0619e-02, -8.5292e-03,  4.3877e-02, -1.9533e-02, -1.7361e-02,\n",
       "                       1.8423e-02, -3.9086e-02,  4.1158e-02, -4.0712e-02,  6.3145e-03,\n",
       "                       6.5629e-03,  1.5921e-02,  4.4657e-02, -2.5374e-02, -3.9158e-02,\n",
       "                      -1.1099e-02, -2.1821e-03,  5.2003e-03,  4.2068e-02, -2.6948e-02,\n",
       "                       3.9366e-02, -2.9638e-02,  2.0921e-02,  3.4274e-02, -3.1383e-02,\n",
       "                       1.3150e-02, -2.6220e-02, -2.2832e-02, -3.3236e-02,  3.7429e-02,\n",
       "                       1.7403e-02, -2.4122e-02, -4.0989e-02, -8.7317e-03,  4.4876e-03,\n",
       "                       3.5746e-03, -3.7170e-02,  1.7879e-02,  4.0010e-02, -3.7849e-03,\n",
       "                       8.2206e-03, -1.2298e-02,  2.4506e-03, -2.5047e-02, -4.3532e-02,\n",
       "                       6.4174e-03,  3.9524e-02,  2.8575e-02,  4.3592e-03, -3.2055e-02,\n",
       "                       3.5451e-02, -2.5202e-02, -2.7366e-02, -3.1647e-02,  2.4058e-02,\n",
       "                       4.3006e-02,  4.4619e-02, -3.6428e-02,  1.5686e-02,  2.5108e-02,\n",
       "                       2.6930e-02,  1.7282e-02,  4.1741e-02, -8.0513e-03,  1.9061e-02,\n",
       "                       5.3967e-04,  6.1333e-03,  2.0775e-02, -4.1270e-02,  1.7013e-02,\n",
       "                       2.0807e-02,  1.6876e-02, -2.8935e-02, -1.9259e-02, -1.0350e-02,\n",
       "                       1.6391e-02, -3.4055e-02,  3.9899e-02,  9.3231e-03,  4.2639e-02,\n",
       "                       3.2701e-02, -3.4577e-02, -2.7119e-02, -3.9109e-02,  3.9363e-02,\n",
       "                      -7.0014e-03,  2.1955e-02, -2.0287e-02,  2.5566e-02, -3.7797e-02,\n",
       "                      -3.1782e-02,  3.1412e-02, -1.0414e-02,  1.7646e-02,  1.8625e-02,\n",
       "                      -5.7430e-03, -3.8321e-02, -3.3297e-02, -1.2245e-02, -3.2138e-02,\n",
       "                       3.2433e-03, -1.0884e-02, -1.8021e-03, -1.8036e-02,  1.7081e-02,\n",
       "                       3.4808e-02,  9.7616e-03,  5.6574e-03, -2.7521e-02, -1.6337e-02,\n",
       "                       2.5759e-02,  6.4862e-03, -8.8592e-03, -1.2567e-02,  4.2656e-02,\n",
       "                       3.6268e-02,  2.8451e-02, -1.4828e-02, -2.1907e-02,  1.8924e-03,\n",
       "                      -2.1310e-02,  3.2843e-02, -1.8945e-02, -2.9218e-02, -6.9950e-03,\n",
       "                       1.3022e-02, -1.5872e-02, -3.6315e-02, -4.1302e-02,  2.3974e-03,\n",
       "                      -2.3124e-02, -1.1111e-02, -2.6781e-02,  4.1501e-02,  2.2533e-02,\n",
       "                       3.6563e-02, -1.1316e-03, -7.0598e-03, -1.3765e-02, -3.3357e-03,\n",
       "                       3.0916e-02, -1.8856e-02,  1.8972e-02, -2.2532e-02,  1.1247e-02,\n",
       "                       3.8074e-02,  1.1514e-03, -1.9682e-02, -4.1639e-02,  3.1026e-02,\n",
       "                       4.1992e-03, -3.8802e-02,  2.8207e-02, -3.3317e-02,  4.1761e-02,\n",
       "                      -3.7307e-03, -5.6650e-03,  2.1278e-02, -2.3303e-02, -2.4102e-02,\n",
       "                       2.4353e-02,  7.9178e-03, -3.4180e-02, -3.5188e-02, -5.8437e-03,\n",
       "                       3.9321e-02, -1.3787e-02, -3.0068e-02,  8.0430e-03, -2.3555e-02,\n",
       "                      -3.3995e-03, -1.4745e-02,  3.2911e-02, -4.0362e-02,  1.0469e-02,\n",
       "                       4.4621e-02, -2.0605e-02, -1.4083e-02, -3.4383e-02, -3.3388e-02,\n",
       "                      -7.1844e-03, -3.6696e-02,  4.4692e-02, -1.5410e-02, -4.4658e-02,\n",
       "                      -2.1364e-05,  3.8945e-02,  3.8788e-02,  1.1766e-02, -8.9790e-03,\n",
       "                      -3.5772e-03,  4.1205e-03, -1.0013e-02, -3.4741e-02, -7.7976e-03,\n",
       "                       8.7413e-03, -2.3350e-02, -9.2583e-03, -2.2701e-02,  2.3297e-02,\n",
       "                       9.2139e-03,  2.3435e-04, -3.4573e-02, -1.8971e-02, -3.3164e-02,\n",
       "                      -4.0125e-02, -4.3776e-02, -3.1811e-02,  2.1441e-02, -7.8776e-03,\n",
       "                      -4.8007e-03,  3.3528e-02, -3.6921e-02,  1.1133e-02, -1.7597e-02,\n",
       "                       3.1832e-02,  3.1509e-02, -3.1277e-02, -3.0754e-02,  2.2014e-02,\n",
       "                      -1.5139e-02, -3.7890e-02, -1.1289e-02, -1.3051e-02, -1.7091e-02,\n",
       "                      -4.4241e-02,  3.1276e-02,  2.8659e-02, -2.0698e-02, -7.5077e-03,\n",
       "                      -3.1738e-02,  2.3269e-02,  2.2096e-02,  2.3669e-02,  3.2447e-02,\n",
       "                       4.0491e-02, -2.0421e-02,  2.9816e-02,  7.9027e-03,  3.4131e-02,\n",
       "                       1.3215e-02,  1.0731e-02, -4.4493e-02, -1.9766e-02, -1.3072e-02,\n",
       "                       3.8418e-02, -3.7101e-03, -5.0605e-03, -1.9688e-02,  2.5536e-02,\n",
       "                       4.2249e-02, -2.8094e-02, -4.6251e-04, -4.4343e-02,  2.4838e-02,\n",
       "                      -4.3737e-03,  4.2095e-02,  1.1378e-02,  5.9493e-05, -4.4435e-02,\n",
       "                      -1.1926e-02, -1.7130e-02,  1.9088e-02,  2.3806e-02, -3.9683e-02,\n",
       "                       1.8180e-02,  9.9165e-03,  1.8542e-02,  4.8329e-03, -2.4092e-02,\n",
       "                       1.8767e-02, -7.2382e-04, -2.2509e-02, -3.4196e-02,  1.1702e-02,\n",
       "                       1.5822e-02,  3.6145e-02, -3.1682e-02,  4.3357e-02, -2.2254e-02,\n",
       "                       2.4123e-02, -6.7620e-03,  2.0805e-02,  2.1398e-02,  3.7187e-02,\n",
       "                       4.3279e-02, -4.3915e-02, -4.1871e-02,  3.5428e-02,  4.2564e-03,\n",
       "                       3.4890e-02,  1.4986e-02, -1.3816e-02,  6.3090e-03, -4.1951e-02,\n",
       "                      -1.4853e-02, -1.6693e-02, -2.2332e-02,  2.8950e-02, -3.4671e-02,\n",
       "                      -3.6294e-02,  3.8835e-02,  1.1379e-02, -3.0765e-02,  1.4053e-02,\n",
       "                      -1.6058e-02, -4.2057e-02, -4.3282e-02,  2.3078e-02, -3.1748e-02,\n",
       "                       1.6232e-02, -2.0773e-02,  6.5895e-03, -2.6015e-02,  2.4703e-03,\n",
       "                      -3.4205e-02, -1.1409e-02,  2.1215e-02,  2.2030e-03, -8.1913e-03,\n",
       "                       3.9717e-02, -4.3835e-02, -3.3600e-02, -2.9865e-02,  7.5588e-03,\n",
       "                      -3.5312e-02,  3.6181e-02, -4.2525e-02,  3.3706e-02, -1.2273e-02,\n",
       "                      -1.9980e-02, -1.6641e-02, -3.8040e-03,  3.9886e-02,  3.9265e-02,\n",
       "                       8.0187e-03,  3.4123e-02,  1.8446e-02, -1.6917e-02,  2.7187e-02,\n",
       "                      -4.2213e-02,  2.5746e-03,  4.4594e-02,  6.4376e-03, -2.9607e-02,\n",
       "                       3.6332e-02, -4.3979e-02,  4.3028e-02,  2.8780e-02,  3.6662e-02,\n",
       "                      -3.5816e-02, -2.9943e-02,  3.2509e-02, -3.3745e-02,  1.0036e-02,\n",
       "                       2.1378e-02,  3.3151e-02,  7.4778e-03, -2.3044e-02,  4.2530e-02,\n",
       "                      -7.1231e-03, -1.2006e-02,  1.4346e-02, -4.0081e-02, -1.6138e-02,\n",
       "                      -3.0233e-02, -1.9958e-02, -2.5964e-02,  4.0005e-02, -1.4492e-02,\n",
       "                      -2.0096e-02,  3.0087e-03,  6.2154e-04, -3.5184e-02, -3.2905e-02,\n",
       "                       3.5930e-02, -4.2625e-02,  4.8977e-03, -7.8253e-03, -4.4207e-02,\n",
       "                      -2.2771e-03,  1.5649e-04, -1.1881e-02,  1.8823e-02,  4.4615e-03])),\n",
       "             ('BN2.weight',\n",
       "              tensor([1.0101, 1.0382, 1.0111, 0.9917, 1.0031, 0.9843, 1.0014, 1.0035, 0.9931,\n",
       "                      0.9913, 1.0032, 0.9900, 1.0037, 1.0062, 0.9883, 0.9927, 1.0006, 1.0047,\n",
       "                      0.9839, 1.0070, 1.0333, 1.0146, 0.9890, 0.9980, 0.9984, 0.9941, 1.0746,\n",
       "                      1.0335, 1.0050, 1.0017, 1.0016, 1.0040, 0.9876, 0.9980, 0.9993, 0.9925,\n",
       "                      0.9925, 0.9774, 1.0034, 1.0006, 0.9982, 0.9928, 0.9942, 1.0121, 0.9960,\n",
       "                      0.9847, 1.0515, 0.9847, 0.9829, 0.9935, 0.9983, 1.0253, 0.9937, 0.9778,\n",
       "                      0.9762, 1.0114, 0.9998, 0.9769, 1.0177, 1.0060, 1.0053, 1.0013, 0.9931,\n",
       "                      0.9943, 0.9899, 0.9931, 0.9962, 0.9850, 0.9874, 0.9788, 0.9857, 0.9971,\n",
       "                      1.0133, 0.9967, 1.0120, 0.9859, 0.9995, 0.9543, 1.0054, 0.9835, 1.0028,\n",
       "                      0.9902, 0.9978, 1.0202, 0.9739, 0.9988, 1.0011, 1.0055, 0.9971, 1.0215,\n",
       "                      1.0045, 1.0061, 0.9935, 1.0010, 0.9987, 1.0041, 1.0029, 1.0053, 1.0202,\n",
       "                      1.0193, 0.9999, 1.0013, 1.0216, 1.0040, 1.0078, 0.9838, 0.9960, 1.0154,\n",
       "                      0.9896, 1.0054, 1.0023, 0.9669, 1.0091, 1.0018, 0.9860, 1.0180, 1.0124,\n",
       "                      1.0142, 1.0032, 1.0006, 0.9864, 0.9985, 1.0128, 1.0057, 0.9837, 0.9893,\n",
       "                      0.9904, 1.0011, 1.0215, 1.0065, 1.0012, 0.9982, 0.9760, 0.9903, 0.9846,\n",
       "                      1.0003, 1.0016, 1.0115, 0.9890, 1.0073, 1.0072, 1.0002, 0.9885, 1.0063,\n",
       "                      1.0050, 0.9944, 1.0023, 1.0099, 1.0040, 1.0021, 0.9882, 0.9968, 0.9988,\n",
       "                      0.9891, 0.9844, 1.0068, 1.0020, 1.0055, 0.9960, 0.9800, 0.9910, 0.9835,\n",
       "                      1.0205, 0.9887, 1.0053, 1.0138, 1.0116, 0.9916, 0.9994, 1.0118, 0.9938,\n",
       "                      1.0084, 1.0086, 1.0002, 1.0043, 1.0085, 0.9995, 0.9782, 0.9786, 1.0125,\n",
       "                      1.0066, 0.9873, 0.9889, 0.9987, 0.9955, 0.9756, 1.0089, 1.0058, 0.9863,\n",
       "                      0.9923, 0.9857, 0.9888, 0.9982, 1.0259, 0.9995, 0.9983, 0.9853, 0.9975,\n",
       "                      1.0106, 0.9907, 0.9980, 1.0088, 1.0128, 1.0520, 0.9953, 0.9973, 1.0300,\n",
       "                      1.0094, 1.0372, 1.0065, 1.0024, 0.9930, 1.0064, 1.0119, 0.9924, 1.0001,\n",
       "                      0.9880, 1.0093, 0.9843, 0.9833, 1.0253, 0.9990, 0.9911, 1.0131, 0.9945,\n",
       "                      0.9969, 0.9992, 0.9873, 0.9855, 1.0073, 0.9817, 0.9755, 1.0094, 0.9984,\n",
       "                      1.0012, 1.0110, 0.9934, 0.9865, 1.0336, 0.9907, 1.0063, 0.9940, 0.9748,\n",
       "                      0.9948, 0.9932, 1.0238, 1.0080, 0.9886, 1.0100, 0.9852, 0.9885, 0.9948,\n",
       "                      1.0453, 1.0046, 0.9991, 1.0442, 1.0000, 0.9969, 1.0106, 1.0019, 0.9961,\n",
       "                      1.0194, 0.9935, 0.9927, 0.9975, 0.9927, 1.0025, 0.9828, 0.9907, 0.9941,\n",
       "                      0.9885, 1.0059, 0.9909, 1.0027, 0.9988, 1.0079, 1.0077, 0.9905, 0.9999,\n",
       "                      1.0286, 0.9893, 1.0012, 0.9949, 0.9952, 0.9984, 1.0027, 1.0684, 1.0289,\n",
       "                      0.9966, 0.9940, 0.9815, 1.0393, 1.0014, 0.9973, 0.9916, 0.9950, 1.0097,\n",
       "                      1.0696, 0.9915, 0.9952, 0.9996, 0.9988, 0.9878, 0.9809, 1.0166, 1.0053,\n",
       "                      1.0090, 1.0034, 0.9978, 1.0027, 0.9897, 0.9928, 1.0005, 1.0118, 1.0017,\n",
       "                      1.0331, 0.9995, 0.9946, 0.9950, 0.9976, 1.0076, 1.0251, 0.9986, 0.9966,\n",
       "                      0.9996, 0.9885, 1.0168, 0.9847, 1.0085, 0.9968, 1.0039, 0.9946, 0.9809,\n",
       "                      1.0114, 1.0200, 0.9864, 1.0064, 1.0060, 0.9963, 0.9908, 0.9955, 0.9906,\n",
       "                      1.0103, 0.9779, 0.9917, 0.9947, 0.9930, 0.9975, 1.0202, 1.0247, 0.9964,\n",
       "                      0.9891, 1.0078, 1.0091, 1.0040, 1.0007, 1.0107, 0.9707, 1.0006, 1.0058,\n",
       "                      0.9876, 0.9871, 0.9884, 1.0076, 1.0043, 1.0128, 1.0005, 1.0284, 0.9564,\n",
       "                      1.0115, 1.0106, 1.0026, 1.0175, 1.0081, 1.0486, 0.9852, 0.9785, 1.0062,\n",
       "                      0.9861, 1.0040, 0.9858, 1.0060, 1.0034, 1.0023, 0.9919, 0.9848, 0.9762,\n",
       "                      0.9938, 0.9988, 1.0026, 1.0003, 0.9902, 1.0175, 0.9943, 0.9834, 0.9948,\n",
       "                      1.0076, 1.0035, 0.9962, 0.9988, 0.9862, 1.0055, 1.0052, 0.9963, 1.0149,\n",
       "                      1.0100, 0.9981, 0.9723, 1.0032, 0.9971, 1.0033, 0.9977, 0.9928, 0.9978,\n",
       "                      0.9958, 1.0108, 0.9993, 0.9817, 1.0553, 0.9738, 0.9899, 0.9953, 1.0129,\n",
       "                      0.9947, 1.0045, 0.9917, 0.9981, 1.0148, 1.0509, 0.9972, 1.0263, 1.0521,\n",
       "                      1.0083, 0.9880, 0.9734, 0.9951, 1.0102, 1.0175, 0.9902, 0.9892, 0.9941,\n",
       "                      0.9906, 1.0157, 0.9994, 0.9547, 0.9918, 0.9967, 0.9976, 1.0057, 0.9958,\n",
       "                      0.9866, 0.9981, 1.0019, 0.9938, 1.0053, 0.9779, 0.9961, 1.0223, 0.9915,\n",
       "                      1.0064, 0.9983, 1.0004, 1.0078, 0.9856, 0.9971, 0.9955, 1.0093, 0.9962,\n",
       "                      1.0054, 1.0030, 1.0958, 1.0129, 1.0038, 0.9879, 1.0131, 0.9976, 1.0177,\n",
       "                      1.0081, 1.0033, 0.9806, 0.9830, 1.0006, 0.9906, 1.0389, 0.9824, 0.9990,\n",
       "                      0.9875, 0.9830, 0.9794, 0.9974, 0.9741, 0.9904, 1.0172, 0.9911, 0.9767,\n",
       "                      1.0027, 1.0101, 1.0059, 1.0249, 1.0108])),\n",
       "             ('BN2.bias',\n",
       "              tensor([ 2.0794e-02,  2.8417e-02,  4.8444e-03, -1.1467e-02, -2.6848e-03,\n",
       "                      -6.8838e-03,  8.6135e-03,  6.4370e-03, -1.0196e-02, -1.4203e-02,\n",
       "                      -4.5461e-03, -1.3066e-02, -1.3386e-02,  1.7639e-03, -1.1392e-02,\n",
       "                      -4.1762e-03,  1.2687e-03, -6.6871e-03, -9.3679e-03,  1.0226e-02,\n",
       "                       3.3943e-02,  1.7825e-02, -1.1955e-02,  3.6556e-03, -3.0189e-03,\n",
       "                       1.7288e-03,  4.9219e-02,  1.7582e-02, -1.6517e-02,  1.6300e-02,\n",
       "                      -6.5311e-03,  4.2330e-03, -1.3526e-03, -8.1618e-03,  3.3292e-02,\n",
       "                       1.0049e-02, -4.6396e-03, -2.5592e-04,  1.9004e-03, -3.9138e-03,\n",
       "                      -1.6201e-02, -9.6856e-03, -1.5620e-03,  1.9911e-02,  1.6935e-02,\n",
       "                      -1.0332e-02,  3.6671e-02,  1.3425e-02, -1.2466e-02,  9.1602e-04,\n",
       "                       6.8204e-03,  1.9810e-02, -1.5828e-02, -1.8867e-03, -9.6607e-04,\n",
       "                       8.8004e-03,  6.6250e-03, -2.3568e-02,  3.1070e-02,  9.3453e-03,\n",
       "                       1.5350e-02,  4.7394e-03,  8.0342e-03, -2.8446e-03, -1.5450e-02,\n",
       "                      -3.2046e-03, -3.7777e-03, -3.0077e-02, -3.8156e-03, -2.0378e-02,\n",
       "                       7.3694e-03, -1.0179e-03, -1.6798e-02, -6.6603e-04,  1.8450e-02,\n",
       "                      -8.0389e-03, -1.3797e-02, -3.0452e-02,  4.7592e-03,  7.5938e-03,\n",
       "                       4.7431e-03,  7.7321e-04,  8.8512e-03,  1.8145e-02, -1.6655e-02,\n",
       "                       1.5709e-02, -3.4373e-03, -9.1384e-03,  9.3572e-03,  1.6834e-02,\n",
       "                       1.4178e-02,  1.0017e-02, -2.0749e-02,  1.1288e-02, -1.9299e-02,\n",
       "                      -1.3891e-03,  5.3158e-03,  3.5765e-03,  8.6390e-03,  3.7021e-02,\n",
       "                       3.9348e-03,  2.9634e-03,  1.0233e-02, -7.3814e-03,  1.3724e-02,\n",
       "                      -7.9420e-03, -1.1613e-02,  2.6254e-02, -1.7352e-02,  2.4354e-03,\n",
       "                       2.9747e-02, -2.3840e-02, -3.7479e-03,  3.9830e-04,  5.6686e-04,\n",
       "                       1.4653e-02,  6.5726e-03,  3.4718e-02, -9.0309e-03,  1.6628e-03,\n",
       "                      -1.3417e-03, -6.9278e-03, -1.9530e-03, -1.8266e-03, -1.0821e-02,\n",
       "                       2.4580e-03, -2.9227e-02,  4.5752e-03,  4.9467e-03, -2.1456e-02,\n",
       "                       1.1483e-03, -8.1128e-03,  1.0211e-02, -7.7090e-03, -2.7789e-02,\n",
       "                       2.9084e-03,  6.3688e-03,  2.5139e-02, -1.5094e-02, -2.7144e-03,\n",
       "                      -1.5424e-02, -9.7054e-03, -5.4450e-03,  1.7025e-04,  1.3152e-02,\n",
       "                      -8.6451e-03,  1.7413e-02, -2.2674e-02,  1.4044e-02, -2.7251e-03,\n",
       "                      -1.3051e-02, -5.1167e-03, -1.7140e-02, -2.0332e-02, -5.3010e-03,\n",
       "                      -3.8119e-03,  1.8770e-02,  7.3106e-03, -1.8061e-02, -1.2321e-02,\n",
       "                      -5.1946e-03, -5.2102e-03,  3.7921e-02, -6.8874e-03,  1.9393e-02,\n",
       "                       1.6042e-02,  2.2907e-03, -1.1226e-02, -3.7075e-03,  3.0807e-02,\n",
       "                      -1.4077e-02,  9.7296e-03, -6.4037e-03, -7.9059e-03, -6.7732e-03,\n",
       "                      -5.7019e-03,  1.7450e-02, -1.1003e-02, -2.0940e-02,  2.0483e-02,\n",
       "                       8.8828e-03, -8.1309e-03, -4.2919e-03, -6.8080e-03, -3.6399e-03,\n",
       "                      -2.8980e-02,  8.1674e-03, -1.2225e-02, -2.7356e-02, -3.6475e-03,\n",
       "                      -2.0063e-02, -1.0027e-02, -6.2399e-03,  1.2520e-02,  4.0400e-03,\n",
       "                      -2.7804e-03, -1.4224e-02,  1.0821e-03,  3.5308e-03, -6.0122e-03,\n",
       "                       7.4656e-03, -5.8222e-03,  1.2939e-02,  2.8454e-02, -4.3109e-03,\n",
       "                      -9.7562e-03,  2.9108e-02,  5.0129e-03,  3.0061e-02,  1.5446e-02,\n",
       "                      -2.1234e-03,  5.8944e-04,  4.8469e-03,  2.2806e-02, -1.1614e-02,\n",
       "                      -8.8029e-03, -2.0579e-02,  1.3509e-02, -7.5485e-03, -1.4160e-02,\n",
       "                       1.8839e-02, -5.3868e-03, -3.4019e-04,  1.8592e-02, -1.8228e-02,\n",
       "                       8.7324e-04, -2.0993e-02, -2.7359e-03, -1.1276e-02, -5.0835e-03,\n",
       "                      -2.8737e-02, -2.0493e-02,  1.6810e-02,  2.5101e-02,  9.2658e-03,\n",
       "                       4.9558e-02,  5.3516e-03,  2.3525e-03,  1.5621e-02, -1.8396e-03,\n",
       "                      -1.2234e-02, -6.0174e-03, -2.3782e-02,  4.3732e-03, -1.6850e-02,\n",
       "                       1.7949e-02,  1.1219e-02, -7.3821e-03, -1.3826e-02, -6.4049e-03,\n",
       "                      -6.3980e-04,  8.6583e-03,  5.0891e-02, -3.7531e-03,  5.1846e-03,\n",
       "                       2.5617e-02, -1.2382e-02,  9.3695e-03,  2.9672e-02, -6.2743e-04,\n",
       "                       2.3498e-02,  3.4386e-02, -7.1099e-03,  4.5712e-03,  3.5147e-03,\n",
       "                      -3.7726e-02,  8.6283e-03, -3.8682e-03, -5.8540e-03, -1.0476e-02,\n",
       "                       4.9150e-03, -1.5952e-02, -1.3348e-02,  1.6393e-04, -1.5493e-03,\n",
       "                      -7.9257e-03,  3.9739e-03, -1.4565e-02,  1.6796e-02,  3.9293e-02,\n",
       "                      -1.3062e-02, -4.7496e-03, -1.1600e-02, -1.2458e-03, -1.7451e-03,\n",
       "                       7.6147e-04,  7.1432e-02,  2.6261e-02,  2.9850e-03, -5.4330e-03,\n",
       "                      -2.3544e-02,  3.4292e-02,  1.7385e-02, -1.7564e-02, -5.9934e-03,\n",
       "                      -2.2686e-02,  1.2189e-02,  9.8013e-02, -1.0856e-02,  3.6328e-03,\n",
       "                       1.8834e-03, -1.2061e-03, -7.8851e-03, -1.7413e-02,  1.9156e-02,\n",
       "                       3.5822e-03,  7.7703e-03,  3.3072e-03, -1.9787e-03,  1.1555e-02,\n",
       "                      -3.5568e-03, -1.5164e-02, -4.4704e-03,  1.1722e-02, -1.0829e-02,\n",
       "                       2.3973e-02,  4.4892e-03, -1.6078e-02, -3.4253e-03,  2.0791e-03,\n",
       "                       1.5471e-02,  1.1549e-02, -2.3904e-02,  1.5676e-03, -5.0957e-04,\n",
       "                      -1.8198e-02,  3.7923e-02, -1.5517e-02,  1.6241e-02,  1.3219e-02,\n",
       "                       6.6212e-03, -3.5105e-03, -2.3097e-02,  5.9438e-03,  6.9323e-03,\n",
       "                      -7.1576e-03,  1.9006e-02,  2.0631e-02, -5.9913e-03, -2.5714e-03,\n",
       "                      -1.8771e-02, -1.3970e-02,  1.9468e-03, -2.0575e-02, -1.0978e-02,\n",
       "                       2.5249e-03, -3.0164e-03, -5.5927e-03,  2.5510e-02,  1.3401e-02,\n",
       "                      -1.9923e-02, -1.1551e-02,  5.1122e-03, -7.5015e-03, -7.4986e-03,\n",
       "                       1.2159e-02, -4.2632e-03, -2.0326e-02, -3.4277e-02, -5.8676e-03,\n",
       "                      -2.0015e-02, -1.0008e-02,  6.4107e-03,  1.4980e-03, -2.7316e-03,\n",
       "                       1.9875e-02,  2.2761e-03,  2.6069e-02, -2.3671e-02,  6.8063e-03,\n",
       "                       6.8952e-03, -1.8973e-02,  3.3948e-02,  1.6738e-03,  7.7092e-02,\n",
       "                       1.3561e-03, -2.0899e-02,  5.9894e-03, -1.3823e-02, -1.3384e-02,\n",
       "                      -1.4574e-02,  2.2577e-02, -2.3361e-02,  5.3585e-03,  6.1480e-03,\n",
       "                      -1.0706e-02, -1.2054e-02, -1.3215e-02, -5.4065e-03,  1.5380e-03,\n",
       "                       4.3290e-03, -1.2024e-02,  1.5649e-02, -1.6258e-03, -1.0790e-02,\n",
       "                       1.7787e-02, -2.3731e-03, -1.6115e-02, -4.5620e-03, -6.5314e-03,\n",
       "                      -7.3746e-04,  2.0637e-02,  2.3777e-02,  8.7479e-03,  3.7226e-02,\n",
       "                       2.7965e-02,  6.1910e-03, -1.3198e-02, -3.5758e-03, -7.8664e-03,\n",
       "                       4.6828e-03, -3.8005e-03, -2.0052e-02,  2.9429e-02, -1.3195e-02,\n",
       "                       1.4488e-02,  5.7959e-04,  3.8516e-03,  5.9011e-02, -3.3512e-03,\n",
       "                      -1.1585e-02,  9.3004e-04,  1.6806e-02, -2.0223e-05,  1.8816e-02,\n",
       "                       6.5086e-03,  4.7242e-03,  2.8386e-02,  3.3206e-02, -1.3628e-02,\n",
       "                       4.8645e-03,  2.2341e-02,  1.4461e-02, -1.0334e-02, -3.8698e-03,\n",
       "                       1.3159e-02, -2.9716e-04, -2.0201e-03, -6.6447e-03,  2.5146e-03,\n",
       "                       1.1716e-02, -1.0186e-03,  2.7115e-02, -5.4681e-03, -1.9513e-02,\n",
       "                      -9.6477e-03, -4.8941e-03, -7.9616e-03,  2.8464e-02, -2.0239e-03,\n",
       "                       1.1415e-03,  6.8799e-03,  2.0267e-02, -1.2426e-04, -4.4952e-03,\n",
       "                      -1.5866e-02, -2.8326e-02,  5.7046e-02, -1.1203e-02,  8.1668e-03,\n",
       "                      -4.0519e-03,  4.9074e-03,  8.9629e-03, -9.0967e-03, -1.9197e-02,\n",
       "                      -2.0837e-02,  4.2753e-03,  6.6531e-03,  1.1537e-02, -5.6061e-03,\n",
       "                       8.2346e-02,  2.2418e-02, -9.1218e-04, -1.4449e-03, -1.1538e-02,\n",
       "                      -1.1628e-02,  1.1086e-02,  7.4068e-03,  8.1230e-03,  2.8101e-04,\n",
       "                      -1.9145e-02,  1.7723e-06, -3.9060e-03,  2.5754e-02, -9.5527e-03,\n",
       "                      -8.4901e-03, -4.1456e-03, -2.3814e-03, -2.0381e-02,  1.2475e-02,\n",
       "                      -3.5699e-02, -8.7922e-03,  4.1471e-04,  1.2497e-03, -2.3672e-02,\n",
       "                       2.0066e-02,  1.9169e-02,  6.3844e-03,  3.7457e-02,  1.2684e-02])),\n",
       "             ('BN2.running_mean',\n",
       "              tensor([-3.4801e-01,  5.2518e-02,  6.3859e-01,  3.2943e-03, -4.3293e-02,\n",
       "                      -5.2959e-01,  5.1000e-01, -3.5772e-01,  2.4616e-02,  5.7224e-01,\n",
       "                       8.4148e-01, -1.6417e-01,  9.0433e-01,  1.7619e-01,  5.9237e-02,\n",
       "                       1.2440e-01,  7.3338e-02,  5.4394e-02,  2.3124e-01, -1.9367e-01,\n",
       "                       1.8966e-01, -1.7074e-02,  3.6693e-01, -3.0624e-01, -3.0929e-01,\n",
       "                       1.2284e-01, -7.9994e-02,  4.9757e-01,  7.6731e-01, -2.8991e-01,\n",
       "                       1.1280e+00,  4.0459e-02,  4.3213e-02,  5.6107e-01, -4.6030e-01,\n",
       "                      -3.0236e-01, -1.6934e-01, -7.6062e-02,  1.8457e-01, -2.8012e-02,\n",
       "                       7.6986e-01, -6.9954e-02,  3.4794e-01, -3.9966e-01, -7.4298e-01,\n",
       "                       2.6131e-01, -5.8727e-01, -4.7825e-01, -2.8369e-01,  4.5811e-01,\n",
       "                      -6.1616e-01, -6.7581e-01,  3.0790e-01,  9.8877e-02,  5.3537e-02,\n",
       "                      -3.8272e-01,  1.6337e-01,  7.6097e-01, -1.8264e-01,  8.8735e-01,\n",
       "                      -7.3281e-02,  5.3988e-01, -5.1405e-02, -1.6937e-01, -1.0916e-01,\n",
       "                       1.2722e-01, -4.0514e-01,  6.9844e-01,  1.7300e-02,  3.7821e-01,\n",
       "                      -2.0213e-01,  3.8775e-02, -1.6144e-01, -2.0321e-01, -2.0178e-01,\n",
       "                       1.3377e-01,  9.6037e-01,  7.2344e-01, -1.5586e-01,  4.3994e-01,\n",
       "                       3.8377e-01,  2.5522e-01, -4.5103e-02,  7.1530e-02,  5.9042e-02,\n",
       "                      -1.1155e+00, -2.9136e-01,  7.4200e-01,  5.0475e-01,  2.3580e-01,\n",
       "                       5.1128e-02,  1.3420e-01,  1.1182e+00, -1.9376e-01,  4.5857e-01,\n",
       "                       6.5053e-01,  3.8254e-01, -5.3482e-01, -2.5592e-01,  1.9749e-01,\n",
       "                      -4.0570e-01, -1.9713e-01, -6.6293e-01,  3.0995e-01, -3.2665e-01,\n",
       "                       5.1211e-02,  2.9924e-01, -2.3858e-01, -3.4260e-01,  5.3112e-01,\n",
       "                      -5.6686e-01,  7.5207e-01,  1.5395e-01, -5.1283e-02, -4.7459e-02,\n",
       "                      -2.9910e-01,  2.3999e-02, -2.1422e-01,  4.6490e-01, -7.5139e-02,\n",
       "                      -5.1648e-01, -3.1434e-01,  3.8343e-01, -3.1078e-02,  5.4316e-01,\n",
       "                       1.3029e-01,  9.1500e-01, -4.3022e-01,  1.5914e-01,  4.3158e-01,\n",
       "                      -3.0473e-01, -2.6921e-01, -3.7448e-01,  3.9756e-02,  5.6737e-01,\n",
       "                       1.8308e-01, -1.6147e-01, -5.3331e-01,  7.2469e-01,  5.3378e-01,\n",
       "                       6.6224e-01,  9.7215e-02,  1.2141e-01,  1.0718e+00,  9.6805e-02,\n",
       "                       1.2451e-01, -5.2060e-01,  2.8849e-01, -3.0945e-01,  5.3810e-01,\n",
       "                       9.8390e-01,  8.3583e-01,  4.9247e-01,  7.3832e-01,  5.5840e-01,\n",
       "                       5.6373e-01, -4.5792e-01,  1.5174e-01,  3.7279e-01, -6.0158e-01,\n",
       "                       2.9720e-01,  8.4049e-02, -2.1349e-01,  7.1353e-01, -1.8634e-01,\n",
       "                      -5.8565e-01,  8.4497e-02, -2.5169e-01,  3.1607e-01, -1.0924e-01,\n",
       "                       2.2338e-01, -5.2695e-01,  2.4007e-01,  7.1665e-01,  7.0473e-01,\n",
       "                       9.0162e-01, -3.4919e-01,  4.3653e-01,  3.2643e-02,  1.1165e-01,\n",
       "                       1.4860e-01, -1.6525e-01,  6.0296e-02,  4.0557e-01,  2.0656e-01,\n",
       "                       5.8133e-01,  3.4219e-01, -1.9109e-01,  5.1624e-01,  1.3726e-01,\n",
       "                      -2.1570e-01, -2.1409e-01,  6.0343e-01,  5.0163e-01,  3.5037e-01,\n",
       "                      -9.0069e-02,  5.1542e-01, -7.3889e-01, -3.7632e-01,  6.5596e-02,\n",
       "                      -6.9781e-03,  2.0174e-01,  1.2114e-01, -6.9924e-02,  1.6071e-01,\n",
       "                       6.5797e-01,  6.6239e-02,  7.8766e-01, -5.1108e-01, -2.6363e-01,\n",
       "                      -4.8240e-02, -1.4989e-01, -3.9548e-01, -8.5857e-01, -2.3338e-01,\n",
       "                       5.3322e-01,  4.3455e-01, -1.5223e-01, -3.9000e-01, -3.7973e-01,\n",
       "                      -3.7082e-01,  3.2123e-01, -9.2608e-02, -1.3266e-01,  3.8518e-01,\n",
       "                      -1.3669e-01,  4.4535e-01, -5.3220e-01,  2.9427e-01,  8.0739e-01,\n",
       "                       4.2246e-01,  7.0801e-01,  2.1827e-01, -2.2119e-01, -8.6380e-02,\n",
       "                       2.2410e-01, -3.5905e-01, -2.0856e-01, -1.4611e-01,  7.5688e-02,\n",
       "                       7.8462e-01,  8.4821e-01,  4.9365e-01, -9.0258e-02,  6.1480e-01,\n",
       "                       2.8184e-01, -2.2845e-01,  1.1111e-01,  5.1824e-01, -2.5249e-01,\n",
       "                      -5.5458e-01, -3.0121e-01, -5.7579e-02,  1.6643e-02,  2.0491e-01,\n",
       "                       3.7181e-01,  2.3610e-01, -5.2478e-01, -1.3164e-01, -1.2269e-03,\n",
       "                      -6.4125e-02, -3.7082e-01,  5.2318e-01,  8.3215e-03, -5.3598e-01,\n",
       "                       7.6528e-01, -7.3585e-01,  1.4601e-01,  4.3289e-01, -4.7496e-02,\n",
       "                      -4.2863e-01,  8.7089e-01,  3.3840e-02, -5.9720e-01, -4.9197e-03,\n",
       "                       1.0560e+00, -2.6881e-01, -2.6518e-01, -5.5340e-01, -6.9960e-01,\n",
       "                       4.1521e-01,  4.7227e-01,  2.7294e-01,  7.3234e-01, -4.8602e-01,\n",
       "                      -1.7654e-01, -1.2730e-01, -6.7742e-02, -1.0944e-01,  3.4063e-01,\n",
       "                       3.1544e-01,  4.2005e-03, -2.9033e-01,  4.6402e-01, -2.2186e-01,\n",
       "                       1.6662e-01, -2.6868e-02, -1.7802e-01,  4.1417e-01, -5.6558e-01,\n",
       "                      -6.0421e-01,  9.9141e-02, -7.8672e-02,  4.9119e-01,  5.7904e-01,\n",
       "                       1.9762e-01, -2.8784e-01,  2.3793e-01,  9.1996e-02,  2.5949e-01,\n",
       "                       8.7683e-01,  9.5427e-02,  3.7722e-01,  3.7789e-02,  4.2968e-01,\n",
       "                      -4.8141e-02, -2.5223e-01,  9.4063e-01,  3.7429e-01, -6.5861e-03,\n",
       "                      -8.1889e-01,  1.2198e-01,  8.8539e-01, -7.2480e-02, -3.4755e-01,\n",
       "                      -2.9526e-01, -2.0971e-02,  1.3167e-01,  4.5228e-01, -9.8960e-01,\n",
       "                       5.3274e-01, -4.9309e-01,  7.7724e-01, -2.0630e-01,  4.3296e-01,\n",
       "                      -4.0208e-01, -2.0215e-01, -1.7751e-01,  3.0793e-01, -2.8328e-01,\n",
       "                       3.0994e-01, -2.7967e-01,  7.9936e-02,  2.7434e-01, -2.3251e-01,\n",
       "                      -1.1660e-01, -1.5809e-01,  3.8847e-01,  5.2203e-02, -1.8643e-01,\n",
       "                       3.8834e-01, -8.6151e-01,  3.5188e-01, -6.7617e-02, -9.7315e-02,\n",
       "                       7.9560e-01,  4.6096e-01,  2.1012e-01,  2.7979e-01,  7.5647e-01,\n",
       "                       2.4494e-01, -9.9140e-02,  5.1148e-01,  2.3653e-01,  4.6749e-01,\n",
       "                       9.1025e-02, -3.7006e-01, -2.9508e-01,  1.6804e-01,  2.5973e-02,\n",
       "                      -6.4536e-02,  6.5902e-01, -1.2140e-01, -3.0791e-01, -6.0229e-01,\n",
       "                       9.1647e-02,  4.6676e-01,  5.0189e-01,  4.4524e-01,  6.2314e-01,\n",
       "                       1.4324e-01, -4.2427e-01,  4.3412e-01, -2.5690e-01, -2.3322e-01,\n",
       "                      -3.3796e-01, -1.3651e-01,  9.9815e-01,  4.8943e-01, -1.2737e-01,\n",
       "                       6.4970e-01, -4.2843e-02,  5.9102e-02, -3.0640e-01,  2.0075e-01,\n",
       "                      -2.3226e-01, -1.7899e-01,  1.7782e-01, -1.1073e-01,  4.4431e-01,\n",
       "                      -2.4041e-01, -9.6569e-02,  1.5926e-01, -6.0619e-01, -3.5659e-01,\n",
       "                      -1.6039e-01,  4.2394e-01,  7.3657e-01, -3.9895e-01,  2.1016e-01,\n",
       "                      -1.0048e-01,  3.2371e-01,  8.3630e-01,  1.5317e-01,  1.8263e-01,\n",
       "                       2.2981e-02, -2.6845e-01,  3.3200e-01, -7.8782e-02, -1.6590e-01,\n",
       "                       9.1794e-02, -2.4186e-01, -1.6259e-01, -1.0155e-01, -1.1434e-01,\n",
       "                      -3.0116e-01, -3.6006e-01, -2.0061e-01,  4.0127e-01,  6.7359e-01,\n",
       "                      -4.0510e-01, -1.6207e-01, -1.4487e-01,  5.9195e-02,  4.2789e-01,\n",
       "                       1.1898e-01,  3.7237e-01, -4.9267e-02,  1.3254e-01, -2.4117e-01,\n",
       "                      -5.3216e-01, -1.0150e-01, -1.9700e-01, -1.5375e-01,  5.6155e-01,\n",
       "                      -2.9656e-02,  7.2040e-01,  1.8539e-02, -3.3710e-01,  1.2624e-01,\n",
       "                      -7.7266e-01, -1.0876e-01, -2.5189e-01, -3.7654e-01,  8.3663e-01,\n",
       "                       2.5488e-01,  3.7257e-01, -4.7173e-01, -1.4283e-01, -3.4787e-01,\n",
       "                       4.0767e-01,  2.2500e-01, -8.1275e-01,  7.0368e-01,  1.1193e+00,\n",
       "                       3.6660e-01,  4.1739e-02, -8.0886e-02,  6.8903e-02,  1.4168e-02,\n",
       "                      -1.4030e-01, -7.0084e-01,  9.0926e-01,  4.4698e-02,  9.1276e-01,\n",
       "                       7.9540e-02, -1.2677e-01, -2.4829e-01, -4.1378e-01,  3.0035e-01,\n",
       "                      -3.7157e-01,  2.4015e-01, -2.2446e-01, -1.4926e-01, -1.6386e-01,\n",
       "                      -3.4433e-01,  6.2467e-01,  1.5813e-02,  4.5979e-01, -2.7629e-01,\n",
       "                       2.9940e-01,  1.1584e-01,  1.6454e-01,  4.8761e-01,  3.9126e-01,\n",
       "                      -1.5973e-01, -3.6911e-01,  4.6594e-01,  3.2995e-04, -2.9259e-01])),\n",
       "             ('BN2.running_var',\n",
       "              tensor([0.9189, 0.3285, 0.8336, 1.1751, 0.5079, 0.3631, 0.4279, 0.2200, 1.6130,\n",
       "                      2.4399, 2.9125, 0.3813, 1.9059, 0.2509, 0.7000, 0.3894, 2.1958, 0.5797,\n",
       "                      2.0013, 0.7237, 0.2704, 0.7776, 0.6643, 0.6827, 1.2912, 0.8542, 0.2618,\n",
       "                      0.2164, 1.5599, 0.2423, 1.8803, 0.3584, 0.4470, 2.5250, 0.8006, 0.7197,\n",
       "                      0.7184, 0.2821, 0.8469, 0.8936, 1.8429, 0.3524, 1.3093, 0.4605, 1.1316,\n",
       "                      1.2883, 0.5418, 0.3490, 0.6181, 1.2062, 0.8550, 0.3886, 1.8031, 0.5092,\n",
       "                      0.2006, 0.2464, 0.6897, 1.9547, 0.4011, 0.4745, 0.9873, 0.3133, 0.7145,\n",
       "                      0.7091, 0.6339, 1.2497, 1.0456, 1.1509, 0.8656, 0.9732, 1.5334, 0.7162,\n",
       "                      0.2870, 0.6754, 0.2500, 1.5649, 0.8321, 1.6217, 1.4640, 0.6761, 0.7343,\n",
       "                      0.7545, 1.0849, 0.6792, 1.0921, 0.6051, 0.1814, 2.1239, 1.3021, 0.4393,\n",
       "                      0.5902, 0.6145, 2.2571, 1.3039, 0.2859, 0.8829, 0.7565, 0.3663, 0.2123,\n",
       "                      0.7103, 1.0281, 0.5199, 0.3585, 0.7787, 0.8852, 0.8962, 1.5182, 0.1978,\n",
       "                      0.5228, 1.9902, 0.6613, 1.2429, 0.9213, 0.9970, 0.3634, 0.6452, 0.5779,\n",
       "                      0.2118, 1.9874, 0.6777, 0.5232, 0.4570, 1.8323, 1.2136, 0.6573, 0.4382,\n",
       "                      2.2648, 1.4121, 0.3130, 1.5863, 1.1818, 0.2995, 0.5275, 1.6873, 1.8187,\n",
       "                      0.6307, 0.3091, 0.6826, 1.5210, 3.5776, 1.9880, 1.5077, 1.1889, 1.1986,\n",
       "                      0.4633, 0.6784, 0.3671, 0.7017, 0.8948, 1.6119, 1.3171, 1.3005, 1.5122,\n",
       "                      1.0306, 0.7759, 1.7782, 0.3108, 1.5673, 0.2795, 0.6698, 1.3566, 1.3853,\n",
       "                      0.3435, 2.0247, 0.2926, 0.4987, 0.8908, 0.9103, 1.6216, 0.4395, 1.1429,\n",
       "                      0.4438, 0.3882, 0.7650, 0.7933, 1.2332, 0.6906, 0.4353, 0.7864, 0.2540,\n",
       "                      0.5894, 0.7417, 0.8770, 0.9489, 0.4583, 1.8231, 0.4798, 0.2325, 1.8624,\n",
       "                      1.3975, 0.6363, 1.0299, 1.0360, 0.2823, 0.6831, 0.9425, 2.2186, 0.2264,\n",
       "                      0.7528, 1.7868, 0.4964, 1.0726, 0.2313, 0.2571, 0.9918, 0.6314, 0.5344,\n",
       "                      1.1741, 0.2847, 0.4492, 1.3518, 0.2125, 0.6774, 0.6165, 0.2753, 2.4055,\n",
       "                      1.2699, 0.5027, 0.5717, 1.2190, 0.4100, 1.6560, 1.1207, 0.5078, 1.4795,\n",
       "                      0.8547, 1.5286, 0.2147, 0.5038, 2.7337, 0.7486, 1.1637, 0.8511, 0.6522,\n",
       "                      0.7615, 0.3101, 0.7067, 1.3637, 0.3959, 0.2743, 1.2741, 1.2383, 1.1737,\n",
       "                      0.7662, 0.9575, 0.3135, 0.9174, 1.7451, 0.6631, 0.4414, 0.4257, 0.9695,\n",
       "                      0.3459, 0.1411, 0.3716, 0.2017, 1.9856, 0.2631, 0.2841, 0.5654, 0.4537,\n",
       "                      0.2181, 0.5841, 0.7521, 0.2235, 2.3553, 0.3563, 0.3020, 1.5742, 1.0709,\n",
       "                      0.4232, 1.8768, 0.1855, 0.5997, 0.3703, 1.4407, 1.0021, 0.6963, 0.7502,\n",
       "                      0.3529, 0.7963, 0.8497, 1.7574, 1.3596, 0.6923, 1.0857, 0.2820, 0.2326,\n",
       "                      0.5484, 1.9538, 1.3075, 0.4460, 0.5997, 2.3435, 0.9289, 1.3456, 0.3069,\n",
       "                      0.2775, 1.2547, 0.3728, 1.2579, 2.0653, 0.7883, 1.2367, 0.8239, 0.1770,\n",
       "                      0.5818, 0.9570, 0.3277, 0.4738, 2.1441, 0.4117, 1.4963, 0.8935, 0.8038,\n",
       "                      0.2934, 0.5419, 2.2512, 1.8881, 1.0046, 0.4815, 0.2708, 2.1672, 1.2902,\n",
       "                      0.7095, 0.2918, 1.2654, 1.0308, 0.5017, 0.9804, 2.1359, 1.0070, 1.2594,\n",
       "                      0.3427, 0.4602, 0.2994, 0.2571, 0.6898, 0.6530, 0.6597, 0.8751, 1.2320,\n",
       "                      0.8377, 0.2670, 0.9849, 0.9041, 1.2392, 1.5441, 0.3593, 0.3106, 2.3123,\n",
       "                      1.2176, 0.6200, 0.2089, 1.0250, 1.0086, 1.8488, 0.4549, 0.9180, 1.4667,\n",
       "                      1.0397, 0.3355, 0.4603, 0.3951, 0.8608, 0.6395, 0.4005, 0.1248, 1.3889,\n",
       "                      0.9804, 0.4852, 1.3076, 1.0265, 0.1980, 0.2121, 0.7233, 1.0691, 1.5315,\n",
       "                      0.8224, 2.4757, 1.4495, 1.0378, 1.3051, 0.2364, 0.7220, 0.3350, 0.8358,\n",
       "                      1.6632, 0.7325, 1.4531, 1.1904, 0.6100, 0.2077, 0.5343, 0.7362, 0.4146,\n",
       "                      1.3577, 0.4604, 0.7392, 0.8989, 1.4048, 0.2222, 0.3287, 0.6724, 0.9401,\n",
       "                      0.9777, 1.1598, 1.5588, 0.4105, 2.4829, 0.8182, 0.2975, 0.8913, 0.9650,\n",
       "                      0.4632, 0.3945, 0.4580, 1.8667, 0.3675, 0.6002, 2.2789, 1.5251, 0.3718,\n",
       "                      0.6405, 0.4839, 0.4856, 1.0957, 0.3164, 0.2982, 0.6782, 0.1884, 0.3946,\n",
       "                      0.2612, 0.4625, 1.4528, 0.4022, 0.8957, 0.4277, 0.9022, 0.3028, 0.5754,\n",
       "                      0.8646, 0.4321, 0.9893, 0.8159, 0.5092, 0.4875, 1.1044, 0.5344, 0.2616,\n",
       "                      0.4544, 0.7881, 1.1475, 0.8166, 2.1281, 1.7561, 0.4813, 0.5106, 0.9161,\n",
       "                      0.5304, 1.1365, 0.5240, 0.3556, 1.0488, 2.1108, 2.4426, 0.2483, 0.5087,\n",
       "                      0.8776, 0.4077, 0.2429, 0.5681, 0.7625, 2.3191, 0.7908, 0.3807, 0.2131,\n",
       "                      0.4147, 1.2424, 0.6853, 1.2559, 2.5208, 0.7983, 0.1944, 0.7069, 0.4916,\n",
       "                      0.4774, 0.2985, 0.5814, 0.8464, 0.8716, 1.9029, 0.4545, 1.4019, 0.6142,\n",
       "                      0.4612, 0.9894, 0.3453, 0.8069, 0.7617])),\n",
       "             ('BN2.num_batches_tracked', tensor(1200)),\n",
       "             ('enc_3.weight',\n",
       "              tensor([[ 0.0293,  0.0131,  0.0102,  ..., -0.0346,  0.0046, -0.0216],\n",
       "                      [ 0.0118,  0.0233, -0.0002,  ..., -0.0452,  0.0073, -0.0270],\n",
       "                      [-0.0104, -0.0171, -0.0598,  ..., -0.0237,  0.0414, -0.0265],\n",
       "                      ...,\n",
       "                      [ 0.0237,  0.0133,  0.0309,  ..., -0.0117, -0.0443,  0.0108],\n",
       "                      [-0.0231, -0.0050, -0.0370,  ...,  0.0476,  0.0150,  0.0171],\n",
       "                      [-0.0173, -0.0567, -0.0342,  ..., -0.0312,  0.0224,  0.0120]])),\n",
       "             ('enc_3.bias',\n",
       "              tensor([-0.0005,  0.0436,  0.0267,  ..., -0.0416,  0.0415, -0.0395])),\n",
       "             ('BN3.weight',\n",
       "              tensor([1.0146, 0.9925, 1.0001,  ..., 1.0060, 1.0058, 0.9983])),\n",
       "             ('BN3.bias',\n",
       "              tensor([-0.0154, -0.0131,  0.0031,  ...,  0.0040,  0.0087,  0.0034])),\n",
       "             ('BN3.running_mean',\n",
       "              tensor([ 0.4436,  0.3747, -0.3979,  ...,  0.1372,  0.2374,  0.0687])),\n",
       "             ('BN3.running_var',\n",
       "              tensor([0.4973, 0.5538, 0.5906,  ..., 1.2589, 0.4495, 0.5192])),\n",
       "             ('BN3.num_batches_tracked', tensor(1200)),\n",
       "             ('z_layer.weight',\n",
       "              tensor([[ 0.0339,  0.0050,  0.0098,  ..., -0.0191,  0.0032,  0.0160],\n",
       "                      [-0.0109,  0.0024,  0.0204,  ...,  0.0097, -0.0095, -0.0123],\n",
       "                      [ 0.0083, -0.0010, -0.0064,  ...,  0.0234,  0.0233, -0.0099],\n",
       "                      ...,\n",
       "                      [ 0.0260,  0.0155, -0.0265,  ...,  0.0240, -0.0319,  0.0300],\n",
       "                      [-0.0349, -0.0104, -0.0136,  ..., -0.0078, -0.0067,  0.0233],\n",
       "                      [ 0.0168, -0.0142,  0.0029,  ...,  0.0101, -0.0226, -0.0086]])),\n",
       "             ('z_layer.bias',\n",
       "              tensor([ 0.0172,  0.0047,  0.0045, -0.0185,  0.0120, -0.0100, -0.0218, -0.0100,\n",
       "                       0.0129,  0.0018])),\n",
       "             ('dec_1.weight',\n",
       "              tensor([[ 0.1453,  0.3241, -0.3125,  ...,  0.1679,  0.1796, -0.0963],\n",
       "                      [-0.1154, -0.2163,  0.1988,  ..., -0.2741,  0.2893,  0.1945],\n",
       "                      [ 0.0815, -0.1273, -0.2063,  ..., -0.2925,  0.1930, -0.0977],\n",
       "                      ...,\n",
       "                      [ 0.1675, -0.2414, -0.0544,  ..., -0.1845,  0.2279,  0.2800],\n",
       "                      [ 0.2031, -0.0374,  0.1206,  ...,  0.1065, -0.1576,  0.1332],\n",
       "                      [-0.1940, -0.1132, -0.0358,  ...,  0.0528, -0.0175, -0.1937]])),\n",
       "             ('dec_1.bias',\n",
       "              tensor([ 0.0452,  0.2904,  0.0536,  ..., -0.0088, -0.1437, -0.1040])),\n",
       "             ('BN4.weight',\n",
       "              tensor([0.9988, 1.0047, 0.9877,  ..., 0.9931, 1.0647, 0.9756])),\n",
       "             ('BN4.bias',\n",
       "              tensor([ 0.0111, -0.0297,  0.0237,  ..., -0.0321, -0.0067, -0.0113])),\n",
       "             ('BN4.running_mean',\n",
       "              tensor([-0.9719,  0.7104, -0.6821,  ...,  0.0212, -0.0917,  0.3228])),\n",
       "             ('BN4.running_var',\n",
       "              tensor([15.9971,  4.6675, 11.6531,  ...,  4.6472,  1.7073,  7.1396])),\n",
       "             ('BN4.num_batches_tracked', tensor(1200)),\n",
       "             ('dec_2.weight',\n",
       "              tensor([[-0.0239,  0.0233, -0.0242,  ..., -0.0058, -0.0072, -0.0066],\n",
       "                      [ 0.0161, -0.0065,  0.0140,  ...,  0.0004, -0.0193, -0.0063],\n",
       "                      [ 0.0025,  0.0158, -0.0138,  ...,  0.0022,  0.0155,  0.0105],\n",
       "                      ...,\n",
       "                      [-0.0020, -0.0156, -0.0147,  ...,  0.0045, -0.0301, -0.0057],\n",
       "                      [-0.0098,  0.0103,  0.0112,  ...,  0.0138,  0.0227,  0.0243],\n",
       "                      [ 0.0223, -0.0018, -0.0087,  ..., -0.0201, -0.0006,  0.0206]])),\n",
       "             ('dec_2.bias',\n",
       "              tensor([ 1.6453e-02,  1.0193e-02, -1.9294e-02,  1.7105e-02, -5.9344e-03,\n",
       "                      -9.1510e-03, -1.7391e-02, -3.5916e-03, -1.3800e-02, -1.8516e-02,\n",
       "                       7.4182e-03, -3.1364e-03, -1.5435e-02,  1.8224e-02, -5.7645e-03,\n",
       "                       7.0082e-03, -1.1127e-02, -7.1892e-03, -1.1692e-02, -2.7440e-03,\n",
       "                      -6.4728e-03,  3.7740e-03, -1.2333e-02,  1.0171e-02,  2.1272e-02,\n",
       "                       1.3469e-02,  1.9649e-02, -1.9490e-02,  9.5425e-03,  6.6197e-03,\n",
       "                       4.9395e-03,  1.3896e-02,  1.6573e-02,  2.9891e-03, -1.6952e-02,\n",
       "                      -2.0017e-02, -7.9065e-03, -2.1717e-02, -1.7937e-02,  3.2794e-03,\n",
       "                       1.7831e-02, -1.8630e-03, -1.1664e-02, -2.1869e-02, -2.0872e-02,\n",
       "                       4.6276e-03,  2.0175e-02,  8.3370e-03,  1.4997e-02, -1.0668e-02,\n",
       "                       2.0921e-02, -9.7931e-03,  7.8570e-03, -1.0487e-02,  1.7359e-02,\n",
       "                      -1.2525e-02,  1.3147e-02, -9.5387e-03, -1.1747e-02,  1.7804e-02,\n",
       "                       8.2665e-03,  1.2297e-02,  2.6762e-03, -2.0017e-02,  8.1789e-03,\n",
       "                       7.9400e-03,  1.2407e-02,  2.0308e-02, -1.7371e-02,  1.6169e-02,\n",
       "                       1.3884e-03,  5.9942e-04, -1.6409e-02,  1.1090e-02,  8.9756e-03,\n",
       "                       7.3162e-03,  1.0460e-02,  2.1576e-02,  3.3011e-03, -1.5953e-03,\n",
       "                       4.9161e-03,  1.4140e-02, -1.8186e-02, -1.8416e-02, -3.1325e-03,\n",
       "                      -7.8505e-03,  1.8470e-02, -1.2261e-02, -1.3593e-02, -9.9013e-03,\n",
       "                       5.6674e-03, -1.6492e-02,  1.2446e-02, -1.3545e-02, -9.3518e-03,\n",
       "                       2.2234e-02,  1.1785e-02, -2.5162e-03, -1.1097e-03, -1.3698e-02,\n",
       "                      -1.6860e-02,  8.3837e-04,  1.2328e-02, -1.9849e-02, -2.4599e-03,\n",
       "                      -1.9671e-02,  9.2731e-03, -3.8414e-04,  1.4630e-02,  2.1946e-02,\n",
       "                       1.1908e-02, -8.6907e-03,  9.5615e-03,  4.5728e-03,  1.8110e-02,\n",
       "                      -1.7620e-02, -1.0440e-02,  3.1324e-03,  6.4992e-03, -2.0247e-02,\n",
       "                       1.7318e-03,  6.4931e-03, -2.2354e-02,  4.3483e-03, -2.7841e-03,\n",
       "                       8.9399e-03, -1.7129e-02,  8.5912e-03,  1.0439e-02, -1.6367e-02,\n",
       "                      -2.1135e-02,  3.7798e-03,  2.0338e-02,  1.0077e-02, -3.2335e-03,\n",
       "                      -6.9088e-03,  8.8613e-03, -2.0675e-02,  1.7087e-02, -1.4105e-02,\n",
       "                      -3.4918e-03, -5.9002e-03, -7.4533e-04,  1.3640e-02, -1.4804e-02,\n",
       "                      -7.5159e-03, -3.8216e-03,  7.1975e-03, -6.3644e-03, -1.7707e-02,\n",
       "                       1.1930e-02,  1.6122e-03, -1.3458e-02,  4.6087e-03, -4.6905e-03,\n",
       "                      -7.4993e-03, -2.9741e-03, -1.6779e-02,  1.6505e-03,  5.0613e-03,\n",
       "                       1.9123e-02,  1.6225e-02,  2.1723e-02, -7.9045e-03, -1.6494e-02,\n",
       "                       8.7737e-03,  6.1306e-03, -1.2561e-02, -1.8624e-02,  9.5373e-03,\n",
       "                       3.6700e-03,  2.1291e-02,  1.6474e-02, -5.7572e-03,  8.6677e-03,\n",
       "                       2.6911e-03, -2.0937e-02,  8.9191e-03, -1.6311e-02,  9.0514e-03,\n",
       "                       1.4720e-02,  1.3049e-03,  4.0979e-03,  5.8538e-04, -1.0370e-02,\n",
       "                       1.5282e-02, -1.7064e-02, -1.1542e-02, -1.7430e-02,  6.7478e-03,\n",
       "                       1.4136e-02, -1.2741e-02, -1.0222e-02, -1.2522e-02, -1.3919e-02,\n",
       "                       6.7523e-03, -1.8973e-02,  1.5528e-02,  1.7949e-02, -2.6149e-03,\n",
       "                      -1.3153e-03,  4.7315e-03, -1.5433e-02,  1.4401e-02,  7.7053e-03,\n",
       "                       5.9887e-03, -1.0564e-02,  1.6974e-02,  1.9481e-02,  1.6416e-02,\n",
       "                       1.4829e-02, -9.5450e-03,  5.3345e-05, -1.1013e-02,  3.2352e-03,\n",
       "                      -1.8680e-02, -4.4627e-03, -1.1236e-02,  1.2779e-02, -5.8505e-03,\n",
       "                       1.1448e-03,  2.0623e-02, -1.0269e-02,  7.9159e-03,  1.2072e-02,\n",
       "                      -2.1195e-02, -1.8298e-02,  7.9520e-03,  7.5368e-03, -1.9082e-02,\n",
       "                       1.7836e-02, -2.1252e-02, -1.0582e-02, -1.3608e-03,  1.4359e-02,\n",
       "                       3.6478e-03, -1.5610e-02, -1.0532e-02,  1.8896e-02, -1.0773e-02,\n",
       "                       1.7568e-02,  4.8717e-03, -1.8068e-02, -1.0917e-02, -1.4772e-02,\n",
       "                       8.5292e-03,  7.9554e-03, -3.6125e-03, -1.2598e-02, -5.6542e-03,\n",
       "                      -7.3388e-03, -5.3675e-03, -9.3868e-03, -1.7726e-02,  3.2655e-03,\n",
       "                       7.2390e-03, -1.8175e-02, -1.6521e-02, -1.2449e-02, -8.6531e-03,\n",
       "                      -1.7154e-02, -2.8777e-03,  2.2279e-02, -9.4955e-03,  1.0664e-02,\n",
       "                       2.0107e-02,  6.2253e-03, -1.9516e-02, -1.7044e-02,  1.4234e-02,\n",
       "                      -1.5100e-03, -1.4634e-02, -9.4608e-03, -1.8468e-03, -9.7993e-03,\n",
       "                       5.5421e-03, -1.7777e-02, -6.8504e-03, -2.2358e-02, -1.1141e-02,\n",
       "                       1.4422e-02, -1.8179e-02, -3.7811e-03,  1.0191e-02,  5.0218e-03,\n",
       "                      -8.4691e-03,  1.4670e-02,  1.8081e-02,  1.3614e-02,  1.7985e-02,\n",
       "                      -1.5070e-02, -1.2590e-02,  1.7536e-02,  3.1347e-03, -1.0031e-02,\n",
       "                       3.4413e-03, -1.5162e-02, -1.3107e-03,  2.6866e-03, -4.9416e-03,\n",
       "                       1.7656e-02,  1.7195e-03,  1.8429e-02, -2.9639e-03, -4.9636e-03,\n",
       "                       2.4754e-03, -1.4377e-02, -9.7630e-03, -2.0902e-02, -7.7185e-03,\n",
       "                      -1.4360e-02, -1.0224e-02, -6.7609e-03, -1.9930e-02,  1.8935e-02,\n",
       "                      -5.9562e-03, -2.5887e-03, -1.7302e-02, -1.0145e-02,  1.8742e-02,\n",
       "                       6.1721e-03,  1.4956e-03,  1.8365e-02,  9.8026e-03, -1.6614e-03,\n",
       "                      -1.7193e-02, -4.2159e-03,  1.4000e-02,  1.6854e-02,  1.3291e-02,\n",
       "                      -5.3625e-03,  1.2370e-02, -1.8675e-02,  1.9730e-02, -1.7785e-02,\n",
       "                      -1.6429e-03,  8.1789e-03,  2.3441e-03, -1.1663e-02, -1.6938e-02,\n",
       "                      -9.7386e-03, -2.5175e-03,  2.6892e-03, -1.9789e-02, -3.3650e-03,\n",
       "                      -1.2508e-02, -1.5036e-02,  1.4494e-02, -2.6632e-03,  9.7478e-03,\n",
       "                       1.6114e-02,  1.2883e-02, -1.5781e-02, -1.5220e-02, -1.9978e-02,\n",
       "                      -9.9471e-03,  1.2876e-03, -9.7537e-03,  1.1361e-02,  2.3314e-03,\n",
       "                      -2.2023e-02, -1.5638e-02,  4.1603e-03,  8.6339e-03,  3.3048e-03,\n",
       "                       6.2023e-03, -1.1469e-03,  8.0226e-03, -1.0937e-02, -4.8935e-03,\n",
       "                      -2.0913e-02,  4.5504e-03,  1.9248e-02, -1.1693e-02,  2.2969e-03,\n",
       "                      -4.3527e-03, -5.7880e-03, -1.3713e-02,  3.2178e-03, -8.4909e-04,\n",
       "                       2.1059e-02,  6.6677e-03,  4.3382e-03,  2.0440e-02, -1.1755e-02,\n",
       "                       1.7503e-02,  4.4421e-03,  4.4741e-03, -1.0051e-02,  1.6696e-02,\n",
       "                       8.0715e-03, -7.8056e-03, -1.8018e-02,  2.0792e-02, -1.7451e-02,\n",
       "                      -1.7288e-02,  1.4337e-02, -1.0233e-02, -1.4027e-02, -2.1623e-02,\n",
       "                      -2.1814e-02, -9.8682e-03,  5.9918e-03, -2.8404e-03,  1.9026e-02,\n",
       "                       1.4634e-02, -4.4379e-03, -1.8307e-02, -3.7706e-03,  1.1336e-02,\n",
       "                       1.2621e-02, -4.1455e-03, -1.2949e-03, -1.8534e-02,  7.6971e-03,\n",
       "                      -1.4719e-03,  7.6647e-05, -1.6691e-02, -2.1502e-02, -1.8808e-02,\n",
       "                       2.1359e-02, -1.8032e-03,  1.6198e-02,  5.8407e-03, -1.4195e-02,\n",
       "                       1.1095e-02, -1.8580e-02,  1.0253e-02,  5.0830e-03,  2.8727e-03,\n",
       "                       5.7661e-03, -2.6392e-03,  1.7306e-02,  1.4366e-02, -3.1484e-03,\n",
       "                       2.0053e-02, -3.5129e-03,  1.7108e-02,  1.9727e-02, -1.0702e-02,\n",
       "                      -1.8571e-02,  9.0172e-03, -1.7235e-03, -6.8359e-03,  1.4328e-02,\n",
       "                       1.8773e-02,  4.0063e-03, -5.6629e-03, -1.6223e-02,  1.4008e-02,\n",
       "                       4.5304e-04,  2.0549e-02, -8.6616e-03, -1.9590e-02, -7.8452e-03,\n",
       "                      -1.5364e-02, -1.1076e-02,  1.1051e-02,  1.1955e-02, -2.5888e-03,\n",
       "                       1.8981e-02, -7.7003e-03,  2.2033e-02,  1.4752e-02, -4.7936e-03,\n",
       "                      -8.4305e-03,  6.8513e-04, -1.9292e-02, -6.8981e-03,  2.3314e-03,\n",
       "                       1.3699e-02, -5.2802e-03,  2.1750e-02,  1.4144e-02, -1.3109e-02,\n",
       "                       2.0629e-02,  1.2505e-02, -1.5754e-02,  1.1954e-02,  7.8709e-03,\n",
       "                      -1.4616e-02, -1.4563e-02,  1.1450e-02, -1.4978e-03,  5.1085e-03,\n",
       "                      -8.1151e-03, -6.0205e-03, -5.6964e-03, -1.3490e-02, -1.8909e-02,\n",
       "                      -8.7010e-03, -4.2851e-03, -1.7551e-02, -1.0046e-02,  6.2417e-03,\n",
       "                       9.6435e-03, -9.5692e-03, -5.5546e-03, -1.3517e-02,  2.0254e-02])),\n",
       "             ('BN5.weight',\n",
       "              tensor([0.9848, 1.0053, 0.9870, 1.0286, 0.9817, 0.9997, 0.9832, 0.9892, 1.0144,\n",
       "                      0.9854, 0.9936, 0.9820, 0.9932, 0.9895, 1.0150, 0.9787, 1.0024, 1.0158,\n",
       "                      0.9763, 0.9937, 1.0336, 0.9816, 0.9796, 0.9962, 1.0104, 0.9943, 0.9879,\n",
       "                      0.9660, 0.9787, 0.9828, 0.9990, 0.9433, 0.9932, 1.0018, 0.9765, 0.9823,\n",
       "                      1.0146, 1.0466, 1.0145, 1.0704, 0.9989, 0.9915, 1.0510, 0.9986, 0.9978,\n",
       "                      0.9881, 0.9937, 1.0077, 0.9744, 1.0188, 1.0080, 0.9775, 0.9862, 0.9843,\n",
       "                      1.0225, 0.9948, 1.0088, 1.0633, 0.9889, 0.9926, 0.9848, 0.9931, 0.9903,\n",
       "                      0.9854, 1.0106, 0.9874, 0.9858, 1.0257, 0.9693, 0.9957, 0.9996, 0.9858,\n",
       "                      1.0168, 1.0350, 0.9995, 0.9881, 1.0004, 0.9852, 0.9892, 0.9875, 0.9850,\n",
       "                      0.9804, 1.0056, 0.9791, 1.0117, 1.0071, 0.9977, 0.9933, 1.0194, 0.9896,\n",
       "                      1.0059, 1.0769, 0.9814, 0.9844, 1.0474, 1.0221, 0.9941, 1.0187, 0.9914,\n",
       "                      0.9914, 0.9816, 0.9867, 0.9837, 0.9812, 0.9733, 0.9790, 1.0105, 1.0118,\n",
       "                      0.9853, 0.9840, 0.9916, 0.9759, 1.0175, 0.9815, 0.9777, 1.0079, 0.9888,\n",
       "                      0.9837, 0.9794, 1.0931, 1.0044, 1.0197, 1.0085, 0.9928, 0.9781, 1.0995,\n",
       "                      0.9855, 1.0582, 1.0169, 1.0116, 1.0580, 1.0289, 0.9761, 1.0023, 1.1008,\n",
       "                      1.0180, 0.9865, 0.9918, 0.9840, 0.9927, 0.9729, 0.9903, 0.9533, 1.0222,\n",
       "                      1.0013, 1.0626, 1.0168, 0.9965, 1.0135, 1.0272, 0.9890, 0.9967, 0.9814,\n",
       "                      1.0376, 1.0077, 0.9997, 1.0084, 0.9921, 0.9961, 1.0536, 0.9980, 1.0335,\n",
       "                      1.0077, 0.9708, 0.9997, 1.0061, 1.0243, 1.0074, 0.9833, 0.9737, 1.0313,\n",
       "                      1.0525, 0.9796, 1.0116, 0.9920, 0.9773, 1.0345, 0.9949, 0.9607, 1.0027,\n",
       "                      0.9884, 1.0093, 0.9859, 1.0430, 1.0414, 1.0343, 1.0285, 1.0518, 1.0155,\n",
       "                      1.0039, 0.9926, 0.9828, 0.9958, 1.0223, 1.0362, 0.9640, 1.0091, 0.9943,\n",
       "                      1.0212, 0.9900, 0.9915, 1.0336, 0.9715, 1.0156, 0.9941, 1.0012, 1.0075,\n",
       "                      1.0071, 0.9908, 1.0579, 0.9796, 0.9722, 0.9988, 0.9915, 0.9911, 0.9749,\n",
       "                      0.9521, 1.0096, 0.9546, 0.9830, 0.9952, 1.0081, 1.0059, 0.9855, 1.0380,\n",
       "                      1.0156, 0.9716, 0.9969, 1.0132, 0.9917, 1.0268, 1.0882, 1.0190, 0.9828,\n",
       "                      1.0052, 0.9834, 0.9990, 1.0085, 0.9999, 1.0089, 0.9799, 0.9661, 0.9568,\n",
       "                      1.0055, 0.9844, 0.9831, 0.9847, 1.0040, 1.0863, 0.9894, 0.9840, 1.0076,\n",
       "                      0.9995, 1.0406, 1.0108, 1.0995, 1.0153, 1.0037, 0.9986, 1.0107, 1.0030,\n",
       "                      0.9796, 0.9625, 0.9875, 1.0428, 1.0160, 0.9783, 0.9695, 1.0068, 0.9682,\n",
       "                      1.0060, 1.0311, 0.9958, 0.9924, 1.0076, 1.0352, 0.9883, 1.0190, 0.9686,\n",
       "                      1.0006, 1.0004, 1.0039, 0.9835, 0.9793, 1.0481, 0.9780, 0.9877, 0.9918,\n",
       "                      0.9780, 0.9863, 1.0246, 1.0275, 1.0179, 1.0194, 0.9756, 0.9987, 1.0048,\n",
       "                      0.9746, 1.0041, 0.9889, 0.9922, 0.9809, 0.9782, 1.0428, 0.9744, 0.9977,\n",
       "                      0.9879, 1.0080, 1.0082, 1.0074, 1.0152, 1.0444, 0.9794, 1.0149, 0.9844,\n",
       "                      0.9917, 0.9854, 1.0368, 1.0309, 1.0052, 1.0012, 0.9917, 0.9767, 0.9927,\n",
       "                      0.9956, 0.9849, 0.9892, 1.0023, 1.0276, 1.0621, 0.9867, 1.0896, 0.9889,\n",
       "                      0.9803, 0.9898, 1.0549, 0.9862, 0.9928, 1.0109, 0.9756, 0.9717, 0.9856,\n",
       "                      0.9789, 0.9955, 1.0524, 1.0558, 0.9964, 0.9970, 0.9767, 1.0509, 0.9797,\n",
       "                      1.0049, 1.0058, 0.9814, 0.9913, 0.9837, 0.9953, 1.0156, 0.9856, 1.0436,\n",
       "                      0.9758, 0.9989, 0.9999, 1.0131, 1.0260, 0.9779, 0.9891, 1.0280, 0.9863,\n",
       "                      0.9892, 0.9913, 1.0572, 0.9790, 1.0341, 1.0309, 1.0038, 0.9918, 1.0134,\n",
       "                      1.0562, 0.9816, 1.0322, 1.1122, 0.9961, 0.9681, 0.9603, 0.9949, 0.9926,\n",
       "                      0.9964, 0.9858, 0.9975, 0.9959, 0.9786, 0.9712, 1.0041, 0.9951, 0.9852,\n",
       "                      0.9827, 1.0391, 0.9856, 1.0022, 0.9809, 0.9897, 1.0276, 0.9921, 1.0227,\n",
       "                      1.1330, 1.0045, 1.0242, 0.9959, 0.9960, 0.9885, 1.0051, 0.9880, 0.9933,\n",
       "                      1.0201, 0.9824, 0.9989, 1.0321, 0.9554, 0.9918, 1.0040, 0.9741, 0.9964,\n",
       "                      0.9976, 0.9782, 0.9874, 1.0052, 1.0149, 0.9827, 1.0381, 1.0766, 0.9764,\n",
       "                      1.0124, 1.0035, 0.9937, 1.0127, 0.9821, 0.9934, 1.0226, 0.9774, 0.9748,\n",
       "                      0.9806, 1.0094, 0.9812, 0.9738, 1.0000, 1.0099, 1.0041, 1.0291, 0.9751,\n",
       "                      1.0392, 0.9925, 1.0056, 1.0360, 1.0054, 0.9895, 0.9693, 0.9920, 0.9784,\n",
       "                      0.9775, 0.9882, 0.9905, 0.9920, 0.9902, 0.9699, 1.0066, 0.9895, 0.9941,\n",
       "                      0.9963, 0.9863, 1.0217, 1.0322, 1.0556, 0.9732, 0.9841, 0.9681, 0.9832,\n",
       "                      0.9912, 1.0272, 0.9711, 0.9920, 0.9969, 0.9911, 1.0505, 0.9928, 0.9986,\n",
       "                      1.0064, 0.9871, 1.0259, 1.0287, 0.9979, 0.9867, 1.0502, 1.0080, 1.0163,\n",
       "                      0.9869, 0.9860, 0.9814, 0.9723, 1.0757])),\n",
       "             ('BN5.bias',\n",
       "              tensor([-7.1112e-03, -5.1311e-02, -3.2003e-03,  5.4924e-02, -1.5465e-02,\n",
       "                       1.6009e-02, -3.3392e-02, -6.0854e-02,  3.7222e-02, -1.7215e-02,\n",
       "                      -6.4172e-02, -4.2800e-02,  6.0751e-04, -2.6226e-02,  7.0581e-02,\n",
       "                      -4.4952e-02,  1.6832e-02,  1.0946e-01, -2.6364e-02, -1.3840e-02,\n",
       "                       5.7281e-02, -1.3924e-03, -1.1674e-01, -9.2492e-02,  6.4531e-02,\n",
       "                      -9.9598e-03, -9.0090e-03, -9.1689e-02, -6.0432e-02, -4.3467e-02,\n",
       "                      -4.4692e-02, -7.0468e-02,  2.7020e-03, -9.7353e-02, -2.2658e-02,\n",
       "                      -6.4026e-02, -1.6413e-02,  2.7734e-02,  1.5514e-02,  7.2802e-02,\n",
       "                       3.1834e-02,  3.2181e-03,  2.3937e-02,  1.2862e-03, -8.5401e-04,\n",
       "                      -6.5328e-02, -1.1508e-01,  1.8275e-02, -1.9879e-02,  3.4310e-02,\n",
       "                      -1.5106e-02, -1.7632e-01, -4.1528e-03, -1.1299e-02,  2.7800e-02,\n",
       "                       9.2238e-03, -6.3502e-03,  8.4773e-02, -2.7048e-02,  2.0842e-03,\n",
       "                      -1.6340e-02,  1.7617e-02, -4.0681e-03, -1.1419e-01,  3.1599e-02,\n",
       "                      -5.3300e-02, -3.5026e-02,  1.5416e-02, -8.4477e-02, -9.3760e-03,\n",
       "                      -1.6498e-02, -6.6557e-03,  8.0658e-02, -4.7387e-02,  2.4658e-03,\n",
       "                      -5.3575e-02, -1.1590e-02, -5.2567e-02, -4.7548e-02, -1.9323e-02,\n",
       "                      -8.4837e-02,  5.5272e-04, -1.9597e-02, -7.0361e-02,  4.4724e-02,\n",
       "                      -2.1009e-02,  1.6442e-02, -1.6486e-02,  2.3051e-02, -3.7482e-02,\n",
       "                       3.3358e-03,  7.5185e-02, -7.8094e-02, -6.9103e-02,  3.3123e-02,\n",
       "                       2.6445e-02, -7.4670e-03,  3.9123e-02, -3.6890e-03, -4.0992e-02,\n",
       "                      -5.3270e-02, -3.3674e-02,  7.6916e-04, -3.2199e-02, -4.9835e-03,\n",
       "                      -1.4855e-02, -2.2227e-02,  7.7641e-02, -5.1288e-02, -3.1145e-02,\n",
       "                      -6.3566e-02, -2.6167e-02, -4.5895e-02, -6.8521e-03, -1.2228e-01,\n",
       "                       1.2450e-02,  1.5098e-02, -8.0971e-02, -5.8941e-02,  4.3398e-02,\n",
       "                      -9.0695e-03,  3.1557e-02,  4.5800e-02, -9.5890e-03, -2.7757e-03,\n",
       "                       5.3560e-02, -7.2070e-02,  1.9295e-02,  1.5653e-02,  1.7095e-02,\n",
       "                       5.5338e-02,  6.7596e-02, -1.0864e-01,  9.0208e-03,  1.2080e-01,\n",
       "                       4.3934e-02, -7.3438e-02, -6.9731e-02, -6.6733e-02,  1.6061e-02,\n",
       "                      -2.4688e-02,  1.4232e-02, -5.4772e-02,  8.1390e-02,  1.5533e-02,\n",
       "                       8.6464e-02,  2.1402e-02, -7.3572e-02,  1.4680e-02,  9.4406e-02,\n",
       "                      -4.3512e-02,  4.5417e-03, -1.4915e-01,  3.0664e-02,  1.5293e-02,\n",
       "                      -7.7517e-02, -1.2482e-02, -8.1022e-02,  2.4980e-02,  1.4791e-02,\n",
       "                      -6.9300e-03,  8.0319e-02,  1.6757e-02, -7.7113e-02, -1.0364e-02,\n",
       "                       5.0820e-02, -3.2841e-02, -1.4109e-02, -2.7355e-02, -6.9043e-02,\n",
       "                       3.7008e-02,  3.2003e-02, -2.6281e-02,  3.3162e-02, -3.9054e-02,\n",
       "                      -5.6069e-02,  5.2471e-02,  1.0131e-01, -1.1202e-01, -5.4267e-03,\n",
       "                       8.3016e-03,  8.3198e-02, -6.9636e-02,  4.1742e-02,  2.8313e-02,\n",
       "                       7.8180e-02,  2.3503e-02,  4.4762e-02,  1.9610e-02,  1.4077e-03,\n",
       "                       2.2509e-02, -3.9847e-02, -9.4008e-03,  2.3838e-02,  4.3852e-02,\n",
       "                      -6.9042e-02,  3.2451e-02, -1.4632e-02,  2.9822e-02,  1.7697e-03,\n",
       "                       3.7481e-03,  3.3620e-02, -6.9677e-02,  5.1424e-02,  8.7856e-04,\n",
       "                      -6.0367e-02,  2.9621e-02,  1.6057e-02,  1.8117e-03,  3.6967e-02,\n",
       "                      -9.3710e-02, -1.3908e-02,  1.8999e-02, -1.5423e-02, -1.4075e-03,\n",
       "                      -4.5727e-02, -2.2226e-02,  4.7300e-02, -1.0855e-01, -1.1635e-01,\n",
       "                      -7.2006e-02,  3.2782e-02,  1.8980e-02, -8.1002e-02,  1.4511e-02,\n",
       "                       3.4714e-02, -4.2816e-02,  1.5250e-03,  4.7601e-02, -1.6856e-02,\n",
       "                      -4.1385e-02,  1.1413e-01,  6.6840e-02, -5.9137e-02, -1.6295e-04,\n",
       "                      -1.5374e-02, -9.7135e-03,  1.4341e-02,  1.5452e-02,  1.9431e-03,\n",
       "                       1.6628e-03, -3.4015e-02, -1.2975e-01, -9.3399e-03,  5.5636e-03,\n",
       "                      -8.2269e-02, -1.0370e-01,  8.7090e-03,  4.2052e-02, -2.5653e-02,\n",
       "                      -1.2204e-01,  5.0267e-02, -7.7887e-03,  3.8430e-02,  2.0765e-02,\n",
       "                       3.5931e-02,  2.0852e-02,  7.9364e-03,  4.4914e-02,  9.3105e-03,\n",
       "                       2.2918e-02, -6.6810e-03, -8.5915e-02, -1.7498e-02,  1.1368e-01,\n",
       "                       3.7170e-02, -9.3784e-02, -2.5528e-02,  2.3476e-02, -1.3566e-01,\n",
       "                       2.3563e-02,  1.6675e-02, -4.1782e-02, -7.2000e-03, -9.6825e-03,\n",
       "                       4.6075e-02,  2.4616e-02,  3.6323e-02, -2.7744e-02, -4.2875e-02,\n",
       "                      -1.5624e-02,  3.3542e-03, -1.5672e-02, -7.5921e-02,  1.1394e-01,\n",
       "                      -1.3877e-01, -3.8329e-02, -7.5988e-03,  6.6657e-03, -1.1138e-01,\n",
       "                       2.0771e-02,  3.6209e-02,  1.9451e-02,  8.6167e-02, -2.6597e-02,\n",
       "                       1.1273e-02,  9.0063e-02, -1.2876e-02,  2.1804e-02, -1.0166e-02,\n",
       "                      -6.3825e-03, -2.1981e-02,  2.8661e-03,  1.4073e-02, -9.2277e-02,\n",
       "                      -6.4189e-02, -3.9032e-02, -4.7125e-02, -2.8299e-03,  7.2556e-02,\n",
       "                       2.0119e-02,  2.1008e-02, -3.0222e-02,  3.9331e-02, -1.2008e-02,\n",
       "                      -3.0791e-02, -7.6443e-02,  5.8542e-04,  3.5291e-02,  1.6490e-02,\n",
       "                       1.2964e-02,  9.4017e-03, -6.0734e-02, -3.0849e-02, -3.9985e-02,\n",
       "                      -5.0574e-02, -4.6033e-04, -8.5748e-02,  2.9930e-02,  7.6114e-02,\n",
       "                      -5.8344e-02,  5.3256e-02, -1.1097e-02, -4.2265e-02, -2.9497e-02,\n",
       "                       1.4305e-02, -4.2739e-02, -2.7678e-02,  1.7684e-02, -4.6543e-03,\n",
       "                      -5.5596e-02, -8.6342e-02, -3.6254e-02,  1.1254e-02,  2.2487e-02,\n",
       "                       6.9371e-02,  9.5408e-03, -8.7821e-04, -5.2353e-02,  8.7310e-02,\n",
       "                      -1.4622e-01,  5.0056e-02,  3.8159e-03, -7.4332e-02, -5.5975e-02,\n",
       "                      -7.2315e-02, -5.9472e-02,  5.1813e-02, -6.5508e-02,  1.5947e-02,\n",
       "                      -2.2695e-02, -6.1055e-02, -5.7650e-04,  1.8883e-02,  7.8766e-02,\n",
       "                      -8.1810e-02, -5.7627e-02,  1.3422e-01, -9.5896e-02, -2.4109e-02,\n",
       "                      -4.4593e-02,  4.8843e-02, -1.0892e-01,  3.5036e-02,  1.1516e-01,\n",
       "                       6.8833e-02, -9.5310e-02,  1.2970e-02,  3.5166e-02, -3.3752e-02,\n",
       "                       6.0345e-02,  4.7142e-02, -5.2478e-03, -3.8433e-03, -4.6027e-02,\n",
       "                      -2.9379e-02, -2.3100e-02, -4.5781e-02, -1.0657e-01, -4.4647e-02,\n",
       "                       1.6197e-03, -2.2665e-02, -6.3369e-02,  1.8895e-02, -5.3859e-04,\n",
       "                      -8.7836e-02, -3.2789e-02,  8.7099e-02, -8.1334e-02, -3.2713e-03,\n",
       "                      -6.6852e-02, -4.3606e-02,  1.7395e-02,  2.9571e-02, -3.4315e-03,\n",
       "                       1.2863e-01,  1.5866e-02,  8.5211e-02, -9.5574e-02, -3.9323e-02,\n",
       "                      -1.1768e-02, -1.2406e-02, -1.0619e-01, -2.6342e-02,  3.9394e-03,\n",
       "                      -4.0777e-02, -1.6055e-02, -5.9182e-02, -7.9756e-02, -4.6069e-02,\n",
       "                      -5.6567e-02, -5.8788e-03, -4.7897e-02, -3.1906e-02, -5.1136e-02,\n",
       "                      -9.0814e-03,  4.6818e-02,  6.8247e-02, -4.9697e-05,  3.1775e-02,\n",
       "                       9.2868e-02, -1.3676e-02,  3.1619e-02,  1.2046e-02,  6.3056e-03,\n",
       "                       3.9393e-02, -5.1473e-03, -1.2430e-02,  1.1568e-03, -3.5163e-02,\n",
       "                      -4.9384e-02, -2.9220e-02,  1.3735e-02, -1.8377e-02, -3.3623e-02,\n",
       "                       1.4443e-02,  3.9867e-02, -2.4582e-02,  6.1192e-02, -2.2573e-02,\n",
       "                       1.9657e-02, -7.7844e-03, -1.5906e-02,  4.7520e-02,  3.5623e-02,\n",
       "                       1.1468e-02, -1.0283e-01, -9.8626e-03, -2.8951e-02, -1.7840e-03,\n",
       "                      -2.7829e-03, -1.7863e-03, -3.5861e-02,  4.9660e-03, -3.7502e-02,\n",
       "                      -2.2070e-02, -8.6109e-03, -6.7473e-02, -1.0607e-02, -6.6955e-02,\n",
       "                       4.6457e-02,  1.3023e-01,  1.0488e-01, -5.1289e-02,  1.5120e-02,\n",
       "                      -4.8402e-02, -9.5330e-02, -1.3969e-02,  6.3622e-02, -2.9242e-02,\n",
       "                      -7.0639e-02, -2.2350e-02, -3.0983e-02,  9.3977e-02, -1.5144e-02,\n",
       "                      -4.3743e-03,  5.8435e-04, -6.9618e-02,  7.5027e-02,  3.3392e-02,\n",
       "                       2.9800e-02, -4.3199e-02, -3.3238e-02, -1.8372e-02, -1.4690e-02,\n",
       "                      -7.2331e-03, -1.3025e-02, -1.1714e-04, -9.7653e-02, -1.8311e-02])),\n",
       "             ('BN5.running_mean',\n",
       "              tensor([-7.2224e-02,  2.7440e+00,  2.5396e+00, -6.7915e-01,  1.4520e+00,\n",
       "                      -2.4134e+00,  1.9871e+00,  8.8461e-01, -1.4912e+00, -2.2564e-01,\n",
       "                       2.2994e+00,  1.8834e+00,  1.4459e+00, -3.2361e-02, -2.8137e+00,\n",
       "                       1.6785e+00, -2.1976e+00, -1.7242e+00,  2.5663e+00,  4.1095e-01,\n",
       "                      -1.2036e+00,  1.6156e+00,  1.5237e+00,  2.0508e+00, -1.7565e+00,\n",
       "                      -9.9545e-01,  7.3985e-01,  1.2157e+00,  1.2744e+00,  2.2658e+00,\n",
       "                      -1.7312e+00,  1.1416e+00, -2.3272e+00,  6.5079e-02,  2.2233e+00,\n",
       "                       2.4876e+00, -1.3629e+00, -9.8399e-01,  7.1185e-01, -3.6218e+00,\n",
       "                      -2.3262e+00, -2.4375e+00,  6.6047e-01, -2.1992e+00, -2.7176e+00,\n",
       "                       1.7877e+00,  2.4736e+00, -1.9234e-02,  2.4910e+00, -5.5784e-01,\n",
       "                       1.6224e-02,  8.0288e-01, -3.1272e-01,  2.6762e+00, -6.9241e-01,\n",
       "                      -4.0704e+00, -6.8816e-02, -1.6622e+00, -5.4169e-01, -9.5031e-02,\n",
       "                      -1.5411e-01, -1.9785e+00,  2.4902e+00,  1.6077e+00, -2.2284e+00,\n",
       "                       2.5982e+00,  1.3608e+00, -3.2035e-01,  2.0782e+00, -1.3914e+00,\n",
       "                       5.0168e-01,  7.2784e-01, -3.4249e+00,  1.8179e+00, -3.3259e-01,\n",
       "                       1.6398e+00,  2.1830e+00,  2.4318e+00,  6.8439e-01,  3.1530e+00,\n",
       "                       1.4528e-01,  1.0001e+00,  1.2811e+00,  1.1098e+00, -3.0135e+00,\n",
       "                       1.1089e+00,  8.8290e-01,  3.1152e+00,  1.2219e+00,  6.0528e-01,\n",
       "                      -2.1751e+00,  1.2958e+00,  2.5168e+00,  2.7641e+00,  1.5719e+00,\n",
       "                      -4.2734e-01,  8.7052e-01, -1.5868e+00,  3.7572e+00,  2.4775e+00,\n",
       "                       1.1868e+00,  2.5789e-01, -9.1683e-01,  1.6378e+00,  1.6621e+00,\n",
       "                      -1.3595e+00,  1.7468e+00, -1.2919e+00,  2.6651e+00,  3.3686e+00,\n",
       "                       1.3950e+00,  5.0622e-01, -7.9354e-01,  2.6083e+00,  2.6955e+00,\n",
       "                       4.7032e-01,  1.7070e+00,  2.2821e+00,  2.2874e+00, -6.4170e-01,\n",
       "                       1.4627e+00, -2.4799e+00, -4.8756e-01, -2.8805e+00,  1.0916e+00,\n",
       "                      -1.7421e+00,  7.7149e-01, -2.5670e+00, -1.8848e+00, -8.1447e-01,\n",
       "                      -1.1968e+00, -1.8310e+00,  2.1085e+00,  1.3167e+00,  1.8507e+00,\n",
       "                      -4.7541e-01,  8.2048e-02,  1.3274e+00,  1.5665e+00, -3.2867e+00,\n",
       "                       1.7049e+00, -1.7230e+00,  1.7860e+00, -1.3887e+00,  3.0699e-01,\n",
       "                       8.1779e-02, -1.6684e+00,  1.4164e+00, -2.0291e+00, -1.3152e+00,\n",
       "                      -2.1914e-04, -1.5377e+00,  1.3382e+00, -3.2198e-01, -2.5358e+00,\n",
       "                       2.3041e+00,  5.9454e-01,  1.6127e+00, -2.4995e+00, -3.8727e-01,\n",
       "                      -2.0160e+00, -2.6979e+00, -2.4371e+00,  1.5050e+00,  1.7204e+00,\n",
       "                      -2.4988e+00,  1.1253e+00,  1.7499e+00,  2.4613e+00,  2.0631e+00,\n",
       "                      -1.9851e+00, -1.0348e+00,  1.7270e+00, -1.2383e-01,  1.9884e+00,\n",
       "                       1.6644e+00, -2.0609e-01, -2.3694e+00,  2.3857e+00, -2.3367e+00,\n",
       "                      -1.5401e+00, -2.3758e+00,  2.3993e+00, -1.1649e+00, -1.4549e+00,\n",
       "                       2.5042e-01, -3.3620e+00, -9.4328e-01, -2.5440e+00, -2.0498e+00,\n",
       "                      -1.9686e+00,  1.0624e+00,  2.4422e+00, -1.9357e+00, -1.4559e+00,\n",
       "                       2.1635e+00, -2.8870e+00,  2.1714e+00, -9.6191e-01,  3.3567e+00,\n",
       "                       2.5954e+00, -2.0687e+00,  6.2522e-01, -2.1309e-01, -2.1647e+00,\n",
       "                       2.0844e+00, -2.6240e+00, -2.0220e-01,  2.3723e+00, -1.4907e+00,\n",
       "                       2.4216e+00,  1.0825e+00, -2.1276e+00,  3.0764e+00, -2.4767e+00,\n",
       "                       2.6930e+00,  2.2571e+00, -8.5751e-01,  1.2224e+00,  1.0052e+00,\n",
       "                       2.4103e+00, -1.5868e+00, -1.8030e+00,  2.3048e+00,  8.1023e-01,\n",
       "                      -1.0286e+00,  1.1727e+00,  3.6172e+00, -5.1714e-01,  2.8718e+00,\n",
       "                      -8.2019e-01, -5.3851e-01, -2.5035e+00,  1.4955e+00, -1.8346e+00,\n",
       "                       1.9598e+00, -1.5709e+00, -2.0572e+00, -1.5348e+00, -2.1785e+00,\n",
       "                       1.7941e+00,  1.6144e+00,  1.9736e+00, -3.1445e+00,  1.4364e+00,\n",
       "                       1.6739e+00,  2.0120e+00, -1.8678e+00, -5.4591e-01,  2.7374e+00,\n",
       "                       1.3787e+00, -2.2956e+00,  1.1664e+00, -5.4477e-01, -3.1335e+00,\n",
       "                       1.1036e+00, -1.3458e+00, -2.5366e+00, -2.9584e+00, -1.6563e+00,\n",
       "                      -1.1370e-01,  2.6739e+00,  5.6599e-01, -3.4737e+00, -2.3310e+00,\n",
       "                      -2.1382e+00,  1.9169e+00,  2.8082e+00, -7.7688e-01,  2.6883e+00,\n",
       "                      -2.0309e+00, -7.9180e-01,  2.3360e+00,  2.9054e+00, -1.3396e+00,\n",
       "                      -1.5094e+00,  1.0815e+00, -4.1567e-01, -7.5051e-01, -1.4969e+00,\n",
       "                      -3.2438e+00, -2.7143e+00,  2.8718e-02,  1.2451e+00, -1.5970e+00,\n",
       "                       6.4278e-01,  3.8523e-01,  3.1785e+00,  2.5650e+00,  1.7665e+00,\n",
       "                      -9.2357e-01, -1.4671e+00, -3.0430e-01, -2.3620e+00,  1.4090e+00,\n",
       "                      -2.4829e+00, -1.2605e+00,  1.4169e+00, -2.4323e+00,  1.9026e+00,\n",
       "                       2.1807e+00,  2.3535e-01,  3.0566e+00, -1.8027e+00,  1.9780e+00,\n",
       "                       2.1616e+00,  3.0581e+00,  1.0964e+00,  6.2104e-01, -2.5726e+00,\n",
       "                      -1.1407e+00, -3.5754e-01,  1.6843e+00, -2.8450e+00, -2.9022e+00,\n",
       "                      -1.3368e+00,  2.1509e+00, -8.5733e-01, -3.4912e-01, -1.0836e+00,\n",
       "                      -2.2186e+00,  2.2244e+00,  1.4173e+00,  2.4218e+00,  8.5659e-01,\n",
       "                       1.9500e+00, -2.7956e+00,  1.2466e+00, -1.8789e+00, -2.3822e+00,\n",
       "                       2.7473e+00, -1.2345e+00,  2.7002e+00,  5.1917e-01, -5.7504e-02,\n",
       "                       1.3761e+00,  2.5635e+00,  1.1768e+00, -1.6112e+00,  1.7192e+00,\n",
       "                       2.3139e+00,  2.1024e+00,  1.3280e+00, -3.0613e+00,  5.3542e-01,\n",
       "                      -1.5665e+00, -1.5879e+00,  3.8005e+00,  1.2434e+00,  2.3774e-01,\n",
       "                       2.7456e+00, -1.6401e+00,  6.1618e-01,  2.1918e+00,  2.0874e+00,\n",
       "                       1.3029e+00,  3.1423e+00, -1.3122e+00,  2.5815e+00, -2.2500e-01,\n",
       "                       1.5099e+00, -6.2603e-01, -1.6153e-01, -1.2868e+00, -6.8263e-01,\n",
       "                       2.4447e+00,  2.8500e+00, -1.4384e+00, -4.3709e-01,  3.2555e+00,\n",
       "                      -4.7884e-01, -7.0684e-01,  2.4170e+00, -1.6344e+00, -1.9369e+00,\n",
       "                      -1.2459e+00,  9.1643e-01, -7.7305e-01, -9.9792e-01,  3.4901e+00,\n",
       "                      -6.3579e-01, -4.5672e-01,  2.9051e+00,  2.2056e+00,  9.4426e-01,\n",
       "                       2.4217e+00,  7.7935e-01,  1.5425e+00,  2.2898e+00,  1.9451e+00,\n",
       "                      -1.5768e+00,  4.3220e-01, -4.7807e-01, -2.0900e+00,  2.9282e+00,\n",
       "                       9.3307e-01,  2.1712e+00, -5.4417e-01,  2.1294e+00, -1.5700e+00,\n",
       "                       9.4141e-01,  2.4737e+00,  4.0605e+00, -5.7508e-01,  1.5358e-01,\n",
       "                      -8.4751e-01,  1.4040e+00, -8.9352e-01,  2.4118e-01,  2.4542e+00,\n",
       "                       1.2402e+00,  1.5031e+00,  2.1614e+00, -1.7141e+00,  9.3896e-02,\n",
       "                       2.4332e+00,  4.7321e-01,  2.1450e+00,  2.1084e+00,  2.4287e+00,\n",
       "                      -8.3261e-01,  8.3239e-01,  1.8453e+00,  2.2112e+00,  6.6744e-01,\n",
       "                       2.2387e+00, -1.4480e+00, -2.3371e+00, -1.0214e+00,  1.1836e+00,\n",
       "                      -1.8243e+00,  2.2923e+00, -1.4854e+00, -4.0224e-01,  1.8813e+00,\n",
       "                      -1.9866e+00,  1.0738e+00,  1.4107e+00,  1.7992e+00,  1.2142e+00,\n",
       "                      -1.8420e-02,  1.4143e+00, -2.3928e+00,  2.5399e+00, -3.5103e-01,\n",
       "                      -3.0407e+00, -1.3020e-01,  1.1537e-01, -6.2818e-01,  1.5018e+00,\n",
       "                      -3.0512e-01,  3.2660e+00,  1.3779e+00, -2.1777e-01, -2.3943e+00,\n",
       "                       3.3749e-01,  3.0884e-01, -1.3985e+00,  1.6472e-01,  7.6871e-01,\n",
       "                       1.5930e+00,  2.2732e+00,  2.5573e+00,  2.6006e+00,  1.5023e+00,\n",
       "                       1.1927e+00,  3.3585e+00, -7.5061e-01, -9.7153e-01, -2.7813e-01,\n",
       "                      -1.1527e+00, -1.5106e+00, -1.9820e+00,  1.2170e-01,  7.4365e-01,\n",
       "                       1.9538e+00,  1.8503e+00,  2.4014e+00, -8.9569e-01,  1.8297e+00,\n",
       "                       1.0189e+00,  3.0797e+00,  1.2530e+00, -1.0862e+00,  2.8023e+00,\n",
       "                      -1.4623e+00, -1.4450e+00,  1.7031e+00, -3.1743e+00, -2.2127e+00,\n",
       "                      -1.5806e+00,  2.6206e+00,  1.9436e+00,  3.9486e-01,  1.3385e+00,\n",
       "                      -6.5277e-01,  2.7884e+00,  1.7590e+00,  6.5796e-01,  1.1112e+00])),\n",
       "             ('BN5.running_var',\n",
       "              tensor([ 7.2532,  1.9405, 17.8715,  5.2744,  9.9644, 10.2869, 10.2382,  2.7201,\n",
       "                       4.3126,  5.9456,  3.1746,  7.6035, 15.6981,  2.3964, 13.2403,  5.5695,\n",
       "                       5.7790,  3.1273,  7.7899,  4.7981,  3.4229, 21.8118,  2.0321,  2.6718,\n",
       "                       9.5834,  1.7974,  7.8593,  2.5898,  4.1734,  8.0312,  3.6453,  6.6122,\n",
       "                       9.6595,  2.7728, 13.4569,  8.9305,  1.1259,  2.2175,  1.5956,  1.7698,\n",
       "                      10.1686,  6.4286,  2.3120,  7.9913, 13.6712,  5.2145,  3.6081,  5.0074,\n",
       "                       9.6818,  7.1129,  3.4409,  2.0160,  6.1128, 15.2289,  1.8343, 13.8877,\n",
       "                       2.9176,  1.8486,  3.0863,  1.4373,  3.6890,  1.5633, 15.5599,  2.5464,\n",
       "                       2.7809,  3.3227,  8.5498, 11.7026,  3.8657,  9.1368,  1.7751,  7.0028,\n",
       "                       3.2366,  2.0192,  1.8229,  5.9534,  5.4933,  3.9453,  4.4435, 13.7289,\n",
       "                       2.1480, 20.4665,  5.1043,  5.7249, 18.0924,  7.9807,  2.3776, 12.3186,\n",
       "                       1.8844,  5.2173,  6.7627,  4.0009,  4.4022,  7.0423,  7.7739,  4.6854,\n",
       "                       6.0636,  2.1697, 18.5234,  3.9592,  3.8645,  1.6304,  9.4176, 10.3820,\n",
       "                      12.1156,  5.6748,  6.9940,  2.7546,  6.2309, 13.7227, 11.7565,  7.6106,\n",
       "                       3.8132, 10.8640,  4.5602,  2.7534, 22.7965,  6.9652,  7.9815,  1.9157,\n",
       "                       6.2267,  5.4079,  4.8417,  6.8226, 16.8250,  3.4006,  4.7476,  2.7377,\n",
       "                       6.4223,  6.4178,  2.8435,  4.9753,  3.0189,  3.4270,  5.1784,  2.4646,\n",
       "                       1.7355,  2.8428,  4.7693, 20.7389, 10.0330,  5.9346,  6.2551,  8.1682,\n",
       "                       6.3348,  1.7507,  7.5335,  2.4527,  4.1831,  4.7808,  6.0819,  6.6991,\n",
       "                       4.0798,  2.1232,  2.4521,  5.3666,  3.8660,  3.4676, 10.4262,  6.0294,\n",
       "                      12.8773,  2.7557,  3.0285,  2.1662,  4.9086,  9.6399,  4.4241,  5.7733,\n",
       "                      13.7215,  4.7247,  3.7674,  3.3874, 10.1284,  4.6298,  4.6590,  6.4984,\n",
       "                       1.8598,  9.9029,  3.0167,  4.1864, 20.3163,  7.1198,  4.3768,  2.1114,\n",
       "                       2.7198,  2.2814,  6.1196,  2.3521,  4.4638,  9.2184,  8.7291,  8.5412,\n",
       "                      19.7230,  1.5054,  3.1507,  4.9861,  4.0015, 12.4347,  7.6735, 24.9291,\n",
       "                      24.6139,  5.6982,  6.1977,  6.4524, 22.3908,  2.8511,  8.0678, 13.0066,\n",
       "                      16.0550,  4.9775,  4.0754,  9.2931, 11.2178, 12.3547, 18.2351, 11.1871,\n",
       "                      18.2715,  6.2778,  4.1450,  1.8076,  4.2435,  3.3234, 10.6566,  3.3695,\n",
       "                       4.6325,  5.3722,  4.2648, 22.6518,  6.3347, 11.1681,  2.1375,  5.1601,\n",
       "                       3.5734,  4.2694,  1.5297, 17.4888,  4.1426,  3.9228,  4.6961,  4.6792,\n",
       "                      22.2233, 12.4803,  5.0539,  4.9406, 13.0501,  3.0167,  4.6684,  3.7916,\n",
       "                       2.1198, 16.9970,  2.9319,  7.0561,  3.2862,  2.0004, 11.8567,  3.5194,\n",
       "                       2.0469, 14.0015,  8.6037,  2.6823, 10.6336, 12.6303,  2.0753, 20.2695,\n",
       "                       3.6855,  9.2480,  2.2989, 17.2457,  3.3061,  8.1133,  3.5875,  1.4752,\n",
       "                       4.2108, 17.5157,  3.8541,  4.6818, 18.1330,  3.2819,  6.9779,  2.8516,\n",
       "                       6.2329,  4.1118,  9.5482,  2.2555,  3.8180,  2.9151,  5.1858, 16.9876,\n",
       "                      13.8509,  2.2952,  1.8529,  4.3523,  1.9112,  6.7114, 14.5063, 11.3795,\n",
       "                       8.0186, 14.8956,  5.8980,  6.2112, 18.2452,  6.1899, 14.3595,  4.4817,\n",
       "                       6.7397,  3.4852, 13.8759,  3.6031,  7.8161, 12.2227,  4.0397,  5.8882,\n",
       "                      15.7377,  8.6298,  8.7554,  5.3718,  5.1114,  2.9882,  4.2762,  3.7239,\n",
       "                       9.9929, 20.5431,  3.2139,  7.7336,  6.2211,  6.6797,  8.0582,  2.4771,\n",
       "                       4.5632,  2.6714,  3.8621,  1.7398, 13.7798,  9.0242,  2.6779,  1.6783,\n",
       "                      11.2160,  9.3414,  3.2587, 14.0863,  9.6937,  6.3972,  5.0391, 11.0114,\n",
       "                       5.0322,  1.9145, 14.8071, 27.4382,  6.3546,  2.5500,  7.8558,  4.2366,\n",
       "                       4.9099,  1.7455,  7.9855,  4.0740,  2.4233,  4.1245,  7.0696,  2.7432,\n",
       "                      14.7143,  1.8104,  1.9659,  3.7889,  3.1957,  5.4865,  5.2737,  4.8309,\n",
       "                       2.9943, 10.8239,  2.6101,  3.6809,  6.6777,  3.1940,  5.2572, 10.6138,\n",
       "                       2.7130,  5.1067,  2.2021,  9.9014,  5.4375,  1.9572,  8.5156, 13.4660,\n",
       "                       5.5665,  5.6260,  4.4503,  6.2711,  4.0361,  5.0769,  1.5572,  8.8429,\n",
       "                       3.9433,  4.8764, 16.6769,  2.6190,  7.7370,  3.6398,  8.9859,  5.0212,\n",
       "                       4.0655, 10.4996,  6.5584,  6.9517,  2.7953,  2.4513,  1.8823,  3.3946,\n",
       "                       1.8995,  8.8572, 14.2767,  5.7156,  3.5095,  1.2522,  1.8193,  6.2119,\n",
       "                       3.9140,  1.6966,  4.5839, 10.1192,  3.1955, 10.4882,  5.6852,  6.6781,\n",
       "                       4.1408, 13.6284, 13.0729,  4.9012,  5.3906, 13.5186,  2.8968, 16.1202,\n",
       "                      10.1519,  5.4530, 12.7103,  8.3124, 16.7730, 13.2158,  7.6191,  2.6143,\n",
       "                       5.0365, 10.4671,  2.0139, 13.8560,  6.5633,  7.8151,  4.9928,  2.4415,\n",
       "                       2.4757,  8.0232,  2.0601, 19.1912,  8.0927,  3.1674, 17.0445,  5.4094,\n",
       "                       3.2163, 16.6150,  3.6494, 11.1771, 14.7876, 15.1662,  6.6592, 21.0555,\n",
       "                       9.4455,  3.0916, 18.1143,  3.3550,  6.0961,  4.4565,  3.7559,  2.8711,\n",
       "                       2.6376,  2.6223,  7.4259,  2.8982,  3.6674, 12.1163,  7.4848, 11.5068,\n",
       "                       4.9039, 11.9047,  5.2286,  2.8972, 16.3892,  3.2675,  4.7352,  6.9513,\n",
       "                       4.2353,  1.6378,  5.4943,  8.1746,  3.3710,  5.3273,  4.0183,  5.6844,\n",
       "                       7.9928, 21.2849,  5.4273,  2.3044])),\n",
       "             ('BN5.num_batches_tracked', tensor(1200)),\n",
       "             ('dec_3.weight',\n",
       "              tensor([[ 0.0088,  0.0279, -0.0535,  ...,  0.0338, -0.0323, -0.0875],\n",
       "                      [-0.0198,  0.0342,  0.0190,  ..., -0.0221,  0.0256,  0.0249],\n",
       "                      [-0.0388, -0.0013, -0.0277,  ...,  0.0067,  0.0062,  0.0139],\n",
       "                      ...,\n",
       "                      [-0.0441, -0.0414, -0.0353,  ...,  0.0303, -0.0416, -0.0753],\n",
       "                      [ 0.0258, -0.0273,  0.0044,  ..., -0.0123, -0.0468, -0.0082],\n",
       "                      [-0.0342, -0.0550, -0.0442,  ..., -0.0115, -0.0315, -0.0129]])),\n",
       "             ('dec_3.bias',\n",
       "              tensor([ 4.1636e-02,  3.4160e-02, -4.3423e-03, -4.0886e-02, -3.3976e-02,\n",
       "                       2.7190e-02, -1.3130e-02,  1.9077e-02, -6.5487e-03, -1.9242e-02,\n",
       "                      -1.0288e-02,  1.6412e-02,  3.2023e-02,  1.5355e-02,  3.4894e-02,\n",
       "                      -1.8381e-02,  2.8879e-03,  1.4771e-02, -1.0260e-02, -4.1115e-02,\n",
       "                       1.7250e-02,  1.6681e-02,  2.4622e-03, -1.5801e-02,  3.1284e-02,\n",
       "                       1.7592e-02, -1.2495e-02,  3.6496e-02,  1.6355e-02, -1.7242e-04,\n",
       "                      -2.6294e-02, -4.9339e-03,  1.5501e-02,  1.0451e-02, -2.0247e-02,\n",
       "                      -1.3424e-02,  3.4363e-02, -2.4348e-02,  4.4219e-02, -2.3815e-02,\n",
       "                      -3.5559e-02,  2.9780e-02, -1.9191e-02,  3.8352e-02,  3.4910e-02,\n",
       "                      -3.4076e-02, -2.2784e-02,  3.3712e-02,  8.1337e-03,  3.5895e-02,\n",
       "                       3.7475e-02, -3.6709e-02,  3.4662e-02, -2.0569e-02,  4.1802e-02,\n",
       "                       3.7615e-02, -3.0105e-02, -8.3173e-03, -1.3486e-02, -5.9728e-03,\n",
       "                      -3.2303e-02, -2.3118e-02,  9.8846e-03,  1.2942e-02, -4.0243e-02,\n",
       "                      -1.4105e-03,  1.2593e-02,  3.0878e-02,  3.0876e-02, -4.3536e-03,\n",
       "                       1.3148e-02, -4.0234e-02, -1.1198e-03, -3.0191e-02, -4.1998e-02,\n",
       "                       1.0743e-02, -2.8837e-02, -3.1189e-02,  2.2661e-02,  4.2126e-02,\n",
       "                       3.1668e-02, -7.4323e-03,  5.2503e-03,  1.9212e-02,  3.0108e-02,\n",
       "                       3.0128e-02, -1.6286e-03,  4.4574e-03, -2.5857e-03,  3.6367e-02,\n",
       "                       1.6274e-02,  2.9679e-02,  2.9044e-02,  1.3367e-02, -1.3242e-02,\n",
       "                      -3.7375e-02,  8.2777e-03, -3.7200e-03, -6.0136e-05, -2.2064e-02,\n",
       "                       2.1563e-02,  1.3902e-02, -4.0300e-02,  1.4468e-02, -2.3851e-02,\n",
       "                      -8.0263e-05, -2.8858e-02,  1.2928e-02,  1.8541e-02,  1.4592e-02,\n",
       "                      -3.3836e-02, -4.3631e-02,  1.7958e-02,  1.4216e-02, -1.5427e-02,\n",
       "                       2.9249e-02,  3.8636e-02,  4.3746e-03, -9.7062e-03, -4.0159e-02,\n",
       "                       2.8702e-02, -2.6973e-02, -2.4747e-02, -1.4299e-03,  4.4739e-02,\n",
       "                       5.4259e-03, -3.7924e-03,  3.4222e-02,  3.7799e-02, -3.6317e-02,\n",
       "                      -1.6167e-03, -1.9983e-02,  2.7488e-02,  2.9536e-02, -5.8993e-03,\n",
       "                       1.9235e-02,  4.0648e-02,  1.2865e-02, -1.6238e-02,  2.4322e-02,\n",
       "                       1.5420e-02, -3.9134e-02, -1.4500e-02, -4.0255e-02,  1.4286e-02,\n",
       "                      -6.3149e-03,  4.2622e-02,  1.3029e-02,  2.2265e-02,  2.6134e-02,\n",
       "                      -3.2169e-02,  4.4052e-02,  3.5509e-02,  3.6079e-02, -3.5881e-02,\n",
       "                      -2.4100e-02, -2.6083e-02,  4.1842e-03, -1.7400e-02, -1.9774e-02,\n",
       "                       8.3457e-03,  3.8195e-02, -3.9250e-02,  1.0528e-02,  8.1545e-03,\n",
       "                       2.0323e-02,  1.0527e-02, -3.2915e-02,  3.3761e-02,  3.0374e-02,\n",
       "                      -3.2949e-02, -3.0488e-02,  2.2180e-02,  7.4119e-03, -2.3850e-02,\n",
       "                       1.0476e-02, -2.7109e-02,  1.7804e-02,  2.0515e-02,  1.9435e-02,\n",
       "                      -3.6782e-02,  1.5709e-02, -1.7097e-02,  2.3717e-02,  9.5430e-03,\n",
       "                       9.7332e-04, -5.0302e-04, -4.1879e-02,  2.7091e-02,  3.4661e-02,\n",
       "                       4.1090e-02,  9.7079e-03,  3.4592e-02, -2.6803e-02,  3.7053e-02,\n",
       "                      -2.2922e-02, -1.3342e-02,  1.0330e-02,  2.0029e-02,  2.2718e-02,\n",
       "                       3.5734e-02, -1.3392e-02,  2.1368e-02,  4.8568e-04, -1.0200e-02,\n",
       "                       3.2215e-02,  1.4086e-02, -1.2352e-02,  3.7019e-02, -2.5749e-02,\n",
       "                       3.6154e-02, -4.4180e-02, -4.3187e-03,  2.2519e-02, -4.3248e-02,\n",
       "                      -3.4053e-02,  3.0934e-02, -8.2658e-03, -1.9493e-02, -1.9445e-02,\n",
       "                       1.3255e-02,  2.7812e-02,  9.8421e-03,  1.6480e-02,  1.1481e-02,\n",
       "                       3.2518e-02,  3.3463e-02,  4.3488e-02,  3.2142e-02, -5.7501e-03,\n",
       "                       2.3327e-02, -4.3822e-02, -2.1723e-02,  4.3395e-03, -2.4545e-02,\n",
       "                      -6.1233e-03,  3.7329e-02, -4.5284e-03, -1.7443e-02, -1.8033e-02,\n",
       "                       1.4546e-02,  2.9369e-02, -6.1576e-03,  3.3856e-02, -1.9620e-02,\n",
       "                       1.4964e-02, -2.8554e-02, -1.5058e-02,  2.1130e-02,  2.9780e-02,\n",
       "                       4.4380e-02,  7.6182e-03, -4.4541e-02, -4.1765e-02,  7.2436e-04,\n",
       "                       8.5878e-03, -2.6658e-02, -9.7804e-03,  3.7739e-02, -3.2966e-02,\n",
       "                      -3.6702e-02,  2.7576e-02, -1.9899e-02, -6.8509e-04,  3.5900e-03,\n",
       "                       2.9099e-02, -4.1276e-02, -1.0121e-03, -5.0506e-03, -3.3363e-02,\n",
       "                      -3.6215e-02,  1.4843e-02,  2.0862e-02, -1.9372e-02, -3.2081e-03,\n",
       "                      -3.0682e-02, -4.1856e-02, -1.7644e-02, -3.3873e-02, -1.7605e-02,\n",
       "                       3.1906e-02, -2.0034e-02,  2.1118e-02, -8.3292e-03, -2.3868e-02,\n",
       "                       3.7338e-02, -3.6606e-02,  2.4030e-02,  3.5064e-02, -4.3933e-02,\n",
       "                       4.2018e-02,  4.2700e-02,  2.6462e-02,  4.1299e-02,  4.1478e-02,\n",
       "                       6.3590e-04, -2.4626e-02,  4.8607e-03,  4.2906e-02, -2.4730e-02,\n",
       "                       1.7506e-02,  2.8732e-03,  1.1020e-02,  2.5439e-02,  7.8700e-03,\n",
       "                      -1.8108e-02, -4.3862e-02, -2.8785e-02,  2.9907e-02,  1.5033e-02,\n",
       "                      -4.0632e-04, -2.6857e-02, -1.4527e-02,  3.9371e-02,  2.8452e-02,\n",
       "                       3.8617e-02,  2.8177e-02,  7.0489e-03, -3.5499e-02,  1.6192e-02,\n",
       "                      -2.0345e-02,  1.1187e-02, -4.4484e-03, -2.9837e-02, -1.9813e-02,\n",
       "                       2.9986e-02,  2.1672e-02,  1.6812e-02, -7.0237e-03,  8.7495e-03,\n",
       "                       2.4917e-03, -3.0964e-02,  1.9517e-02,  1.5719e-02, -2.1245e-02,\n",
       "                      -4.0994e-02, -2.0676e-02,  4.2070e-02,  2.2260e-02, -2.2154e-02,\n",
       "                       2.1531e-02,  1.6994e-03,  3.3883e-02, -1.8832e-02, -1.5232e-02,\n",
       "                       4.2723e-02, -1.8889e-02,  3.9209e-02, -3.7557e-02, -1.0731e-02,\n",
       "                      -4.8679e-03, -6.5660e-03, -1.3582e-02, -2.8190e-02,  1.0021e-02,\n",
       "                      -2.6747e-02,  2.2209e-02,  1.5633e-02,  2.9491e-02, -3.5333e-02,\n",
       "                      -4.1042e-02, -3.7019e-03, -6.5639e-03,  2.7440e-03,  1.9925e-02,\n",
       "                      -9.7731e-03, -3.4928e-02,  2.2492e-02, -4.4178e-02,  3.5918e-02,\n",
       "                       8.4503e-03,  4.3874e-02, -2.2835e-02, -3.5740e-02, -3.8545e-02,\n",
       "                      -3.6673e-02, -2.4935e-02,  1.9353e-02,  1.1106e-02, -2.1996e-02,\n",
       "                       2.0529e-02,  1.2430e-03, -8.6510e-03,  3.0858e-02,  3.9167e-02,\n",
       "                      -1.5743e-02,  1.3584e-02, -4.2881e-02, -2.1601e-02,  3.9471e-02,\n",
       "                      -1.1225e-02, -3.6228e-02,  3.9629e-02, -1.0541e-02, -4.4585e-02,\n",
       "                       4.4718e-02,  4.2799e-03, -1.4360e-02,  2.2399e-03, -8.1273e-03,\n",
       "                       8.3583e-03, -2.1959e-02, -4.3192e-02,  2.0128e-02, -3.4963e-02,\n",
       "                      -4.0603e-02,  9.5553e-03,  1.7324e-02, -3.2940e-02,  2.1954e-02,\n",
       "                       1.6604e-02,  3.4300e-02,  4.4232e-02,  2.8245e-02, -3.2919e-02,\n",
       "                       3.1215e-03, -5.0518e-03,  2.1023e-03,  1.7373e-02, -7.4522e-03,\n",
       "                       2.7078e-02, -4.0218e-03, -1.2299e-02,  3.0493e-02,  2.8318e-02,\n",
       "                       1.2392e-02,  1.6803e-02, -2.6127e-02, -2.1406e-02, -2.7228e-02,\n",
       "                      -9.3412e-03,  1.4647e-02,  6.2609e-03, -1.4029e-02, -2.6393e-02,\n",
       "                      -8.7485e-03,  4.0496e-02, -1.7222e-02,  4.2581e-02, -4.3406e-02,\n",
       "                      -7.2460e-03, -3.6495e-02, -2.5665e-02, -1.4956e-02,  7.1812e-04,\n",
       "                       3.1083e-02,  3.0807e-02,  1.4015e-02,  3.1599e-02, -2.4435e-03,\n",
       "                      -1.2563e-02, -8.7195e-03,  9.3456e-03,  3.7382e-02,  4.2434e-02,\n",
       "                      -4.3560e-02, -1.9091e-02, -1.5682e-02,  2.1773e-02, -2.9888e-02,\n",
       "                       1.5674e-02, -1.6060e-02,  2.7360e-02, -3.1989e-02, -1.8874e-03,\n",
       "                       3.6744e-02,  9.1589e-03, -7.5688e-03, -1.9677e-02, -9.3632e-03,\n",
       "                      -1.8146e-02,  4.0351e-02,  1.6748e-02, -3.4785e-02, -1.8042e-02,\n",
       "                      -1.3497e-02, -6.4078e-03, -2.3753e-02,  2.1759e-02, -2.2422e-02,\n",
       "                       3.5764e-02, -1.6387e-02, -1.9584e-02, -2.2568e-02, -1.3226e-02,\n",
       "                      -2.6327e-02, -3.3644e-02,  2.1641e-02,  2.3978e-02, -3.7382e-02,\n",
       "                       4.0807e-04,  1.7405e-02, -1.5548e-02,  4.0168e-03, -6.9898e-03,\n",
       "                      -2.6264e-02, -4.7024e-03,  5.2434e-03, -1.0574e-02,  1.5065e-02])),\n",
       "             ('BN6.weight',\n",
       "              tensor([0.9859, 0.9885, 0.9807, 0.9855, 0.9822, 0.9799, 0.9861, 0.9825, 0.9843,\n",
       "                      0.9839, 0.9875, 0.9954, 0.9780, 0.9879, 0.9877, 0.9838, 0.9960, 0.9881,\n",
       "                      0.9885, 0.9840, 0.9974, 0.9899, 0.9828, 0.9956, 0.9804, 0.9848, 0.9796,\n",
       "                      0.9877, 0.9887, 0.9822, 0.9807, 0.9794, 0.9825, 0.9834, 0.9850, 0.9923,\n",
       "                      0.9810, 0.9905, 0.9841, 0.9913, 0.9881, 0.9813, 0.9812, 0.9841, 0.9816,\n",
       "                      0.9802, 1.0040, 0.9821, 0.9844, 0.9859, 0.9876, 0.9866, 1.0129, 0.9831,\n",
       "                      0.9843, 0.9800, 0.9927, 0.9889, 0.9909, 0.9812, 0.9828, 0.9893, 0.9855,\n",
       "                      0.9944, 0.9812, 0.9889, 0.9823, 0.9809, 0.9828, 0.9902, 0.9815, 0.9825,\n",
       "                      0.9883, 0.9990, 0.9818, 0.9803, 1.0001, 0.9813, 0.9880, 0.9822, 0.9828,\n",
       "                      0.9875, 0.9852, 0.9846, 0.9794, 0.9833, 0.9852, 0.9971, 0.9930, 0.9978,\n",
       "                      0.9938, 0.9808, 0.9766, 0.9911, 0.9829, 1.0023, 0.9878, 1.0387, 0.9825,\n",
       "                      0.9866, 0.9962, 0.9890, 0.9880, 0.9968, 0.9807, 0.9801, 0.9829, 0.9885,\n",
       "                      0.9883, 0.9920, 0.9893, 0.9886, 0.9887, 0.9840, 0.9895, 0.9956, 0.9819,\n",
       "                      0.9867, 0.9897, 0.9814, 0.9850, 0.9960, 0.9859, 0.9833, 0.9852, 1.0162,\n",
       "                      0.9911, 0.9983, 0.9939, 1.0386, 0.9822, 0.9838, 0.9850, 1.0208, 0.9811,\n",
       "                      0.9885, 0.9853, 0.9849, 0.9854, 0.9835, 0.9819, 0.9819, 0.9800, 0.9911,\n",
       "                      0.9760, 0.9893, 0.9821, 0.9840, 0.9851, 0.9831, 0.9819, 0.9832, 0.9814,\n",
       "                      0.9960, 0.9818, 0.9762, 0.9799, 0.9841, 0.9862, 0.9893, 0.9884, 0.9827,\n",
       "                      0.9950, 0.9838, 0.9837, 0.9893, 0.9808, 0.9926, 0.9837, 0.9869, 0.9797,\n",
       "                      0.9929, 0.9839, 0.9872, 0.9826, 0.9903, 0.9836, 0.9844, 0.9802, 0.9896,\n",
       "                      0.9905, 0.9821, 0.9831, 0.9912, 0.9926, 0.9823, 0.9836, 0.9908, 0.9830,\n",
       "                      0.9780, 0.9882, 0.9836, 0.9798, 0.9896, 0.9809, 0.9947, 0.9924, 0.9888,\n",
       "                      0.9841, 0.9841, 0.9954, 0.9791, 1.0020, 0.9834, 0.9889, 0.9848, 0.9871,\n",
       "                      0.9910, 0.9795, 0.9815, 0.9835, 0.9825, 0.9838, 0.9923, 0.9935, 0.9920,\n",
       "                      0.9782, 0.9836, 0.9828, 0.9849, 0.9810, 0.9908, 0.9831, 0.9869, 0.9878,\n",
       "                      0.9811, 0.9837, 0.9899, 0.9857, 0.9838, 0.9843, 0.9925, 0.9851, 0.9908,\n",
       "                      0.9829, 0.9883, 0.9988, 0.9849, 0.9813, 0.9981, 0.9795, 0.9811, 0.9905,\n",
       "                      0.9797, 0.9832, 0.9835, 0.9909, 0.9840, 0.9873, 0.9908, 0.9962, 0.9879,\n",
       "                      0.9949, 0.9903, 0.9904, 0.9781, 0.9905, 0.9810, 0.9807, 0.9818, 0.9924,\n",
       "                      0.9857, 0.9915, 0.9788, 0.9833, 0.9817, 0.9883, 0.9861, 0.9792, 0.9820,\n",
       "                      0.9839, 0.9677, 0.9864, 0.9951, 0.9815, 0.9809, 0.9892, 0.9839, 0.9826,\n",
       "                      0.9791, 0.9766, 0.9929, 0.9906, 0.9817, 0.9838, 0.9874, 0.9805, 0.9832,\n",
       "                      0.9866, 0.9947, 0.9815, 0.9844, 0.9905, 0.9854, 0.9856, 0.9821, 0.9824,\n",
       "                      0.9813, 0.9900, 0.9876, 0.9809, 0.9860, 0.9861, 0.9882, 0.9894, 0.9807,\n",
       "                      0.9834, 0.9852, 0.9902, 0.9806, 0.9850, 0.9817, 0.9854, 0.9848, 0.9823,\n",
       "                      0.9910, 0.9823, 0.9907, 0.9866, 0.9838, 0.9966, 0.9856, 0.9888, 0.9888,\n",
       "                      0.9819, 0.9939, 0.9878, 0.9805, 0.9822, 0.9787, 0.9903, 0.9825, 0.9798,\n",
       "                      0.9870, 0.9847, 0.9875, 0.9864, 0.9893, 0.9813, 0.9939, 0.9941, 0.9841,\n",
       "                      0.9890, 0.9928, 0.9840, 0.9824, 0.9819, 0.9890, 0.9900, 0.9826, 0.9822,\n",
       "                      0.9892, 0.9915, 0.9901, 1.0139, 0.9826, 0.9910, 0.9879, 0.9802, 0.9883,\n",
       "                      0.9854, 0.9833, 0.9771, 0.9922, 0.9876, 0.9902, 0.9866, 0.9980, 0.9785,\n",
       "                      0.9825, 0.9836, 0.9827, 1.0385, 0.9844, 0.9795, 0.9817, 0.9927, 0.9887,\n",
       "                      0.9859, 0.9817, 0.9838, 0.9932, 0.9811, 0.9860, 0.9844, 0.9792, 0.9883,\n",
       "                      0.9825, 0.9831, 0.9906, 0.9781, 0.9883, 0.9905, 0.9817, 0.9807, 0.9860,\n",
       "                      0.9768, 0.9878, 0.9846, 0.9831, 0.9918, 1.0196, 0.9806, 0.9820, 0.9813,\n",
       "                      0.9842, 0.9888, 0.9815, 0.9829, 0.9819, 0.9840, 0.9872, 0.9905, 0.9858,\n",
       "                      0.9844, 0.9829, 0.9828, 0.9882, 0.9923, 0.9832, 0.9903, 0.9872, 1.0148,\n",
       "                      0.9802, 0.9949, 1.0151, 0.9929, 0.9823, 0.9995, 0.9827, 0.9949, 0.9866,\n",
       "                      1.0192, 0.9913, 0.9890, 0.9888, 0.9800, 0.9826, 0.9854, 0.9976, 0.9889,\n",
       "                      0.9775, 0.9828, 0.9830, 0.9820, 0.9835, 0.9826, 0.9903, 0.9846, 0.9837,\n",
       "                      0.9835, 0.9851, 0.9960, 0.9835, 0.9867, 0.9852, 0.9812, 0.9807, 0.9799,\n",
       "                      0.9845, 0.9846, 1.0366, 0.9825, 0.9891, 0.9965, 0.9929, 0.9789, 0.9884,\n",
       "                      0.9941, 0.9896, 0.9841, 1.0199, 0.9916, 0.9865, 0.9833, 1.0254, 0.9899,\n",
       "                      0.9829, 0.9847, 0.9803, 0.9815, 0.9880, 0.9920, 0.9800, 1.0290, 1.0005,\n",
       "                      0.9849, 0.9861, 0.9846, 0.9852, 0.9870, 0.9822, 0.9817, 0.9866, 0.9812,\n",
       "                      0.9800, 0.9828, 0.9878, 0.9816, 0.9821])),\n",
       "             ('BN6.bias',\n",
       "              tensor([-4.9376e-04, -9.7267e-03, -1.9141e-02, -5.7079e-03, -1.7835e-02,\n",
       "                      -2.1480e-02, -4.1949e-03, -1.2554e-02, -5.6183e-03, -9.3330e-03,\n",
       "                      -9.1734e-03,  1.4204e-02, -2.0720e-02, -2.1954e-02, -7.9571e-03,\n",
       "                      -1.3874e-02,  2.4561e-02, -1.4930e-02,  9.3677e-04, -1.7749e-02,\n",
       "                       1.1446e-02, -1.1285e-02, -9.2531e-03,  2.9573e-03, -2.8928e-02,\n",
       "                      -2.4496e-02, -2.4207e-02, -9.2040e-03, -6.7968e-03, -1.1258e-02,\n",
       "                      -1.6842e-02, -2.0164e-02, -1.4904e-02, -1.0293e-02, -1.1694e-02,\n",
       "                       9.0475e-03, -6.0318e-03,  1.1561e-03, -1.3711e-02, -1.1742e-02,\n",
       "                      -1.1826e-02, -1.2919e-02, -2.1872e-02, -9.7489e-03, -1.9391e-02,\n",
       "                      -1.3360e-02,  1.7873e-02, -9.0909e-03, -1.5241e-02, -9.9406e-03,\n",
       "                      -2.4183e-03, -8.2349e-03, -3.6289e-03, -2.4988e-02, -6.5373e-03,\n",
       "                      -2.8627e-02, -5.5874e-03, -9.8353e-03, -5.7750e-03, -3.3783e-02,\n",
       "                      -2.0301e-02, -6.7082e-03, -4.0800e-03, -1.0566e-02, -2.2526e-02,\n",
       "                      -1.4786e-02, -1.7458e-02, -1.6077e-02, -1.8142e-02, -4.0985e-03,\n",
       "                      -2.7540e-02, -1.1575e-02,  1.7748e-02,  1.3608e-02, -1.9128e-02,\n",
       "                      -2.1691e-02,  2.4300e-02, -1.5576e-02,  9.2255e-04, -6.3051e-03,\n",
       "                      -1.5338e-02, -2.6949e-03, -2.2231e-02, -1.3851e-02, -1.2292e-02,\n",
       "                      -1.8729e-02, -8.0685e-03,  3.2151e-02, -5.6968e-03,  2.5460e-02,\n",
       "                       4.6598e-03, -2.7824e-02, -2.2611e-02, -5.5752e-03, -1.3223e-02,\n",
       "                       1.6833e-02,  8.6744e-03,  1.0790e-03, -3.4784e-02, -5.9273e-03,\n",
       "                       1.2713e-03,  6.7577e-04, -7.9915e-03,  2.1606e-02, -1.7249e-02,\n",
       "                      -5.5815e-03, -1.5333e-02, -5.0634e-03, -8.8183e-03,  1.2196e-03,\n",
       "                       1.2217e-02, -1.5982e-02, -1.2736e-02, -1.5357e-02, -8.0712e-04,\n",
       "                       1.1726e-02, -1.0461e-02, -1.0527e-02, -1.3265e-02, -3.2641e-03,\n",
       "                      -1.0216e-02,  1.2321e-02, -6.3453e-03, -1.0861e-02, -2.1245e-02,\n",
       "                       3.6298e-02, -4.7982e-04,  2.6596e-02,  1.7583e-02,  2.2551e-02,\n",
       "                      -1.5301e-02, -9.0490e-03, -1.4196e-02,  2.0854e-02, -1.9174e-02,\n",
       "                      -1.0654e-02, -1.7773e-02, -8.2118e-03, -1.0827e-02, -1.9616e-02,\n",
       "                      -1.3841e-02, -2.8636e-02, -1.1620e-02, -1.5773e-02, -2.2412e-02,\n",
       "                      -7.5509e-03, -6.1905e-03, -1.9138e-02, -2.0678e-02, -1.3866e-02,\n",
       "                      -1.3979e-02, -1.1044e-02, -2.0413e-02,  1.2517e-02, -1.9695e-02,\n",
       "                      -2.9748e-02, -3.0305e-02, -1.4786e-02, -1.7282e-02, -6.4253e-03,\n",
       "                      -5.8594e-03, -3.9040e-03,  5.3047e-03, -1.4417e-02, -3.1208e-03,\n",
       "                       6.7334e-03, -1.2188e-02, -1.1100e-02, -2.7352e-03, -7.6682e-05,\n",
       "                      -2.5858e-02,  7.1621e-03, -2.2681e-02, -1.7794e-02, -1.8584e-02,\n",
       "                      -4.5719e-03, -2.3109e-02, -2.0306e-02, -1.8955e-02, -3.8466e-03,\n",
       "                       7.7018e-03, -1.2148e-02,  7.5622e-03, -1.0671e-02,  2.3709e-03,\n",
       "                      -8.3533e-03, -1.6376e-02, -1.3832e-02, -1.3998e-02, -1.5129e-02,\n",
       "                      -1.0380e-02, -3.4561e-02, -3.6230e-02,  1.7397e-04, -8.7046e-03,\n",
       "                       2.1173e-02, -2.3603e-03,  1.0609e-02, -1.1022e-02, -2.0851e-02,\n",
       "                      -1.8227e-03, -1.4537e-02,  1.3006e-02, -3.6897e-02, -8.8219e-03,\n",
       "                      -9.8274e-03,  3.2586e-03,  4.3446e-03, -2.0336e-02, -1.8330e-02,\n",
       "                      -2.4010e-02, -1.7217e-02, -1.5028e-02,  5.8101e-03,  1.0279e-02,\n",
       "                       1.4033e-04, -2.3986e-02, -6.5104e-03, -3.9990e-03,  8.6983e-04,\n",
       "                      -2.0600e-02, -1.1344e-02, -1.7537e-02, -1.3246e-02, -1.5817e-02,\n",
       "                      -9.5776e-03, -2.8525e-03, -9.6751e-03, -2.5580e-02, -8.7921e-04,\n",
       "                      -1.3368e-02,  3.8514e-03, -1.4215e-02, -6.1808e-03, -2.5376e-02,\n",
       "                      -1.2362e-02,  5.5749e-03, -1.5271e-02, -1.7141e-02,  2.5229e-02,\n",
       "                      -2.2668e-02, -3.4882e-02, -1.3900e-02, -1.4723e-02, -3.3561e-03,\n",
       "                      -1.6085e-02,  3.9865e-03, -7.8736e-03, -1.4506e-02, -1.5711e-02,\n",
       "                       1.0377e-02, -2.2471e-02,  4.7864e-03, -5.8235e-03,  3.6813e-03,\n",
       "                      -2.3729e-02, -1.3280e-02, -1.0560e-02, -1.3929e-02, -3.2727e-02,\n",
       "                       1.9854e-02, -3.5305e-03, -1.6010e-02, -2.7187e-02, -1.0115e-02,\n",
       "                      -1.3473e-02, -6.6118e-03, -1.3313e-02, -6.2251e-03, -2.1252e-02,\n",
       "                      -2.5051e-03, -2.6781e-02, -1.6922e-02,  3.9260e-03, -1.4989e-02,\n",
       "                      -2.1591e-02,  1.0352e-03, -6.1722e-03, -1.0092e-02, -2.2520e-02,\n",
       "                      -4.1495e-03,  5.0484e-03, -2.0601e-03, -2.1040e-02, -8.3900e-03,\n",
       "                      -8.4147e-03, -2.1793e-02, -2.0858e-02, -2.5136e-02,  1.7720e-03,\n",
       "                      -2.8505e-02, -2.2304e-02, -1.2283e-02, -8.5817e-03, -4.1257e-03,\n",
       "                      -1.7386e-02, -1.8951e-03, -2.4333e-02, -7.0426e-03, -1.6100e-02,\n",
       "                      -1.3139e-02, -1.4227e-02, -1.3326e-02, -2.4862e-03, -9.7385e-03,\n",
       "                      -1.8134e-02, -1.1187e-02, -1.6839e-02, -1.1567e-02, -1.9480e-02,\n",
       "                       6.6429e-03, -1.2658e-02,  1.2196e-03, -1.3768e-02, -2.1493e-02,\n",
       "                      -1.4651e-02, -2.1904e-02, -5.6036e-03,  3.0886e-03, -1.9383e-02,\n",
       "                       8.3345e-03, -1.0452e-02,  2.8129e-03, -7.6046e-03, -1.9875e-02,\n",
       "                       1.3225e-02, -1.6914e-03, -1.5906e-02, -1.6370e-02, -1.4960e-02,\n",
       "                      -7.7667e-03, -1.1717e-02, -2.1775e-02,  1.0136e-03, -2.3933e-02,\n",
       "                      -7.0614e-03, -9.3287e-03, -1.4575e-02, -2.3840e-02,  1.0725e-02,\n",
       "                      -7.0845e-03,  7.3449e-03,  6.8639e-03,  1.0546e-03, -2.6500e-02,\n",
       "                      -1.9257e-02, -9.8655e-03, -9.8919e-03, -1.5662e-03, -1.8869e-03,\n",
       "                      -2.5597e-02,  9.1670e-03, -1.1235e-02, -7.2023e-03,  4.5153e-02,\n",
       "                      -1.8038e-02, -6.5459e-04, -2.0410e-02, -2.1747e-02, -6.7641e-03,\n",
       "                      -6.4531e-03, -1.5529e-03, -2.5293e-02, -3.9524e-03,  3.9412e-03,\n",
       "                      -5.1093e-04, -6.5868e-03,  1.2514e-02, -2.4834e-02, -3.0394e-02,\n",
       "                      -7.4521e-03, -1.9796e-02,  2.5015e-02, -1.9238e-02, -1.3623e-02,\n",
       "                      -7.4240e-03, -4.6559e-03, -1.8969e-02, -2.1450e-02, -2.9548e-02,\n",
       "                      -2.4433e-02, -6.7390e-03, -7.9073e-03, -1.3619e-02, -2.4712e-02,\n",
       "                      -5.5644e-03, -1.9767e-02, -1.7930e-02, -1.5604e-02, -5.6135e-03,\n",
       "                      -1.9495e-02, -8.9464e-03,  4.3320e-04, -1.4345e-02, -2.4830e-02,\n",
       "                      -1.3312e-02, -3.3120e-02, -1.1232e-03, -2.0721e-02, -2.0563e-02,\n",
       "                       5.9269e-03,  2.9671e-02, -2.3332e-02, -2.2408e-02, -4.4121e-03,\n",
       "                      -5.7755e-03, -1.6572e-02, -2.3625e-02, -1.3994e-02, -1.5762e-02,\n",
       "                      -1.1979e-02, -1.1884e-02,  8.1021e-03, -7.0155e-03, -1.9456e-03,\n",
       "                      -1.2676e-02, -3.4559e-02, -1.1696e-02,  1.1331e-02, -1.3883e-02,\n",
       "                      -8.1546e-03, -1.1569e-02,  3.8104e-02, -1.9290e-02,  2.1914e-02,\n",
       "                       4.4433e-02, -1.2893e-02, -1.3130e-02,  2.0210e-02, -9.3499e-03,\n",
       "                       1.5413e-02, -1.0937e-02,  3.7572e-02, -5.5785e-03, -3.2375e-03,\n",
       "                      -9.8012e-03, -1.5746e-02, -1.1544e-02, -1.3884e-02,  7.1892e-03,\n",
       "                      -6.4922e-06, -1.7522e-02, -1.4598e-02, -4.5625e-03, -2.1767e-02,\n",
       "                      -1.2591e-02, -1.9681e-02, -9.3655e-03, -1.7118e-02, -2.1912e-02,\n",
       "                      -7.1971e-03, -1.0622e-02,  1.2098e-02, -6.1655e-03,  1.1432e-04,\n",
       "                      -4.4020e-03, -2.0536e-02, -1.7236e-02, -3.5953e-04, -1.1641e-02,\n",
       "                       2.1154e-03,  6.5618e-02, -3.0516e-02, -7.5931e-03,  1.1165e-02,\n",
       "                       5.7875e-03, -2.1117e-02, -5.6657e-04, -4.1529e-03, -1.0331e-02,\n",
       "                      -1.8615e-02,  3.5760e-02, -8.6793e-03, -1.4775e-02, -2.3903e-02,\n",
       "                       4.8491e-02, -1.3855e-02, -2.1677e-02, -2.5570e-02, -7.0697e-03,\n",
       "                      -2.7720e-02, -6.6608e-03,  1.2856e-04, -2.9805e-02,  3.7962e-02,\n",
       "                       2.6437e-02, -8.0894e-03, -1.6169e-02, -2.5708e-02, -1.1813e-02,\n",
       "                      -1.7902e-02, -1.2951e-02, -1.4123e-02,  1.4569e-03, -2.0489e-02,\n",
       "                      -2.7778e-02, -1.1169e-02,  3.2668e-03, -7.1326e-03, -1.6445e-02])),\n",
       "             ('BN6.running_mean',\n",
       "              tensor([-2.7635e-01, -3.1889e-01, -4.0311e-01, -4.6745e-01, -5.7581e-01,\n",
       "                      -6.7561e-01,  5.8119e-02, -2.7433e-01, -4.8934e-01, -1.5701e-01,\n",
       "                      -5.0722e-01, -2.8619e-01, -5.0027e-01, -4.9515e-01, -2.2204e-01,\n",
       "                      -5.4865e-01,  3.0030e-01, -1.3225e-01, -4.2929e-01, -2.6959e-01,\n",
       "                      -4.1986e-01, -6.2866e-02, -2.9974e-01, -8.8336e-01, -2.3041e-01,\n",
       "                      -9.3747e-02, -5.2972e-01, -2.0360e-01, -4.5197e-01, -4.7395e-01,\n",
       "                      -6.9828e-01, -3.0005e-01, -7.8533e-02, -2.1934e-01, -5.6846e-01,\n",
       "                       2.6667e-02,  2.2499e-01, -4.5711e-01, -4.1566e-01, -4.3139e-01,\n",
       "                      -4.6173e-01, -4.3498e-01, -5.5118e-01, -3.5998e-02, -2.1694e-01,\n",
       "                      -2.6993e-01, -2.2660e-01, -5.2401e-01, -1.8907e-01, -3.4966e-01,\n",
       "                      -2.3983e-01, -3.8672e-01,  1.9587e-02,  1.6517e-01, -3.3446e-01,\n",
       "                      -4.4393e-01, -6.9245e-01, -9.9377e-03,  3.3316e-01, -2.7327e-01,\n",
       "                      -3.8632e-01, -2.6506e-01, -2.9738e-01, -9.0281e-03, -6.7791e-01,\n",
       "                      -4.1135e-01, -5.4882e-02, -3.0652e-01,  1.8074e-01,  1.3404e-01,\n",
       "                      -1.9224e-01, -2.2252e-01, -4.3287e-01, -1.1152e-01, -3.5236e-01,\n",
       "                      -3.8520e-01, -2.7084e-01, -5.2871e-01, -1.8787e-01, -3.8840e-01,\n",
       "                      -1.7426e-01, -6.8886e-02, -9.0822e-02, -4.0468e-02, -5.2613e-01,\n",
       "                      -4.5076e-01,  1.2208e-01, -6.7411e-01, -2.8203e-01, -4.7519e-01,\n",
       "                      -1.1466e-01, -3.7546e-01, -5.6576e-01, -1.2832e-01, -2.8388e-01,\n",
       "                       3.5823e-02, -4.2275e-01, -1.5728e+00, -4.7599e-01, -4.8869e-01,\n",
       "                      -1.9725e-01, -1.9504e-01, -2.2674e-01, -1.6004e-01, -5.1354e-02,\n",
       "                       1.8015e-01, -3.6686e-01, -5.4838e-02, -3.2217e-01, -2.8467e-01,\n",
       "                      -1.2683e-01, -4.1161e-01, -9.4895e-01, -3.1895e-01, -2.4953e-01,\n",
       "                       5.2751e-01, -1.1526e-01, -4.6060e-01, -4.0724e-01, -6.9438e-01,\n",
       "                      -1.8763e-01,  5.6927e-02, -4.8310e-01, -5.2537e-01, -2.1553e-01,\n",
       "                      -1.8443e+00, -4.0966e-01, -1.4637e-01, -5.3660e-01, -3.1618e-01,\n",
       "                      -4.5681e-01, -3.7684e-01, -4.9004e-02, -1.5075e+00, -4.7198e-02,\n",
       "                      -3.6494e-01, -3.8171e-01, -2.5739e-01, -1.5021e-01, -3.3631e-01,\n",
       "                      -2.8801e-01, -3.1120e-01, -6.4839e-02, -3.3519e-01, -3.3858e-01,\n",
       "                      -4.7894e-01, -4.7945e-01, -1.9091e-01, -4.0471e-01, -3.0772e-01,\n",
       "                      -5.7588e-01, -2.8869e-01, -4.8606e-01,  1.4359e-01, -6.0489e-01,\n",
       "                      -4.8637e-01, -3.6967e-01,  1.3900e-01, -4.1587e-01, -3.9403e-01,\n",
       "                      -4.6872e-01, -4.1280e-01,  2.5218e-02, -3.0040e-01, -4.1235e-01,\n",
       "                      -3.8639e-01, -2.4805e-01, -2.3978e-01, -1.5043e-01,  2.1953e-02,\n",
       "                      -4.9294e-01, -3.3423e-01, -1.3522e-01, -5.6921e-01, -3.6343e-01,\n",
       "                      -1.8407e-01, -8.8774e-01, -1.7686e-03, -5.1384e-01, -4.1999e-01,\n",
       "                      -1.4279e-01, -7.4712e-01, -6.5382e-01,  1.8414e-01, -8.7841e-02,\n",
       "                      -4.5771e-01, -2.7027e-01, -3.3355e-01, -4.3006e-01, -3.7919e-01,\n",
       "                      -3.9420e-01,  7.2651e-02, -2.6807e-01, -2.2732e-01, -5.9135e-01,\n",
       "                      -7.5057e-01, -3.7791e-01, -6.2334e-01, -2.1265e-01, -1.3488e-01,\n",
       "                       2.1956e-01, -4.4807e-01, -5.3102e-01, -2.5320e-01, -3.7757e-01,\n",
       "                      -1.3448e-01, -4.5420e-01, -1.0202e-01, -4.4521e-01, -2.8453e-01,\n",
       "                      -5.4072e-01, -5.0888e-01, -4.1168e-01, -2.4562e-01, -3.6529e-01,\n",
       "                      -1.8597e-01, -6.6818e-01, -4.7024e-01, -2.4950e-01, -1.8446e-01,\n",
       "                       7.5858e-02, -4.6320e-01, -1.8613e-01, -3.8512e-01, -2.5164e-01,\n",
       "                      -2.5426e-01,  5.7465e-02, -2.5541e-01,  3.1687e-02, -5.0370e-01,\n",
       "                      -6.8673e-01, -7.0737e-01, -5.3377e-01, -1.0096e-01, -6.0061e-01,\n",
       "                      -1.8317e-01, -2.2910e-01, -3.7161e-01, -4.9763e-01,  7.0602e-02,\n",
       "                      -6.5702e-01, -2.1512e-01, -4.2034e-01, -5.1794e-01, -4.3495e-01,\n",
       "                      -5.6469e-01, -2.5853e-01, -3.7278e-01, -1.0727e-01, -7.7313e-01,\n",
       "                      -4.2819e-01, -8.7166e-02,  3.9634e-02, -6.2298e-01,  1.5788e-01,\n",
       "                      -2.6482e-01, -1.1221e-01,  3.5756e-02, -4.9690e-01, -1.0100e-01,\n",
       "                      -3.5032e-01, -3.2829e-01, -5.7648e-01, -6.0318e-01, -5.6687e-01,\n",
       "                      -3.3260e-01, -5.5825e-01, -3.3992e-01, -2.0432e-01, -7.5112e-01,\n",
       "                      -6.8651e-01, -1.2014e-01, -3.9441e-01, -5.4126e-01, -5.0702e-01,\n",
       "                      -2.6809e-01, -4.9482e-01, -1.9948e-01, -2.1027e-01, -6.3561e-01,\n",
       "                      -1.2831e-01, -2.4144e-01,  2.8736e-03, -7.9666e-01, -4.4557e-01,\n",
       "                      -3.7464e-01, -3.3995e-01, -3.4413e-01, -4.5131e-01, -8.8016e-02,\n",
       "                      -5.1987e-01, -1.8080e-01,  6.9273e-02, -1.0733e-01, -3.0858e-01,\n",
       "                      -5.8724e-01, -3.2162e-01, -4.9902e-01, -1.1270e-01, -5.6474e-01,\n",
       "                      -3.1848e-01, -2.1344e-01, -3.9621e-01, -5.6457e-02, -1.1624e-01,\n",
       "                      -8.8801e-01, -5.9246e-01, -2.3788e-01, -4.1240e-01, -5.1953e-01,\n",
       "                      -2.0402e-01, -4.2083e-01, -2.7875e-01, -3.8843e-01, -4.2339e-01,\n",
       "                      -6.9248e-01,  7.5884e-03, -2.7399e-01, -6.1692e-01, -3.2060e-01,\n",
       "                      -4.3177e-01,  2.2425e-02, -2.4996e-01, -2.4308e-01, -5.2382e-01,\n",
       "                       4.1033e-01, -4.9918e-01, -1.4430e-01, -3.1986e-01, -6.5110e-02,\n",
       "                      -6.9593e-01, -1.0927e-01,  2.0166e-03, -5.6467e-01, -3.6583e-01,\n",
       "                      -3.1995e-01, -3.4066e-01, -1.3039e-01, -2.6252e-01, -2.2193e-01,\n",
       "                       4.3530e-02, -2.6963e-01, -3.7361e-01, -4.0028e-01, -5.8074e-01,\n",
       "                      -9.4058e-02, -6.0194e-01, -3.9015e-01,  2.9074e-01, -3.1177e-01,\n",
       "                      -4.6331e-01,  1.4700e-01, -2.6023e-01, -4.6137e-01, -1.4429e+00,\n",
       "                      -4.3992e-01,  9.7384e-02, -3.5252e-01, -3.9822e-01, -8.3311e-01,\n",
       "                      -2.9477e-01, -7.0892e-01, -6.2780e-01, -7.2599e-01, -5.0068e-01,\n",
       "                      -3.1945e-01, -3.9533e-01, -1.0391e-01, -1.6074e-01, -2.5548e-01,\n",
       "                      -7.0407e-02, -3.4699e-02, -1.0230e+00, -2.8047e-01, -2.8279e-01,\n",
       "                      -1.9612e-02, -5.4533e-01, -3.8021e-01, -4.1186e-01, -5.1971e-02,\n",
       "                      -3.4531e-01, -6.1876e-01, -5.7009e-01, -2.6232e-01, -1.6619e-01,\n",
       "                      -4.3047e-01, -3.5545e-01, -3.9859e-01, -1.8462e-01,  1.0901e-01,\n",
       "                      -3.0156e-01, -3.0267e-01,  1.2911e-01, -3.5848e-01, -2.3401e-01,\n",
       "                      -3.1418e-01, -5.8962e-01, -5.7967e-01, -4.8068e-01, -7.3996e-02,\n",
       "                      -5.5553e-01, -1.2644e+00, -7.5626e-01, -4.3486e-01, -3.4036e-02,\n",
       "                      -2.1217e-01, -2.3507e-01, -5.1944e-01, -3.8226e-01, -4.0744e-01,\n",
       "                       4.4390e-02, -3.1019e-01, -3.1028e-01, -6.9295e-01, -4.5234e-01,\n",
       "                      -3.8008e-01, -1.1272e-01, -3.8874e-01, -6.8353e-01, -8.8247e-02,\n",
       "                      -6.7922e-02, -2.4584e-01,  1.4334e-01, -7.7198e-01, -6.5740e-01,\n",
       "                       3.9746e-01, -4.1678e-02, -4.9191e-01, -2.0985e-01, -3.2914e-01,\n",
       "                      -1.0092e-01, -3.6292e-01, -1.3594e+00, -3.7015e-01, -1.2428e-01,\n",
       "                      -4.5848e-01, -2.7650e-01, -2.9455e-01, -2.0806e-01, -2.4907e-01,\n",
       "                       1.5033e-01,  1.5674e-02, -4.1919e-01, -3.3385e-01, -3.7559e-01,\n",
       "                      -4.5939e-01, -2.7686e-01,  1.2589e-02, -1.0775e-01, -3.6565e-01,\n",
       "                      -1.3723e-01, -5.7134e-01, -5.0692e-01, -1.2144e-01, -1.6164e-01,\n",
       "                      -2.7364e-01, -4.5692e-01, -3.4392e-01, -1.0655e-01, -2.9713e-01,\n",
       "                      -5.1996e-01, -9.7920e-01, -1.0729e-01, -8.5503e-01, -1.9530e-01,\n",
       "                       1.0648e-01, -1.1559e-01, -2.7578e-01, -2.2105e-01, -5.7023e-02,\n",
       "                      -2.5430e-02, -1.3633e+00, -4.1266e-01, -3.6922e-01, -5.7976e-01,\n",
       "                      -9.3286e-01, -9.8328e-01, -1.7961e-01, -3.3570e-01, -5.5596e-01,\n",
       "                      -4.1226e-01, -4.2147e-01, -2.9119e-01, -4.4590e-01, -8.5701e-01,\n",
       "                       4.3478e-01, -3.8676e-01, -1.4091e-01, -1.2087e-01, -4.9199e-01,\n",
       "                      -4.6370e-01, -1.8912e-01, -5.6528e-01, -5.4979e-01, -4.8264e-01,\n",
       "                      -2.8416e-01, -3.4102e-01, -7.6417e-02, -7.0008e-01, -3.4031e-01])),\n",
       "             ('BN6.running_var',\n",
       "              tensor([0.4595, 0.2679, 2.6936, 0.5993, 1.1277, 0.6628, 0.6340, 0.5922, 0.7313,\n",
       "                      1.4154, 0.2503, 0.4524, 1.2060, 0.5190, 0.7840, 0.5005, 1.0063, 0.2867,\n",
       "                      0.3854, 0.7009, 0.5581, 0.4517, 1.2851, 0.8806, 0.5250, 0.5220, 1.0527,\n",
       "                      0.3982, 0.5395, 0.5559, 0.8530, 0.4603, 0.4609, 0.7100, 0.7634, 0.5881,\n",
       "                      0.6802, 0.4217, 0.2373, 0.3886, 0.3236, 0.9024, 0.5917, 0.4431, 0.6168,\n",
       "                      3.5936, 0.5252, 0.5199, 0.5056, 0.3487, 0.5477, 0.4024, 0.5967, 1.4865,\n",
       "                      0.6738, 0.4178, 0.3652, 0.5418, 0.6797, 0.6937, 0.5705, 0.4170, 1.1032,\n",
       "                      0.5590, 0.7146, 0.4259, 0.4033, 1.2470, 0.6369, 0.5928, 0.3878, 0.9459,\n",
       "                      1.4303, 0.4198, 0.5558, 1.2076, 0.3860, 0.7265, 0.6075, 0.4946, 1.5362,\n",
       "                      0.7478, 0.4935, 0.7921, 1.9738, 0.9445, 1.2855, 0.9901, 0.7135, 0.5079,\n",
       "                      0.7424, 0.9496, 0.6702, 0.5084, 0.8427, 0.4711, 0.9370, 0.7402, 0.3896,\n",
       "                      1.0302, 0.4302, 0.3857, 0.4844, 0.6456, 1.4821, 0.4062, 1.4824, 0.9694,\n",
       "                      1.1118, 0.5865, 0.5923, 0.3478, 0.6072, 0.4767, 0.6868, 0.4896, 2.6206,\n",
       "                      0.5684, 0.2804, 1.2327, 0.6416, 0.3310, 0.4837, 0.4149, 0.3603, 1.2321,\n",
       "                      0.3784, 0.5996, 0.5416, 0.8974, 1.1152, 1.1101, 1.6233, 0.8567, 0.6453,\n",
       "                      0.2912, 1.0572, 0.9210, 0.6030, 0.4676, 0.9093, 1.0757, 0.8190, 0.5706,\n",
       "                      0.4881, 0.3973, 1.1287, 0.2806, 0.7325, 0.4207, 0.5888, 0.6345, 0.5447,\n",
       "                      0.4801, 0.6438, 0.9104, 0.5339, 0.2647, 0.5503, 0.2989, 0.4825, 0.9532,\n",
       "                      0.4189, 0.8055, 0.6223, 0.3561, 1.0958, 0.5513, 0.3802, 0.3852, 0.5924,\n",
       "                      0.5691, 0.6204, 0.3190, 0.5438, 0.5722, 0.5084, 0.3278, 0.4442, 0.4310,\n",
       "                      0.5173, 0.8824, 0.7239, 0.4027, 0.5089, 0.8529, 0.3142, 0.3428, 0.7131,\n",
       "                      0.5351, 0.4976, 0.4208, 1.4739, 0.3774, 0.7289, 0.4575, 0.4155, 1.3846,\n",
       "                      0.7534, 1.4219, 0.5196, 1.0081, 0.4847, 2.0832, 0.8849, 0.5421, 0.5842,\n",
       "                      0.7040, 1.2628, 0.4091, 0.8070, 0.3866, 0.4712, 0.3459, 0.4522, 0.4277,\n",
       "                      0.7225, 0.6714, 1.0414, 0.5755, 0.6441, 0.4737, 0.2876, 0.8782, 0.5456,\n",
       "                      1.2379, 0.4424, 0.4039, 0.8024, 0.5967, 0.6105, 0.4472, 0.5392, 0.4158,\n",
       "                      0.3450, 0.5317, 0.4829, 0.3368, 1.8525, 0.5723, 0.9525, 0.4049, 1.2696,\n",
       "                      3.4833, 2.6658, 0.3882, 0.7187, 0.5902, 1.0764, 0.3415, 0.4667, 1.3101,\n",
       "                      0.4684, 0.2899, 0.4041, 0.7566, 0.5944, 0.3900, 0.9005, 0.4732, 0.4740,\n",
       "                      1.8618, 0.4217, 1.1622, 0.4023, 0.4680, 0.6476, 0.5781, 0.6377, 0.8069,\n",
       "                      1.4469, 0.5652, 0.8203, 0.3983, 1.2001, 1.2620, 0.3251, 1.3012, 0.5170,\n",
       "                      0.5903, 0.3854, 0.4843, 0.7145, 0.6891, 0.6173, 0.3103, 0.6783, 0.3592,\n",
       "                      0.3577, 0.4924, 0.4874, 0.6060, 0.4047, 0.4629, 0.3640, 0.8101, 0.8219,\n",
       "                      1.6688, 0.4181, 0.3878, 0.3368, 0.9863, 0.3061, 0.6700, 0.5972, 1.7685,\n",
       "                      0.4734, 0.4217, 0.3887, 0.7305, 0.6649, 2.1604, 0.5745, 0.5151, 0.8067,\n",
       "                      0.4224, 0.5680, 0.7448, 0.7428, 0.8981, 0.3385, 0.4469, 0.7507, 0.4441,\n",
       "                      0.7592, 0.3677, 0.5879, 0.3125, 1.2397, 1.5107, 0.5223, 1.5490, 0.5596,\n",
       "                      0.7084, 1.0821, 0.6430, 0.5650, 0.4941, 0.4681, 0.4833, 0.5809, 1.0164,\n",
       "                      0.2506, 0.5039, 1.6238, 0.4912, 0.5270, 0.7755, 0.6962, 0.3486, 0.3656,\n",
       "                      0.7651, 0.4905, 0.4180, 1.3699, 0.5493, 0.9639, 1.3678, 1.2038, 0.5338,\n",
       "                      0.9205, 0.8208, 1.8168, 0.4775, 0.4131, 0.4049, 0.3359, 0.5583, 0.7801,\n",
       "                      0.5050, 0.5098, 0.7247, 0.4388, 1.3515, 1.0421, 1.4581, 0.2680, 0.4327,\n",
       "                      0.5572, 0.6119, 0.4157, 0.4514, 0.7837, 0.4154, 0.4047, 1.7079, 1.0063,\n",
       "                      0.6442, 0.5923, 0.5086, 1.3336, 0.5058, 0.3765, 1.0385, 0.9735, 0.4732,\n",
       "                      1.3943, 0.6309, 0.4651, 0.6405, 0.4293, 0.6245, 0.7387, 0.5272, 0.6122,\n",
       "                      0.5669, 0.7248, 0.6853, 0.7450, 0.4679, 0.8100, 0.6991, 0.7237, 0.5615,\n",
       "                      0.8545, 1.1511, 0.5262, 0.3232, 1.0453, 0.3213, 0.3924, 0.4416, 0.4425,\n",
       "                      1.6142, 0.7883, 0.3791, 0.5500, 0.6590, 0.3501, 1.5979, 0.6437, 0.5215,\n",
       "                      1.0822, 0.5779, 0.5525, 0.7277, 1.6126, 1.3437, 0.5721, 0.5749, 0.5509,\n",
       "                      0.6285, 3.3006, 0.7829, 1.0542, 1.5808, 0.5998, 0.4834, 0.2794, 0.5580,\n",
       "                      0.3870, 1.1955, 0.4549, 1.6457, 0.4756, 0.8619, 0.9027, 1.0186, 0.7537,\n",
       "                      0.4039, 0.6069, 0.6533, 0.8230, 0.5828, 0.7756, 0.9280, 1.2466, 0.8635,\n",
       "                      0.3245, 0.6340, 0.3570, 0.8152, 1.3500, 0.3928, 0.5208, 0.8544, 0.3545,\n",
       "                      0.7978, 1.3939, 0.7241, 0.6528, 0.4774, 0.5470, 0.6501, 0.8171, 0.5416,\n",
       "                      0.7970, 0.4969, 0.6039, 1.8139, 1.0935, 0.8125, 0.9103, 0.9712, 1.0567,\n",
       "                      0.5532, 1.6847, 0.7004, 0.6184, 0.6296])),\n",
       "             ('BN6.num_batches_tracked', tensor(1200)),\n",
       "             ('x_bar_layer.weight',\n",
       "              tensor([[-0.0024,  0.0626,  0.0123,  ...,  0.0119,  0.0222, -0.0295],\n",
       "                      [ 0.0277,  0.0347, -0.0150,  ...,  0.0318,  0.0280, -0.0388],\n",
       "                      [ 0.0294, -0.0028, -0.0277,  ...,  0.0215,  0.0326,  0.0004],\n",
       "                      ...,\n",
       "                      [-0.0313, -0.0229,  0.0194,  ...,  0.0161,  0.0213,  0.0121],\n",
       "                      [ 0.0180,  0.0033,  0.0211,  ...,  0.0256,  0.0185,  0.0112],\n",
       "                      [-0.0104, -0.0271, -0.0141,  ...,  0.0370, -0.0045,  0.0090]])),\n",
       "             ('x_bar_layer.bias',\n",
       "              tensor([ 0.0103,  0.0049, -0.0211,  ...,  0.0244, -0.0099,  0.0079]))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('../02-Data/Cases/cases_pre_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6596e711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE(\n",
      "  (enc_1): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (BN1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (enc_2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (BN2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (enc_3): Linear(in_features=500, out_features=2000, bias=True)\n",
      "  (BN3): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (z_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  (dec_1): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (BN4): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dec_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (BN5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dec_3): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (BN6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (x_bar_layer): Linear(in_features=500, out_features=2000, bias=True)\n",
      ")\n",
      "0 loss: 0.9853940010070801\n",
      "0 :acc 0.4083 , nmi 0.4075 , ari 0.2447 , f1 0.1884\n",
      "1 loss: 0.9217234253883362\n",
      "1 :acc 0.4735 , nmi 0.5266 , ari 0.3108 , f1 0.2447\n",
      "2 loss: 0.8778206706047058\n",
      "2 :acc 0.5065 , nmi 0.6177 , ari 0.3947 , f1 0.2577\n",
      "3 loss: 0.84407639503479\n",
      "3 :acc 0.5149 , nmi 0.6403 , ari 0.4152 , f1 0.2599\n",
      "4 loss: 0.8232987523078918\n",
      "4 :acc 0.4742 , nmi 0.5941 , ari 0.3571 , f1 0.2230\n",
      "5 loss: 0.8100120425224304\n",
      "5 :acc 0.4748 , nmi 0.5937 , ari 0.3531 , f1 0.2244\n",
      "6 loss: 0.802544891834259\n",
      "6 :acc 0.4664 , nmi 0.5491 , ari 0.2987 , f1 0.2310\n",
      "7 loss: 0.7969290018081665\n",
      "7 :acc 0.4612 , nmi 0.5450 , ari 0.2884 , f1 0.2288\n",
      "8 loss: 0.7922312617301941\n",
      "8 :acc 0.4658 , nmi 0.5478 , ari 0.2920 , f1 0.2308\n",
      "9 loss: 0.7877040505409241\n",
      "9 :acc 0.4599 , nmi 0.5400 , ari 0.2874 , f1 0.2266\n",
      "10 loss: 0.7834130525588989\n",
      "10 :acc 0.4406 , nmi 0.5159 , ari 0.2621 , f1 0.2171\n",
      "11 loss: 0.7793802618980408\n",
      "11 :acc 0.4509 , nmi 0.5216 , ari 0.2663 , f1 0.2232\n",
      "12 loss: 0.7758961319923401\n",
      "12 :acc 0.4477 , nmi 0.5183 , ari 0.2614 , f1 0.2215\n",
      "13 loss: 0.7726424336433411\n",
      "13 :acc 0.4516 , nmi 0.5230 , ari 0.2646 , f1 0.2238\n",
      "14 loss: 0.7689903974533081\n",
      "14 :acc 0.4516 , nmi 0.5261 , ari 0.2653 , f1 0.2238\n",
      "15 loss: 0.7655153274536133\n",
      "15 :acc 0.4535 , nmi 0.5273 , ari 0.2678 , f1 0.2248\n",
      "16 loss: 0.7618509531021118\n",
      "16 :acc 0.4606 , nmi 0.5289 , ari 0.2722 , f1 0.2288\n",
      "17 loss: 0.7584353089332581\n",
      "17 :acc 0.4677 , nmi 0.5288 , ari 0.2754 , f1 0.2332\n",
      "18 loss: 0.7548509240150452\n",
      "18 :acc 0.4703 , nmi 0.5311 , ari 0.2767 , f1 0.2346\n",
      "19 loss: 0.7515555024147034\n",
      "19 :acc 0.4722 , nmi 0.5292 , ari 0.2799 , f1 0.2357\n",
      "20 loss: 0.7486299276351929\n",
      "20 :acc 0.4599 , nmi 0.5147 , ari 0.2677 , f1 0.2294\n",
      "21 loss: 0.7456863522529602\n",
      "21 :acc 0.4276 , nmi 0.5016 , ari 0.2503 , f1 0.2107\n",
      "22 loss: 0.7431842684745789\n",
      "22 :acc 0.4296 , nmi 0.5005 , ari 0.2554 , f1 0.2114\n",
      "23 loss: 0.7405083775520325\n",
      "23 :acc 0.4231 , nmi 0.4917 , ari 0.2488 , f1 0.2080\n",
      "24 loss: 0.7378609776496887\n",
      "24 :acc 0.4283 , nmi 0.4999 , ari 0.2565 , f1 0.2106\n",
      "25 loss: 0.7354501485824585\n",
      "25 :acc 0.4871 , nmi 0.5715 , ari 0.3274 , f1 0.2588\n",
      "26 loss: 0.7327429056167603\n",
      "26 :acc 0.4335 , nmi 0.5096 , ari 0.2606 , f1 0.2128\n",
      "27 loss: 0.7300696969032288\n",
      "27 :acc 0.4309 , nmi 0.5019 , ari 0.2546 , f1 0.2115\n",
      "28 loss: 0.7272956967353821\n",
      "28 :acc 0.4328 , nmi 0.5073 , ari 0.2596 , f1 0.2125\n",
      "29 loss: 0.7246724963188171\n",
      "29 :acc 0.4832 , nmi 0.5621 , ari 0.3231 , f1 0.2606\n",
      "30 loss: 0.7215072512626648\n",
      "30 :acc 0.4858 , nmi 0.5688 , ari 0.3302 , f1 0.2554\n",
      "31 loss: 0.718638002872467\n",
      "31 :acc 0.4373 , nmi 0.5082 , ari 0.2594 , f1 0.2152\n",
      "32 loss: 0.7157207727432251\n",
      "32 :acc 0.4858 , nmi 0.5658 , ari 0.3287 , f1 0.2554\n",
      "33 loss: 0.7128311395645142\n",
      "33 :acc 0.4877 , nmi 0.5712 , ari 0.3313 , f1 0.2572\n",
      "34 loss: 0.7096325755119324\n",
      "34 :acc 0.4890 , nmi 0.5731 , ari 0.3340 , f1 0.2576\n",
      "35 loss: 0.706487238407135\n",
      "35 :acc 0.4871 , nmi 0.5701 , ari 0.3315 , f1 0.2567\n",
      "36 loss: 0.7042642831802368\n",
      "36 :acc 0.4910 , nmi 0.5679 , ari 0.3295 , f1 0.2600\n",
      "37 loss: 0.701854407787323\n",
      "37 :acc 0.4935 , nmi 0.5778 , ari 0.3382 , f1 0.2607\n",
      "38 loss: 0.6985369920730591\n",
      "38 :acc 0.4948 , nmi 0.5976 , ari 0.3738 , f1 0.2521\n",
      "39 loss: 0.6959552764892578\n",
      "39 :acc 0.4864 , nmi 0.5641 , ari 0.3260 , f1 0.2578\n",
      "40 loss: 0.6925364136695862\n",
      "40 :acc 0.4890 , nmi 0.5672 , ari 0.3300 , f1 0.2586\n",
      "41 loss: 0.6902663111686707\n",
      "41 :acc 0.4922 , nmi 0.5749 , ari 0.3369 , f1 0.2599\n",
      "42 loss: 0.6872743964195251\n",
      "42 :acc 0.4890 , nmi 0.5689 , ari 0.3311 , f1 0.2586\n",
      "43 loss: 0.6838092803955078\n",
      "43 :acc 0.4877 , nmi 0.5662 , ari 0.3286 , f1 0.2580\n",
      "44 loss: 0.6813609600067139\n",
      "44 :acc 0.4916 , nmi 0.5754 , ari 0.3385 , f1 0.2591\n",
      "45 loss: 0.6785532236099243\n",
      "45 :acc 0.4903 , nmi 0.5734 , ari 0.3349 , f1 0.2587\n",
      "46 loss: 0.6754599213600159\n",
      "46 :acc 0.4884 , nmi 0.5680 , ari 0.3297 , f1 0.2584\n",
      "47 loss: 0.6725279688835144\n",
      "47 :acc 0.4910 , nmi 0.6018 , ari 0.3742 , f1 0.2520\n",
      "48 loss: 0.6700137257575989\n",
      "48 :acc 0.4877 , nmi 0.6000 , ari 0.3701 , f1 0.2591\n",
      "49 loss: 0.6673213243484497\n",
      "49 :acc 0.4903 , nmi 0.5995 , ari 0.3738 , f1 0.2517\n",
      "50 loss: 0.6652575135231018\n",
      "50 :acc 0.4897 , nmi 0.6090 , ari 0.3791 , f1 0.2510\n",
      "51 loss: 0.662245512008667\n",
      "51 :acc 0.4890 , nmi 0.6067 , ari 0.3770 , f1 0.2512\n",
      "52 loss: 0.6587544679641724\n",
      "52 :acc 0.4864 , nmi 0.5764 , ari 0.3370 , f1 0.2581\n",
      "53 loss: 0.6575072407722473\n",
      "53 :acc 0.4916 , nmi 0.5753 , ari 0.3360 , f1 0.2600\n",
      "54 loss: 0.6536838412284851\n",
      "54 :acc 0.5265 , nmi 0.6301 , ari 0.3969 , f1 0.3217\n",
      "55 loss: 0.6506558060646057\n",
      "55 :acc 0.4871 , nmi 0.5976 , ari 0.3680 , f1 0.2594\n",
      "56 loss: 0.6482639908790588\n",
      "56 :acc 0.4897 , nmi 0.6046 , ari 0.3767 , f1 0.2509\n",
      "57 loss: 0.6462766528129578\n",
      "57 :acc 0.4903 , nmi 0.6083 , ari 0.3793 , f1 0.2514\n",
      "58 loss: 0.6429103016853333\n",
      "58 :acc 0.5426 , nmi 0.6337 , ari 0.4017 , f1 0.3406\n",
      "59 loss: 0.6394829750061035\n",
      "59 :acc 0.5323 , nmi 0.5707 , ari 0.3254 , f1 0.3065\n",
      "60 loss: 0.6366844177246094\n",
      "60 :acc 0.5401 , nmi 0.6341 , ari 0.3993 , f1 0.3384\n",
      "61 loss: 0.6335328817367554\n",
      "61 :acc 0.5233 , nmi 0.6283 , ari 0.3946 , f1 0.3188\n",
      "62 loss: 0.6304632425308228\n",
      "62 :acc 0.5362 , nmi 0.6285 , ari 0.3950 , f1 0.3362\n",
      "63 loss: 0.6275604367256165\n",
      "63 :acc 0.5401 , nmi 0.6304 , ari 0.3990 , f1 0.3385\n",
      "64 loss: 0.624247133731842\n",
      "64 :acc 0.5355 , nmi 0.5762 , ari 0.3334 , f1 0.3075\n",
      "65 loss: 0.6224370002746582\n",
      "65 :acc 0.5401 , nmi 0.6283 , ari 0.3964 , f1 0.3398\n",
      "66 loss: 0.6191704869270325\n",
      "66 :acc 0.5426 , nmi 0.6418 , ari 0.4112 , f1 0.3356\n",
      "67 loss: 0.6157501935958862\n",
      "67 :acc 0.5355 , nmi 0.5766 , ari 0.3362 , f1 0.3079\n",
      "68 loss: 0.612648069858551\n",
      "68 :acc 0.5401 , nmi 0.6320 , ari 0.3990 , f1 0.3383\n",
      "69 loss: 0.6098203659057617\n",
      "69 :acc 0.5433 , nmi 0.6373 , ari 0.4091 , f1 0.3371\n",
      "70 loss: 0.6064664125442505\n",
      "70 :acc 0.5381 , nmi 0.6241 , ari 0.3965 , f1 0.3373\n",
      "71 loss: 0.6031126976013184\n",
      "71 :acc 0.5426 , nmi 0.6367 , ari 0.4072 , f1 0.3374\n",
      "72 loss: 0.6006386280059814\n",
      "72 :acc 0.5413 , nmi 0.6306 , ari 0.3999 , f1 0.3395\n",
      "73 loss: 0.5981941819190979\n",
      "73 :acc 0.5413 , nmi 0.6292 , ari 0.4026 , f1 0.3379\n",
      "74 loss: 0.5942274928092957\n",
      "74 :acc 0.5413 , nmi 0.6286 , ari 0.4009 , f1 0.3388\n",
      "75 loss: 0.5906537175178528\n",
      "75 :acc 0.5401 , nmi 0.6230 , ari 0.3969 , f1 0.3387\n",
      "76 loss: 0.5883799195289612\n",
      "76 :acc 0.5401 , nmi 0.6242 , ari 0.3978 , f1 0.3382\n",
      "77 loss: 0.5858513116836548\n",
      "77 :acc 0.5401 , nmi 0.6270 , ari 0.3997 , f1 0.3375\n",
      "78 loss: 0.583070695400238\n",
      "78 :acc 0.5407 , nmi 0.6266 , ari 0.4000 , f1 0.3382\n",
      "79 loss: 0.5809736251831055\n",
      "79 :acc 0.5413 , nmi 0.6281 , ari 0.4039 , f1 0.3369\n",
      "80 loss: 0.5772019028663635\n",
      "80 :acc 0.5413 , nmi 0.6350 , ari 0.4096 , f1 0.3342\n",
      "81 loss: 0.5743106007575989\n",
      "81 :acc 0.5394 , nmi 0.6259 , ari 0.4018 , f1 0.3356\n",
      "82 loss: 0.572178065776825\n",
      "82 :acc 0.5401 , nmi 0.6243 , ari 0.3976 , f1 0.3380\n",
      "83 loss: 0.5690857768058777\n",
      "83 :acc 0.5407 , nmi 0.6255 , ari 0.4011 , f1 0.3366\n",
      "84 loss: 0.5657967329025269\n",
      "84 :acc 0.5413 , nmi 0.6364 , ari 0.4103 , f1 0.3337\n",
      "85 loss: 0.5633016228675842\n",
      "85 :acc 0.5407 , nmi 0.6320 , ari 0.4075 , f1 0.3340\n",
      "86 loss: 0.5602692365646362\n",
      "86 :acc 0.5407 , nmi 0.6310 , ari 0.4074 , f1 0.3340\n",
      "87 loss: 0.5583838224411011\n",
      "87 :acc 0.5388 , nmi 0.6209 , ari 0.3987 , f1 0.3364\n",
      "88 loss: 0.55555659532547\n",
      "88 :acc 0.5401 , nmi 0.6313 , ari 0.4079 , f1 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 loss: 0.5527870059013367\n",
      "89 :acc 0.5388 , nmi 0.6244 , ari 0.4028 , f1 0.3344\n",
      "90 loss: 0.5495026111602783\n",
      "90 :acc 0.5413 , nmi 0.6336 , ari 0.4092 , f1 0.3343\n",
      "91 loss: 0.5472448468208313\n",
      "91 :acc 0.5426 , nmi 0.6286 , ari 0.4048 , f1 0.3375\n",
      "92 loss: 0.5443143248558044\n",
      "92 :acc 0.5407 , nmi 0.6314 , ari 0.4077 , f1 0.3341\n",
      "93 loss: 0.5411364436149597\n",
      "93 :acc 0.5426 , nmi 0.6342 , ari 0.4113 , f1 0.3352\n",
      "94 loss: 0.5387020111083984\n",
      "94 :acc 0.5433 , nmi 0.6353 , ari 0.4124 , f1 0.3350\n",
      "95 loss: 0.5352043509483337\n",
      "95 :acc 0.5426 , nmi 0.6347 , ari 0.4118 , f1 0.3342\n",
      "96 loss: 0.5317175984382629\n",
      "96 :acc 0.5426 , nmi 0.6347 , ari 0.4096 , f1 0.3352\n",
      "97 loss: 0.5293543338775635\n",
      "97 :acc 0.5407 , nmi 0.6200 , ari 0.4005 , f1 0.3369\n",
      "98 loss: 0.5277333855628967\n",
      "98 :acc 0.5420 , nmi 0.6327 , ari 0.4094 , f1 0.3348\n",
      "99 loss: 0.5253450274467468\n",
      "99 :acc 0.5439 , nmi 0.6367 , ari 0.4125 , f1 0.3360\n",
      "100 loss: 0.5239942073822021\n",
      "100 :acc 0.5394 , nmi 0.6296 , ari 0.4083 , f1 0.3328\n",
      "101 loss: 0.5207442045211792\n",
      "101 :acc 0.5394 , nmi 0.6269 , ari 0.4058 , f1 0.3337\n",
      "102 loss: 0.5176340341567993\n",
      "102 :acc 0.5388 , nmi 0.6305 , ari 0.4074 , f1 0.3317\n",
      "103 loss: 0.5157721042633057\n",
      "103 :acc 0.5413 , nmi 0.6325 , ari 0.4113 , f1 0.3331\n",
      "104 loss: 0.5140942335128784\n",
      "104 :acc 0.5426 , nmi 0.6306 , ari 0.4077 , f1 0.3364\n",
      "105 loss: 0.5110822916030884\n",
      "105 :acc 0.5252 , nmi 0.5577 , ari 0.3336 , f1 0.3020\n",
      "106 loss: 0.5087746977806091\n",
      "106 :acc 0.5394 , nmi 0.6243 , ari 0.4057 , f1 0.3322\n",
      "107 loss: 0.5050163865089417\n",
      "107 :acc 0.5420 , nmi 0.6326 , ari 0.4122 , f1 0.3335\n",
      "108 loss: 0.503127932548523\n",
      "108 :acc 0.5239 , nmi 0.5494 , ari 0.3246 , f1 0.3021\n",
      "109 loss: 0.5009774565696716\n",
      "109 :acc 0.5420 , nmi 0.6322 , ari 0.4093 , f1 0.3351\n",
      "110 loss: 0.49844929575920105\n",
      "110 :acc 0.5362 , nmi 0.6230 , ari 0.4037 , f1 0.3302\n",
      "111 loss: 0.49530288577079773\n",
      "111 :acc 0.5426 , nmi 0.6323 , ari 0.4106 , f1 0.3351\n",
      "112 loss: 0.492796927690506\n",
      "112 :acc 0.5407 , nmi 0.6276 , ari 0.4088 , f1 0.3335\n",
      "113 loss: 0.4907935559749603\n",
      "113 :acc 0.5401 , nmi 0.6297 , ari 0.4102 , f1 0.3318\n",
      "114 loss: 0.4883849322795868\n",
      "114 :acc 0.5407 , nmi 0.6285 , ari 0.4085 , f1 0.3338\n",
      "115 loss: 0.48728957772254944\n",
      "115 :acc 0.5394 , nmi 0.6282 , ari 0.4081 , f1 0.3326\n",
      "116 loss: 0.4845425486564636\n",
      "116 :acc 0.5401 , nmi 0.6298 , ari 0.4089 , f1 0.3328\n",
      "117 loss: 0.48266881704330444\n",
      "117 :acc 0.5407 , nmi 0.6276 , ari 0.4070 , f1 0.3342\n",
      "118 loss: 0.47929203510284424\n",
      "118 :acc 0.5426 , nmi 0.6309 , ari 0.4132 , f1 0.3331\n",
      "119 loss: 0.47766295075416565\n",
      "119 :acc 0.5433 , nmi 0.6324 , ari 0.4102 , f1 0.3364\n",
      "120 loss: 0.47570380568504333\n",
      "120 :acc 0.5342 , nmi 0.6171 , ari 0.4001 , f1 0.3286\n",
      "121 loss: 0.47334036231040955\n",
      "121 :acc 0.5194 , nmi 0.5446 , ari 0.3249 , f1 0.2991\n",
      "122 loss: 0.47228530049324036\n",
      "122 :acc 0.5420 , nmi 0.6334 , ari 0.4099 , f1 0.3348\n",
      "123 loss: 0.46897560358047485\n",
      "123 :acc 0.5426 , nmi 0.6338 , ari 0.4115 , f1 0.3345\n",
      "124 loss: 0.4681209623813629\n",
      "124 :acc 0.5381 , nmi 0.6249 , ari 0.4046 , f1 0.3319\n",
      "125 loss: 0.4654832184314728\n",
      "125 :acc 0.5413 , nmi 0.6307 , ari 0.4100 , f1 0.3335\n",
      "126 loss: 0.4635487198829651\n",
      "126 :acc 0.5394 , nmi 0.6270 , ari 0.4073 , f1 0.3324\n",
      "127 loss: 0.46126216650009155\n",
      "127 :acc 0.5381 , nmi 0.6241 , ari 0.4066 , f1 0.3306\n",
      "128 loss: 0.4585251212120056\n",
      "128 :acc 0.5407 , nmi 0.6296 , ari 0.4099 , f1 0.3333\n",
      "129 loss: 0.45638054609298706\n",
      "129 :acc 0.5465 , nmi 0.6373 , ari 0.4167 , f1 0.3367\n",
      "130 loss: 0.45391204953193665\n",
      "130 :acc 0.5233 , nmi 0.5485 , ari 0.3255 , f1 0.3020\n",
      "131 loss: 0.45186057686805725\n",
      "131 :acc 0.5420 , nmi 0.6302 , ari 0.4103 , f1 0.3342\n",
      "132 loss: 0.45044949650764465\n",
      "132 :acc 0.5187 , nmi 0.5437 , ari 0.3227 , f1 0.2992\n",
      "133 loss: 0.44792047142982483\n",
      "133 :acc 0.5362 , nmi 0.6223 , ari 0.4028 , f1 0.3298\n",
      "134 loss: 0.44672513008117676\n",
      "134 :acc 0.5381 , nmi 0.6233 , ari 0.4033 , f1 0.3318\n",
      "135 loss: 0.4454961121082306\n",
      "135 :acc 0.5213 , nmi 0.5482 , ari 0.3257 , f1 0.3006\n",
      "136 loss: 0.4436742961406708\n",
      "136 :acc 0.5401 , nmi 0.6294 , ari 0.4075 , f1 0.3328\n",
      "137 loss: 0.44012463092803955\n",
      "137 :acc 0.5388 , nmi 0.6255 , ari 0.4049 , f1 0.3321\n",
      "138 loss: 0.4376685321331024\n",
      "138 :acc 0.5207 , nmi 0.5446 , ari 0.3247 , f1 0.3001\n",
      "139 loss: 0.4355541467666626\n",
      "139 :acc 0.5388 , nmi 0.6212 , ari 0.4061 , f1 0.3308\n",
      "140 loss: 0.43363049626350403\n",
      "140 :acc 0.5368 , nmi 0.6185 , ari 0.4040 , f1 0.3298\n",
      "141 loss: 0.4312623143196106\n",
      "141 :acc 0.5375 , nmi 0.6191 , ari 0.4045 , f1 0.3302\n",
      "142 loss: 0.42993098497390747\n",
      "142 :acc 0.5381 , nmi 0.6234 , ari 0.4069 , f1 0.3305\n",
      "143 loss: 0.42811867594718933\n",
      "143 :acc 0.5407 , nmi 0.6265 , ari 0.4088 , f1 0.3323\n",
      "144 loss: 0.4264255464076996\n",
      "144 :acc 0.5207 , nmi 0.5504 , ari 0.3280 , f1 0.3006\n",
      "145 loss: 0.4243410527706146\n",
      "145 :acc 0.5401 , nmi 0.6266 , ari 0.4073 , f1 0.3328\n",
      "146 loss: 0.42388445138931274\n",
      "146 :acc 0.5388 , nmi 0.6247 , ari 0.4060 , f1 0.3312\n",
      "147 loss: 0.4221391975879669\n",
      "147 :acc 0.5368 , nmi 0.6209 , ari 0.4037 , f1 0.3303\n",
      "148 loss: 0.42116981744766235\n",
      "148 :acc 0.5187 , nmi 0.5420 , ari 0.3197 , f1 0.3001\n",
      "149 loss: 0.4198642671108246\n",
      "149 :acc 0.5394 , nmi 0.6255 , ari 0.4062 , f1 0.3324\n",
      "150 loss: 0.41780248284339905\n",
      "150 :acc 0.5362 , nmi 0.6203 , ari 0.4041 , f1 0.3298\n",
      "151 loss: 0.4160155951976776\n",
      "151 :acc 0.5381 , nmi 0.6266 , ari 0.4055 , f1 0.3314\n",
      "152 loss: 0.414872407913208\n",
      "152 :acc 0.5220 , nmi 0.5460 , ari 0.3276 , f1 0.3004\n",
      "153 loss: 0.4126434624195099\n",
      "153 :acc 0.5226 , nmi 0.5459 , ari 0.3258 , f1 0.3013\n",
      "154 loss: 0.4110223352909088\n",
      "154 :acc 0.5388 , nmi 0.6217 , ari 0.4057 , f1 0.3315\n",
      "155 loss: 0.4092014729976654\n",
      "155 :acc 0.5187 , nmi 0.5397 , ari 0.3232 , f1 0.2994\n",
      "156 loss: 0.4074074923992157\n",
      "156 :acc 0.5168 , nmi 0.5408 , ari 0.3209 , f1 0.2986\n",
      "157 loss: 0.4051457941532135\n",
      "157 :acc 0.5426 , nmi 0.6302 , ari 0.4113 , f1 0.3338\n",
      "158 loss: 0.4032496511936188\n",
      "158 :acc 0.5284 , nmi 0.5873 , ari 0.3827 , f1 0.2939\n",
      "159 loss: 0.4024444818496704\n",
      "159 :acc 0.5368 , nmi 0.6243 , ari 0.4035 , f1 0.3301\n",
      "160 loss: 0.40071889758110046\n",
      "160 :acc 0.5407 , nmi 0.6262 , ari 0.4060 , f1 0.3337\n",
      "161 loss: 0.39880263805389404\n",
      "161 :acc 0.5226 , nmi 0.5481 , ari 0.3271 , f1 0.3013\n",
      "162 loss: 0.3973960280418396\n",
      "162 :acc 0.5401 , nmi 0.6214 , ari 0.4057 , f1 0.3324\n",
      "163 loss: 0.3957011103630066\n",
      "163 :acc 0.5233 , nmi 0.5505 , ari 0.3288 , f1 0.3021\n",
      "164 loss: 0.3948926031589508\n",
      "164 :acc 0.5220 , nmi 0.5433 , ari 0.3251 , f1 0.3008\n",
      "165 loss: 0.3937036097049713\n",
      "165 :acc 0.5407 , nmi 0.6265 , ari 0.4078 , f1 0.3328\n",
      "166 loss: 0.39420634508132935\n",
      "166 :acc 0.5181 , nmi 0.5446 , ari 0.3258 , f1 0.2993\n",
      "167 loss: 0.39271342754364014\n",
      "167 :acc 0.5187 , nmi 0.5462 , ari 0.3297 , f1 0.2995\n",
      "168 loss: 0.3908533453941345\n",
      "168 :acc 0.5381 , nmi 0.6175 , ari 0.4037 , f1 0.3306\n",
      "169 loss: 0.38933709263801575\n",
      "169 :acc 0.5394 , nmi 0.6217 , ari 0.4074 , f1 0.3314\n",
      "170 loss: 0.3873724043369293\n",
      "170 :acc 0.5220 , nmi 0.5449 , ari 0.3247 , f1 0.3012\n",
      "171 loss: 0.385535329580307\n",
      "171 :acc 0.5394 , nmi 0.6209 , ari 0.4052 , f1 0.3322\n",
      "172 loss: 0.3833906650543213\n",
      "172 :acc 0.5213 , nmi 0.5452 , ari 0.3273 , f1 0.3003\n",
      "173 loss: 0.3825738728046417\n",
      "173 :acc 0.5401 , nmi 0.6235 , ari 0.4074 , f1 0.3321\n",
      "174 loss: 0.3814818263053894\n",
      "174 :acc 0.5187 , nmi 0.5377 , ari 0.3213 , f1 0.2996\n",
      "175 loss: 0.3808773159980774\n",
      "175 :acc 0.5368 , nmi 0.6160 , ari 0.4028 , f1 0.3299\n",
      "176 loss: 0.380250483751297\n",
      "176 :acc 0.5368 , nmi 0.6182 , ari 0.4029 , f1 0.3302\n",
      "177 loss: 0.37799355387687683\n",
      "177 :acc 0.5213 , nmi 0.5438 , ari 0.3263 , f1 0.3003\n",
      "178 loss: 0.37712448835372925\n",
      "178 :acc 0.5381 , nmi 0.6194 , ari 0.4039 , f1 0.3311\n",
      "179 loss: 0.3758193552494049\n",
      "179 :acc 0.5407 , nmi 0.6226 , ari 0.4060 , f1 0.3326\n",
      "180 loss: 0.37430188059806824\n",
      "180 :acc 0.5375 , nmi 0.6198 , ari 0.4035 , f1 0.3306\n",
      "181 loss: 0.37378638982772827\n",
      "181 :acc 0.5168 , nmi 0.5369 , ari 0.3287 , f1 0.2972\n",
      "182 loss: 0.3716191053390503\n",
      "182 :acc 0.5168 , nmi 0.5388 , ari 0.3236 , f1 0.2975\n",
      "183 loss: 0.37004950642585754\n",
      "183 :acc 0.5174 , nmi 0.5415 , ari 0.3258 , f1 0.2976\n",
      "184 loss: 0.3689289391040802\n",
      "184 :acc 0.5278 , nmi 0.5932 , ari 0.3853 , f1 0.2935\n",
      "185 loss: 0.36736243963241577\n",
      "185 :acc 0.5213 , nmi 0.5388 , ari 0.3249 , f1 0.3001\n",
      "186 loss: 0.36722809076309204\n",
      "186 :acc 0.5181 , nmi 0.5376 , ari 0.3252 , f1 0.2979\n",
      "187 loss: 0.3671788275241852\n",
      "187 :acc 0.5336 , nmi 0.6153 , ari 0.3989 , f1 0.3268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 loss: 0.3667169213294983\n",
      "188 :acc 0.5207 , nmi 0.5398 , ari 0.3263 , f1 0.2996\n",
      "189 loss: 0.3648119270801544\n",
      "189 :acc 0.5394 , nmi 0.6210 , ari 0.4036 , f1 0.3322\n",
      "190 loss: 0.36416542530059814\n",
      "190 :acc 0.5381 , nmi 0.6152 , ari 0.4030 , f1 0.3304\n",
      "191 loss: 0.36235520243644714\n",
      "191 :acc 0.5207 , nmi 0.5406 , ari 0.3287 , f1 0.2993\n",
      "192 loss: 0.3606615364551544\n",
      "192 :acc 0.5394 , nmi 0.6191 , ari 0.4050 , f1 0.3316\n",
      "193 loss: 0.3600735366344452\n",
      "193 :acc 0.5401 , nmi 0.6061 , ari 0.3972 , f1 0.3360\n",
      "194 loss: 0.35935425758361816\n",
      "194 :acc 0.5368 , nmi 0.6187 , ari 0.4031 , f1 0.3296\n",
      "195 loss: 0.3595365285873413\n",
      "195 :acc 0.5413 , nmi 0.6098 , ari 0.3989 , f1 0.3375\n",
      "196 loss: 0.3574883043766022\n",
      "196 :acc 0.5207 , nmi 0.5441 , ari 0.3278 , f1 0.2996\n",
      "197 loss: 0.35664889216423035\n",
      "197 :acc 0.5187 , nmi 0.5419 , ari 0.3289 , f1 0.2979\n",
      "198 loss: 0.35477110743522644\n",
      "198 :acc 0.5187 , nmi 0.5376 , ari 0.3346 , f1 0.2952\n",
      "199 loss: 0.35330453515052795\n",
      "199 :acc 0.5233 , nmi 0.5407 , ari 0.3351 , f1 0.2985\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAFgCAYAAACmDI9oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAADXoElEQVR4nOyddZgk1bn/P6e9x91n3d1YYHF3iOBJ0IQYkZuEX+DGiNzc2I0RIngIIRAcAiG4LbsLu6y777hLj7Sf3x9V1dM9sjO7O7az7+d5+pnuquqqt2q6T3/rPd/zHqW1RhAEQRAEQRAEA9tIByAIgiAIgiAIowkRyIIgCIIgCIIQhwhkQRAEQRAEQYhDBLIgCIIgCIIgxCECWRAEQRAEQRDiEIEsCIIgCIIgCHGIQBaOOZRSWik1ZaTjEARBONqR9lQYq4hAFkYUpdQ+pVSnUqot7vGHkY5rMFFKTTB/RBwjHYsgCGOXY6E9tVBKpZjn9++RjkUYm8gPtjAauERr/dpIByEIgjAGOFba008CAeAcpVSB1rp6uA6slHJorcPDdTxhZJAMsjBqUUrdoJRarpT6g1KqRSm1TSl1Vtz6IqXU80qpRqXULqXU5+LW2ZVS/62U2q2U8iml1iilSuN2f7ZSaqdSqlkpdbdSSvVy/CIzG5MVt2yhUqpeKeVUSk1RSr1txlavlHr8MM7xYOewVCm1WinVqpSqUUr92lzuUUo9opRqMOP/UCmVf6jHFgTh2GEMtqfXA38GNgCf7nask5VS75vxlCmlbjCXe5VS/6eU2m8e5z1z2elKqfJu+9inlDrbfH6nUupJs91tBW4w2+cV5jGqzOvqinv/bKXUq+b1rDGvX4FSqkMplR233SKlVJ1SytnP+QrDjAhkYbRzPLAbyAF+ADwd18A+BpQDRcDlwE+VUmea674BXANcCKQBNwEdcfu9GDgOmAdcCZzX/cBa60pgBUamwuJa4EmtdQj4MfAKkAmUAHcdxvkd7Bx+B/xOa50GTAb+aS6/HkgHSoFs4AtA52EcWxCEY4sx0Z4qpcYDpwN/Nx/XdVv3b/P9ucACYJ25+lfAYmAZkAX8PyDa13G6cRnwJJBhHjMC/BfGtTwROAv4khlDKvAa8DLG9ZwCvG5mud/CuEYWnwEeM6+BMJrQWstDHiP2APYBbUBz3ONz5robgEpAxW3/AUaDUorRQKXGrftf4CHz+Xbgsj6OqYGT417/E7i9j20/C7xhPldAGXCq+fph4B6gpJ9znGAe09FteX/n8A7wQyCn2/tuAt4H5o30/08e8pDH6HkcC+2pue13gXXm82Iz9oXm6zuAZ3p5jw0jkTC/l3WnA+W9XMuzzed3Au/0E9PXreNi3Eys7WO7q4Dl5nM7UA0sHenPjjx6PiSDLIwGPqa1zoh73Bu3rkKbLYnJfow78iKgUWvt67au2HxeipEp6Yt4v1oHkNLHdk8BJyqlCoFTMbIN75rr/h9GI/+BUmqzUuqmgxyvN/o7h5uBacA200Zxsbn8b8B/gMeUUpVKqV9I95wgCCbHQnt6HUYWF611BfA2Rs/awWLNATz9nMfBKIt/oZSappT6l1Kq2rRd/NQ8xsFiAHgOmKWUmgicA7RorT84zJiEIUQEsjDaKe7mZxuHkQWpBLLMrqz4dRXm8zIMW8IRobVuwuj2uwqjO/Ax6wdGa12ttf6c1roI+DzwR3Vo5Y4Oeg5a651a62uAPODnwJNKqWStdUhr/UOt9SyMrsKLietiFARB6IOjvj1VSi0DpgJ3mOK0GsM6cq0yKgX1FWs94O9jXTuQFHcMO4Y9IyH8bq//BGwDpmrDBvffGAIfM4ZJfVwDP0aW/dMY2fu/9badMPKIQBZGO3nAV81BHFcAM4GXtNZlGDaD/zUHrc3DyLg+Yr7vPuDHSqmpymBe/MCIQ+RRDAF6ufkcAKXUFUqpEvNlE0YDejA/m9uM1aOU8mD8+PR5DkqpTyulcrXWUYyuUoCoUuoMpdRcsxFvBUL9HFcQBAHGRnt6PfAqMAvDX7wAmAN4gQswMstnK6WuVEo5lFLZSqkFZjv6APBrZQwYtCulTlRKuYEdgEcpdZHZG/ddwN3PeaRitL9tSqkZwBfj1v0LKFRKfV0p5VZKpSqljo9b/zCG5eVSRCCPWkQgC6OBF1Ri3c5n4tatwsgW1AP/A1yutW4w112D4e+tBJ4BfqC7yhv9GuMu/RWMRux+jAb0cHjejKFaa70+bvlxwCqlVJu5zde01nsOsp82DA+c9Tizn3M4H9hs7v93wNVa606gAGOwSCuwFaN7URpZQRBgDLenZmLhSuAuM+NsPfZitIHXa60PYAwm/CbQiDFAb765i28BG4EPzXU/B2xa6xaMAXb3YSQu2jEGLB6Mb2FkwX3AvUCs6oZpVTkHuATDfrITOCNu/XIM8f+R1np/P8cRRgiVaEcShNGDMkrzfFZrffJIxyIIgnA0I+3p6EIp9QbwqNb6vpGORegdmShEEARBEARhmFBKHQcswigdJ4xSxGIhCIIgCIIwDCil/opRI/nr3aqGCKMMsVgIgiAIgiAIQhySQRYEQRAEQRCEOEbEg6yUegCjdmut1npOL+sVxqj9CzGKjt+gtf7oYPvMycnREyZMGIJoBUEQBp81a9bUa62711oddJRS52O0p3bgPq31z7qtvwH4JV01b/9gDRxSSkUwRv0DHNBaX9rf8aQtFgThaKKvtnikBuk9BPwBoxZgb1yAUQZmKkYB8D+Zf/tkwoQJrF69ehBDFARBGDqUUkNe3smslX03RsmpcuBDpdTzWust3TZ9XGt9ay+76NRaLziUY0pbLAjC0URfbfGIWCy01u9g1CDsi8uAh7XBSiDDnJpSEARBGDhLgV1a6z1a6yDwGDJyXhAEoV9Gqwe5mMR5z8vpmhM+hlLqFqXUaqXU6rq6umELThAE4ShhQG0p8Eml1Aal1JNKqdK45R6zjV2plPpYXweRtlgQhLHGaBXIA0JrfY/WeonWeklu7qFb+bTWtHSGhiAyQRCEo4YXgAla63kYU/j+NW7deK31EowZw36rlJrc2w6OtC0WBEEYbYxWgVwBxGcxSugaQDJo3PqPtXz8j8sHe7eCIAijhX7bUq11g9Y6YL68D1gct67C/LsHeAtYOJTBCsLRiNaai+96l/ve3dP/xsJRw2gVyM8D1ymDE4AWrXXVYB+kKN1DRVMnUgtaEIQxyofAVKXURKWUC7gao32N0W18x6XAVnN5plLKbT7PAU4Cug/uE4QhJxod3b/RGyta2FTRyqaKlpEORRhERkQgK6X+AawApiulypVSNyulvqCU+oK5yUvAHmAXcC/wpaGIozQriUA4Sp0v0P/GgiAIRxla6zBwK/AfDOH7T631ZqXUj5RSVsm2ryqlNiul1gNfBW4wl88EVpvL3wR+1kv1C+EoIxInNls6Q/z57d0Ew1G01sOaLIqPY3ddG398axfPraugsT1IZzASW7dyTwNL/uc1XtlcfdjHGui5tXSEeOyDA70e62Ai/bUtNQA0dohlcywxImXetNbX9LNeA18e6jhKM5MAKGvqIC/NM9SHEwRBGHa01i9hJB3il30/7vkdwB29vO99YO6QBygcEW/vqOOb/1zH6988nXSv86DbPvDeXn7/xk7evu0M0r1OfvWf7fxt5X4K0z0caOjgryv289OPz2HpxCwAPE47Hqe9x36s8TtOu41kd6KMiEY1GrDbVK8xaK15ZNUB/velrXz+1Mkkuez8z0tbE7Zx2hU//fhcJuWm8Lm/rsYXCHPvu3s4d3ZBbJtQJMpvX9vBw+/v59lbT2JybgrBcJS/vr+PTywqRinFc+squP7ECfzyle28tqWGv3/2+D5/6zdXtnDtvato6QyRkeTknFn5KKXYXu3jJy9uYcXuBu69fglnTM8jEtUJ5/eKKZCb2oNEo5oHlu/lmqXjelybkeDZtRX88j/beeu203HaR6tp4NCIRjW2Pj5fg8nI//dGkNIsLwBljZ0sHj/CwQiCIAjCIbK7to36tiBbq1o53hS2xlxbhhiNRDUOu42tVa387N/bCEairNrTwKTcFB794AAAT31UweaKFpo7Q9zytzWxfXuddr5/ySzOM4VpfVuA59dV8szaCiqaO7HbFD+6bDbXLh3HxooWnv6ogn9tqCQU0Zw1M480j5PLF5cwpzidUCSK027jt6/t5Hev76Qw3cNvXtsBwAVzCvjBJbPZW9/OlqpWXtlcze1Pb0QBhRkePrm4hIfe38fOGh9T81PRWvPNf67n+fWVAGypbGVybgp3vbGTu97YRZLbTiSq+eELW5hekMrTH5VT0xrgM/d/wPcunkVdm5/mjhDXHj8OgDe31fLdZzeR7LLz8YXFPPT+PiqaOynJTOKxDw+wck8DqR4HDy7fR22rn5++tI37rl/CcROyKGvsYFu1D7tN0dQRZGNFCz95cSu5qW4uW9CzYIzWOvb/6Yv3dtYTCEc4a2b+gLY/GFurWqlo7qS6xU9pVhINbQGe+qicz548qYfILGvsYOWeBq5YUtrH3gZOS2eIJ9eUc83SUpJcRy41rc/Pit0N3PzXD3n1G6dRnOE94v0ejGNaIJdYGeTGjhGORBAEQRAOHX/YsCPsqPHx8qZqdtW28chnjXm1fvvaTp5cU84b3zqN7z67iTSvE58/xMo9jTy/vhKv0865s/J5eq0xbvMvn1lMa2eItkAYgFe31HDH0xu54+mNsePZFJw8NZcblk3gnZ11fPfZTdz7zh72NXTgsts4a2YeLoeNd3bU4fOHefqjcj6+sJi/rzrAxfMKeX59JR9fWMwvLp/HHU9vpDMU4TdXLsDlsFGQ7uHEydlcfVwpX/z7R2Qnu7jz0tmEIlH+vmo/tz+9kSXjM0lxO3h+fSU3nzyR+9/bS02rn/Vlzdz95i4AaloDRKJRAP701m5qWgN8YmExr22t4dP3r4qdy8Mr9tPYHqSlM0RRuoeHbz4enz/EQ+/vY1NFCyWZSTS1BylM9/KxhcXc9cZO1h1ootUf5qaHPuSvNy3lz2/txmW3ccaMXN7bWU9Nqx+AxvZgj//VxvIWrvjL+3zp9Cl8+Ywp2G0qJvws9tW3c8vfVlOc4eWsmfmc/9t3yU1186sr5lOQbmS/yxo7eHVLDTeeNKGHeLasJNbyZtP2UdbUQWlWEr95bQePrDzAqdNy+ffGat7dWcfTXzoJgEc/OMCf3trNJfOLYj0H/lCER1cd4JxZ+eSluXngvX3cfPJEnvqonD++tYt3bjuj1xj++5mNvLihiqb2IN86b3q/n2OLPXVtvLuznquXluJ22Clv6uDO5zfz1vY6/vvCmazY00BHMMKeujYRyEOJx2knJ8VNWZMIZEEQBOHowx8yhOC2ah9vb6/D5zcEUas/xP3v7aUtEOa3r+1kzf4mvn/xLF7bWsOrW6upbvFz/YkTuHRBEU+vraA4w8vZM/MTrAPXnziBlzZV0dBmiD2P08YZ0/NiNoXPnDieWx/9iFZ/mM+fNpkL5xYm2DzKmzq4/E8r+OuK/Swcl8Gz6yopzvDyw8tm47Tb+NUV83s9p2S3g4dvWpqw7NMnjOe5dZVsLG8hGImyeHwmd1wwg0dW7qfWF+CF9ZU47Ta8Lju1rf6Yx/ndnfUAfOu86fz0E3N5e0cdWckuWjpC/PrVHZwxPZePLyrhpMnZOOw2/KEIdptiU0Ur588ppKE9SGayi6uOK+WuN3biC4S55zOL+dG/tvDJP72P1vCdC2cSCEf4z+YaKpo7AWgyhWkoEuW+d/dy8bxCNla04A9F+fWrO3DYFZfOL+Ks/3ubOy6YwfXLJrCurJkfPL+ZjmCE+rYA/lCE7TU+ttf4uOQP7/HkF05kfHYyT39UwW9e20FBugeX3YYGzpmVD8Bdb+zita01PH/ryQCxUrblTZ3UtwV4YnU5ALWtATZWtLCxoiVmWahtNcZjNbYHKcrwUucL8Kn7VrKjpo0an5/jJ2bx85e3MbMwlQ3lLZQ1dtLqD/ew9vxrQxUvbqgiL9XNve/u4VMnjKMwfWBi9qH39/Hwiv38c3UZf//s8by4oYrXttYyOTeZX7+6g86QcUNofSaHkmNaIINhsyhv6hzpMARBEAThkAmYguG9nfUxcdYZNLJ+bYEwGUlO/vTWblwOG59YVExbIMz7rzYAcPXSUibnpnD2zHzOmpnXwzdssykunlfU57E9Tjv3XX9cn+tLMpN48osnsr+hg5Om5LBmfyPZyW7SPAf3SvfGDy6ZzQ8umU1bIMy7O+pYMiELh91GfpqH6hY/wXCU0qwk3A4btb5AwiDAKXkpFJnZxvPifMxnm6Ky+zlNzUtho1mRoqkjSG6Km+IML58+fjxel51zZxdw/MRsfvjCZgKRKDefPDFmV9lR4zPeZ/qR/9+TG3hmbQXhSBQrpMJ0D9uqfMwqbCMQjnLnC1u4f/leyho7cTtszC/NYH1ZM1UtRjb6s2bG9jP3f8ALt55MfZshZL/37CaaOoJMyUuJCeT1Zc1sqWyNWTOaOw0hWd7YwV/f30cgbNxQ1bT6qW7xE4poGjuC5KS4qWtLFMgvb65mR00bHqeN2tYA1S3G+lpfIFbcoLE9yId7G3l9Wy25KS6+fvY0nl9fSWmWl0duPp6zf/02Dy7fx39fOHNA/+fa1gBuh43Nla28trWWWl+AZJedv3xmMef99t3Y/9W6BkOJCOTMJNaWNY10GIIgCIJwyFiC50CcVbC61c8jK/ezbHI2yyZn86tXdnDBnAIyklycODkbXoXjJmQyJS8VgPuuXzJk8ZVkJsXsjIvHZx3x/lLcDi6Y21WZsCDNQ02rn/ZgmJJMLwqo9fkJRzTzS9LZWNHCadMObfKaOcXpvLmtFq01Te0hpuenAfDjj82JbZOe5OTXVy2Ivc5KdgGwvdoQyI0dQZ5bX8Ezpn2lutWPUpCZ5KQ4w0utz0+tKTKXTszCYVN85cypnD+ngOfWVbK+rJnt1a0AnDQ1h1On5XLdAx/w3q56GtoDuBw2GkwbhyWkrefhqDYHG7piFovypk42V7ayZHwmq/c3UesLUOsz3lfd4icnxU2taQ9p6jD2W+cLoBTMKEijusUfs4/UtvpjYrqhLcBvX9/Bpgoj1ksXFFPd4mdiTgrjs5OZkJ3MgYaB99LXtQWYVZTG2gPN1LT6qfMFyE11MyUvlS+fMYWaFj9Pry2PnftQMjaGNB4BpVleKpv9hCPRkQ5FEARBEA4JfyjSY9meujbKmzo5aUoOVx03jvmlGXzulEkAzC/J4MRJ2Xz5jCnDHeqQkJfmptYXoLypk5JML3mpHmpajQzn7OJ0HrvlRL565tRD2ufc4nQa2oNUt/ppbA+Sldx/xjszyRDIO2vaAGjuCLKzpg27TTE9PzVB7OWneaht7crCPnzTUh793AlcuaSUNI+T3BRjX1urDLGdm+JmdpEh0mt9furbgiwozeAfnzuBL58xGZ8/HPONV5si1sqwWhaLbdU+dtT6OHlqDqkeB5XNndSbNoXqlsT3WP7pOl+A7GQXxRleanz+mKCu9QWoM4/T0B6kpjXAxJxkAKpaOqlu9VNo2nCyU1w0tPef7Q2aN3q1Pj/jspJI8ziobTWOmZvqBuAb50zj55fPIzvZTcMwZJBFIGcmEYnqhDswQRAEQTgaiBfI+WmGkPhgXyMA47KSyE1189yXT2JOcToALoeNf9xyAqdPzxv+YIeA/DQP5U0dNHeEKMlMIj/NEE+NHUHyUt0snZhFetKhWTqmFxiZ9U0VrXSGImSa2eGDkWmKaJ8pVBvbQ9S0BshLdVOY4aGqxcgY56V6yE01RH1Nq580j6NHKb2cFOP/uLXKyMrmprrJTHLhsClqfQEa2gLkprg5cXI2U81egOoWP/5QJE7cGn8tgbylqhWtYX5pBvlpHjZVtsaOV91qJAmtrKy1j/q2ADkpbuMmpDUQE9I1cRlkK54FpRmA0ZNR3xYgP90SyO5+/cIby1uY/YOX2VvfTp3PuGb5aV03OnmpiaX5slNcMXE/lBzzAnlcltH1s6+hfYQjEQRBEIRDwx+Kkp/mxm5TXGL6hVftMQTyhOzkkQxtWMhPcxOKGL7UkkwvuWkeohq0poewGiglmYZf2fIhZyX1L5C7b9PcEaTW5yc/zUNhuichg5yX5qYtEGZfQ+9zMFgCeZtp18hKdmGzKfJS3dS0+mloD5JtZpkLTSFa1dIZE7BgiNtAOEJHMILL0SX1FpRkkJfqjolvILZPay6VprgMspXxbguE2VNv6KSdNW2xa76j2kdUw7ySdJQyPNBaG9YXMLLf/fmFN1W2EIpoVu5pwB+Kxo5Z3WrcVFgZZAtDdEsGecix7hS3mV0ZgiAIgnC0EAhHyEv18MQXTuTr50wj1eOICbtx2UkjHN3Qkx8nMEszk8iLE1NWRv1w9mlTxKaOHkgGOaObQG5sD1Ld4ic/zRB79W1Bas2MsiXcN1W09BpjjnkOBxo7yEp2xcrA5aZ5qGo2ajhnJxvbWNUhqlr8CT3h9W2BWPZ4pqlzxmcnkZnsIi/VHbM0gJF9tipYgOGftvaRm+KOxbjf9BLvjUsobjN90kUZXvJS3Xx0oNmMy8wgJ7to9YcTjtedKnNw6Ydmz4d1E3GgsQOfP9xDIOckSwZ5WMhOcVOQ5mFL3N2UIAiCIBwN+ENRPE4bi8YZ9YEL0jxEoprMJGe/M+uNBeIFckmmN+H14WaQnXYbBWkeNpQbAjl7AALZ5bCRYs6cl5vqJhCOcqCxg/w0TyybGoxY2VFD8DW2B3uNMdllx+M05FlOStex81LdMUFqZZDz0419Vbf4qWrpqsjV0BakxRygN9u011g2iPisdXGGl+pWP3VtXeK6sT2I1po6X4AcM5trYVMQP2u3lVw0MuVedtW2xV4bcRrxHcyHXNFsHHv1vibzPI1rZlk9emaQDV/zUE+NfswLZIBZRWlsqRSBLAiCIBxd+MORBA+rNZnEuGPAXgFdQszrtJNlZkct8g4zgwxQnOmNWQMGkkE2tjNuSKbnGxnbQDhKfpon5scFMzuaGi/ie8aolIpliOPFYV6qO1Zf2RLOboednBQXVS2dsQxyqseRkEFeUJKBUrB4fGbCMR02xayitIQMcnGGl8b2IL5AmEA4amaQu+KdkpcSe56R5Ix5rvNS3QkTdxSkdw3Sg8S6xeVNHfzfK9tjJdssYW9VYsntJsp7ZJBT3PhDUTqCPQeoDiYikIGZhansrmvrdTSwIAiCIIwGHvvgAGv2J5Yl9YeiuB1dAtkSFhOOAXsFdIm9kkwvSqmYf1epgWV++yJe7A3Egxy/3TRTIAMxD7KFIZDjRXzvWW7LZpGbEm8Z6do2O255QboxCLC6xU+610lJZhL1bYFYibfpBak89cVlXH3cuIRj5qW6KUo3vL5WRY1p+Sk0tYeoN1/npLoSjmsN9gSYWZDWFW+KO3aeLoeNTHNgpCXk433IT39UwV1v7GLtAeOzXNmcOBdFXlyWvfs1iD/3oZ4sRAQyMKswnXBUx7oGBEEQBGG08Yv/bOcf5oQUFoFwBLez66fcEinjs44NgZzsdpDqdlBqnq/LYSMr2UVOihuH/fAlTrE5UM+mIG2AVhXLhzy9oCvLmp/mjlkswBB/GUlOXGZsvWWQgVipt5yUxAyyRbz4L0z3mhYLP4XpHnJSXNS1BWk2M8gZSU4WjcuMDdaz9pNnZrd9fmPAYLrXSUG6h8aOYEww56Z4SHE7SHYZN2FzTYHsddpjRQ6yk124HLbYZCwFaZ7Y9NNWJjxezFq1ot/ZUYfWmsoWPw5zkhqX3Ua615lw49C9J8DKStcPoHzckSACGcNiAYgPWRAEQRi1tPnDdHbrVg6Eonh6ySCPP0YsFgDXHj+OS+d3zfiX1y1LezgUZxjiLyPJ1WOGwb6wJguZHpdZzU/zkO514jbFaW6qIR4t20BfcVrCOLcPy0h8BrnQzCBXtXSaAtlNva/LYpHhTcyAW5+R/LSurO+mihbyzHJyTe3BWBk36/jWeyyBnJvqjglVa5uiDGObgoRMt2mxiBOz283ZBt/eWU9De5BgOMq8kq79KqVix7OpLpEduza9iO4tla20mtOsDxYikDHutJNcdjabI1YFQRAEYTQRDEcJRqK0B8MJy/2hSGxAF3SVdpuan8Kxwh0XzuRjC4tjry9fXMInF5Uc0T4tsZd1CDaNogwPGUlOSjO77Bn5piAuSPfgcthI8xgD+Syx26fFwhTAiRlk08Jg79oPGBnkls4Qe+vbKUj3kmMOYmvuCKKU4UmOJy9O9FpZ4B21PnJT3WQluwhHNXvq2s3ju2LbOu2KGYWG+DcEcuI5WBnkeM91ituB22GLVZ0IhCPsrW8n2WVnQ3lzbPzXssk5xvG63ThkJbt73KB0+ZoN0a215tZ/fMQX/ram12t5uIhAxphvfn5JBmsOyJTTgiAIwuij3RwM1RFIzCAbArkrg3zSlGyev/Uk5pVkDGd4o4rPnjKJm06eeET7sGohD9R/DPCF0ybz9BeXke51ohR4nDbSvIY4LUjzkGdmR8EQztB3Brl7dha6RHV2iiu2H4CJOYbItdsUZ87Iiw1iq2juJM3jxNZNYCa7HVx9XCnnzS5g0bhMvnHONGxKMT47qWvK7BofdpuKzRA4PjuJ0qwkUtwOUtwO8lLdMZtHfmpiybl4z7XlC7c8yLtr24lENVceV4rW8PiHZQDGFOhx18Npt5GT4ur1+nRlpQ3R/eG+JvbUtfPxuJukwcDR/ybHBksnZnHXGztp9YdI84z90jiCIAjC0YM1lXBHqFsGORyNdd+DIUiOZXE8WFjZ0MwBTDNtkepxkmrqh3Sv0xTKhjj95OKSmK8XDMGZk+Im2d27DLMyuyVx2ejsZLdhOUhJFO3nzCrgqS+eyOyidDxOO0+tMawGu+vayehjFsGffXJe7PlXz5rKxxYUk+Z1sLasGYCdNT6yzQlKAG6/YAY+v/HZu37ZeGYXpccy05Zwz0lxccXiEs6ZlZ9wrOwUV8wOscO0V1yxuJRXt9Tw4sYqAGYWppGX6qY0s8s7Pz47uccAPTAqd2Qnu3htaw03nzyRf3xwgFS3g4vmFfZ6roeLCGST4ydm8TsNa/Y3ccYYmYJTEARBGBtY1or4DHI4EiUS1T2mKhaOnCSXg+IMb8yLfKhkJrkSxN2VS0oT1t965hSuPX5cn+8/Y3oeL331FCbldlll7DbDu9zdk2u3KRaPz4q9tmwKu2vbmJQ7MC+6NamMlTHfU9cem0gNDC+2NQjxtvNmALC50rClWn5hpRS/vGJ+j31nJ7tinubtNT6cdsWUvBRuO286X3tsHW6z6sWTX1hGRtwNyd3XLsJp793/feels/nqY2v52N3L2VPfzpVLSkhyDa6kFYFssnBcJg6b4oO9jSKQBUEQhFFFm5m9i/cg+83ZyeI9yMLg8dgtJ5DeRwa2P65dOu6g743PNveGzaxR3J3rTpyQkFXujTlFaWQmOWnqCB3yZDGF6R6UMo7fX0Z2cm4KF88r5NSpuQfdLjvFzcaKVt7dWceb22qZlJOCy2HjknlFPLB8H4FQBKVUj5kfC9J792cDXDK/iEA4yt9W7mdecTo3nXRklpreEIFs4nXZmVeSzgd7G0c6FEEQBEFIIGaxiKtiYdXulwzy0FB6BKXyPnfqpEGMpIsvnzGl322yU9w8dONSrrl3ZUJFiYGQl+bh3187haIMb792U4/Tzh+uXdTvPoszjElXPnP/B3iddr578UzAEOF/vfG4w57w4/LFJVy++MgGYx4MEchxnDApm3ve2UNDWyChhIogCIIwfPzhjZ0sGp8ZG9kuQLtpregIRtBao5SKCeR4D7IgAMwvzeCV/zo1Nv31oTCjoGfm+kj4/GmTWDQ+E5syeuvjYzKsG4N6uEFDvlVxfGxhMeGo5umPKkY6FEEQhGOStkCY/3t1By+srxzpUEYVVhWLSFQTjBjWikDMYiEZZKEnJZlJMd/wSJLkcnDatFxOmZp7WIJ9pBCBHMe0/FQWjcvgHx8eQGs90uEIgiAcc2wob0ZrDrvbdaxiWSyga6BeVwZZBLIgDDYikLtx9dJx7KlrZ8XuhpEORRAE4ZhjfZkxMl4EciLtcQLZGqjnD8kgPUEYKuRb1Y1L5hVRmO7hxy9uJWx2YwmCIAjDw7oyY8Km7lMqH+u0xVWvsK5NQDLIgjBkjIhAVkqdr5TarpTapZS6vZf145RSbyql1iqlNiilLhyu2LwuOz+4ZBZbq1q55909w3VYQRAEAVhnTlTQfUrlY53EDLIpkKXMmyAMGcP+rVJK2YG7gQuAWcA1SqlZ3Tb7LvBPrfVC4Grgj8MZ43mzCzh/dgG/eHk7f357t/iRBUEQhoHqFj81rcaEApJBTqQ9boKQjoBlsZAyb4IwVIzEbedSYJfWeo/WOgg8BlzWbRsNWHVG0oFhHc6slOJ31yzgonmF/Ozf2/jcw6upbvEPZwiCIAjHHFurWgFjel3xICdiTfMLXf5sf1gEsiAMFSMhkIuBsrjX5eayeO4EPq2UKgdeAr7S246UUrcopVYrpVbX1dUNapBuh527rl7I9y6exTs76zn9V2/yf69sTxhJLAiCIAwerf4QIAK5N9oDYbKSjZJd3QfpSR1kQRh8Ruu36hrgIa11CXAh8DelVI9Ytdb3aK2XaK2X5OYefKrDw8FmU9x88kRe/8ZpnDOrgLve2MXpv3yTv63cT0gG8AmCMIwopS7prR0c4Hv7G/dxg1KqTim1znx8Nm7d9Uqpnebj+iM5h/6wsqR5qR46xIOcQHswTK45gZVlPxGLhSAMHSMhkCuA0rjXJeayeG4G/gmgtV4BeIARm1KpNCuJu65ZyLNfPolJOSl879lNnPGrt3ho+V5pxAVBGC6uAnYqpX6hlJox0DcNcNwHwONa6wXm4z7zvVnAD4DjMexxP1BKZR7pifSF1UOXl+qmMxSR8R9xtAXC5KUZAlkG6QnC0DMS36oPgalKqYlKKRfGILznu21zADgLQCk1E0MgD66H4jBYUJrB458/gfuvX0JBmoc7X9jCsp+9wc/+vY3ypo6RDk8QhDGM1vrTwEJgN/CQUmqFaTNL7eetAxn30RfnAa9qrRu11k3Aq8D5h3kK/dLmD2NTkJXiQusuC4FgWCxyUw2B3H2QnpR5E4TBZ9gFstY6DNwK/AfYilGtYrNS6kdKqUvNzb4JfE4ptR74B3CDHiWpBKUUZ83M58kvLuOpL57ICROzueed3Zz6ize55eHVvL+rXrIegiAMCVrrVuBJDJFbCHwc+Egp1es4DZOBjPsA+KRZVvNJpZTVyzeg9w7WeJC2QJgUtyM2Ha300HXRHoiQ4XXhstvoCFkWiyhOu8JuUyMcnSCMPUZkUmyt9UsYg+/il30/7vkW4KThjutQWTw+i8WfyaKiuZO/r9zPYx+W8cqWGqblp3DdiRP4xKJiklxHz7zjgiCMXswEwo3AFOBhYKnWulYplQRsAe46gt2/APxDax1QSn0e+Ctw5kDfrLW+B7gHYMmSJYedIfD5w6R6nHhNT21HMEL24e5sDKG1pj0YJsVtx+uyJ2SQPZI9FoQhQYxLg0Bxhpf/d/4M3r/9TH55+TxcDhvffXYTJ/z0dX7yry0caBD7hSAIR8wngd9oredqrX+pta4F0Fp3YIzb6It+x31orRu01gHz5X3A4oG+dzBpC4RIcTtiiQWpZGHQEYygNSS7HSS77AkeZLcM0BOEIUHSm4OIx2nniiWlXL64hI8ONPHQ+/t56P193L98L6dNy+XS+UWcPSufNI9zpEMVBOHo406gynqhlPIC+VrrfVrr1w/yvti4DwxxezVwbfwGSqlCrbW170sx7G9gWOF+Gjcw71zgjiM9kb5oD0RI8ThIclkZ5KPTYrGzxkdWsotss+rEkWLNopfsduB12ROmmpYBeoIwNIhAHgKUUob9YnwWNRfN5O8r9/PkmnK+sX09LoeN06blcvG8Qs6amR/z2gmCIPTDE8CyuNcRc9lxB3uT1jqslLLGfdiBB6xxH8BqrfXzwFdNC0cYaARuMN/bqJT6MYbIBviR1rpxEM8pAV8gTIbXGRPIR9tsepGo5tevbuePb+3m4nlF3HXNwkHZr88UyCluB8luR1cd5HBEaiALwhAh6myIyU/z8I1zp/P1s6extqyZf22o5KWNVby6pQa3w8YZ0/O4aF4hZ87II1nEsiAIfeMwq1AAoLUOmpWA+mUA4z7uoI/MsNb6AeCBw4r4EGnzhyjJ9MYsFu1HmUD+89u7ufvN3WQkOVmzr+s+orK5E4CiDO9h7Tc+g5zksnfNpBeKSg1kQRgiRJENEzabYvH4TBaPz+R7F81izYEm/rW+kpc2VfPy5mo8zkSxLIP7BEHoRp1S6lIz44tS6jKgfoRjGlTaAmFSXIaNAI4ui8WmihZ+8+oOLppXyMLSDH7y4lZqW/2keZ1c/qf3iWp481un43XZ+duKfbyzs547L51NcYYXnz/E/oYO5hSn97pvawKVZLedJJeDWp8fgEA4IgJZEIYIUWEjgM2mOG5CFsdNyOL7l8xm9b5GXtxYxb83VfPvTYZYPnNGHhfNLeKMGbkilgVBAPgC8Hel1B8AhVF+7bqRDWlwafOHEzzIR5PF4icvbiEjycVPLpvDnvo2ANaVNbOzto3KFkPQPrB8L9edOJ5f/Gc7Pn+YVXsaePDGpfzi5W18sK+Rl756Cv/44AB769u5dH4R588pINXj5L1d9ThsihkFaSS57LQHIjy1ppzt1W1ML0gZydMWhDGLKK8Rxm5THD8pm+MnZfODS2bz4b5GXtxgiOWXNlbjddoNsTyvkDOm58UyK4IgHFtorXcDJyilUszXbSMc0qASiWragxGzikVXmbfRitaaR1bu56mPKrjuxPGs3NPIdy6cSWayi9mudBw2xX821/CfzdWcPTMfpeCPb+5iV20bPn+Yu65ZyK9e2c5Vf1lBOKpx2hU3P/QhlS1+spJdvLuznu89t4mffWIeL6yv5OSpOWQlu0hy2dlb3843n1jPpNxkPnPChJG+FIIwJhGBPIqw2xQnTMrmhEnZ3HnpbD7Y28iLGyt5eVM1L26sItll57zZBVy6oIiTp+TgsMvgDEE4llBKXQTMBjxKGZNDaK1/NKJBDRLWwLNUT1eZt87Q8ArkssYOQpEok3IPnpWNRDXf/Oc6nl1XicOm+MY/15PqcXD1UqMinsdpZ0ZhKk99VI7HaeM7F83EYVNc/+AHPLO2ghMnZXPJ/CLml2Rw1T0rWDQuk4XjDFvGkvGZPHbLCWyoaOEn/9rCt55YTziq+a+zpwHErs0pU3P4641LsckkIYIwJByxQFZKJQOdWuuoUmoaMAP4t9Y6dMTRHcPYbYoTJ2dz4uRsfnjpHFbtaeD59cYAv6fXVpCd7OKieYVctqCIReMysX4sBUEYmyil/gwkAWdg1Cq+HPhgRIMaRNr8XZUaXA4bDpuKDU4bLn74whZaOoM88YVlPdZtLG8hM9lJSWYSP3h+E8+uq+Qb50zjzBl5fOb+Vdx00kRS40p4LijNYFNFK9+5cCYTc5IB+NdXTubB5fs4b3Y+AOOyk3j7tjNw2hWhiCYc1Vy2oAiH3caicZncde0izv/tOwTCUc413zM+O4nsZBe/uHyeiGNBGEIGI4P8DnCKWSfzFYxyQFcBnxqEfQsYYnnZlByWTcnhh5fN5u3tdTy3vpLHPyzj4RX7Kcn0cvbMfC6eV8ji8SKWBWGMskxrPU8ptUFr/UOl1P8B/x7poAYLSwyneIyfJW9ctYbhotUforWzpyjfVdvG5X9+nwvnFnLHhTN4ZOUBPnPCeL561lQAVv332Tjtie3uDcsmMi4riU+fMD62LMnl4MtnTEnYzmWWaXM5FF84bXLCuuIML3/59GKqW/0x8X3Dsglce/w43DKDniAMKYMhkJXWukMpdTPwR631L5RS6wZhv0IvuB12zp1dwLmzC2gLhHllczX/2lDFPz44wEPv72NKXgoXzingE4tKmGBmLQRBGBP4zb8dSqkioAEoHMF4BpX4Wr8ASXETYgwXwXCUQDjxmKFIlP96fB2BcBSfPxTLdC8enxnbxtVLLeIpeSlMyTvyAXTLpuQkvFZKiTgWhGFgUASyUupEjIyxNd2pfHuHgRS3g08sKuETi0roCIb51/oqnvqonD+8uYvfv7GL4ydmcfr0PC6eV0hpVtJIhysIwpHxglIqA/gl8BGggXtHNKJBxBKeqWYGOdnloGOYPciBcBR/KJqwbGNFCxsrWgCj7rC1XsqrCcLYZjAE8tcxCsw/Y87ONAl4cxD2KxwCSS4HVx5XypXHlVLT6uexD8p4eXM1P395Gz9/eRuLx2fysQVFXDi3cNCmPxUEYXhQStmA17XWzcBTSql/AR6tdcvIRjZ4tMUyyIaVwOuy0zHMHuRAONIjg2xZP1x2G52hSGzgoEzxLAhjmyMWyFrrt4G3IdaI12utv3qk+xUOn/w0D187eypfO3sq5U0dPL++kufXVfK95zbzwxe2cMrUHD62sJhzZuVLjWVBOAowB0HfDSw0XweAwMhGNbjEBul5uiwWw+1BDoR6ZpCt1+lJTvyhCAFTIHslgywIY5rBqGLxKEYB+wjGAL00pdTvtNa/PNJ9C0dOSWYSXzp9Cl86fQrbqlt5bp0hlr/22Dq8Tjvnzs7nsgVFnDI1F6eUjROE0czrSqlPAk9rrfVIBzPYdPcge10OWjqHtxhSwPQga61jg539piDOTHJ2yyCLQBaEscxgpA9naa1blVKfwhhRfTuwBsMnJ4wiZhSkMeP8NG47dzqr9zfx3LoKXtxYxXPrKslMcnLB3EIumVfE0olZ2KV8kCCMNj4PfAMIK6X8GLPpaa112siGNThYGeRkc5KQZJed6pbOYY0hGI4Q1RCKaFyORIGckeSioqlTPMiCcIwwGALZqZRyAh8D/qC1Dimlxlx2YyxhsymWTsxi6cQsfnDJbN7ZUccLGyp5dm0Fj646QF6qm4vmFXLR3EJmF6XL7H2CMArQWqeOdAxDSXswjNdpj02A5DWnVB5OAmFD/PrDkVhlCr+5LDPJye7atlgGWSwWgjC2GQyB/BdgH7AeeEcpNR5oHYT9CsOAy2Hj7Fn5nD0rn45gmDe21fLC+kr+vuoADy7fB8DxE7O45dRJnDpNbBiCMFIopU7tbbnW+p3hjmUo8PnDMf8xGB7kmlY/y/73de65bglzitOH9Pha65hADoSi4MF8bmaQvS46Q5FYRlkG6QnC2GYwBun9Hvh93KL9SqkzjnS/wvCT5HJw8bwiLp5XRKs/xHs769lW1coTa8q5+a+rSfc6OdcU00snZJGZ7BrpkAXhWOK2uOceYCmGne3MkQlncGkLhGP+Y4CZhWmkeZ1Utfp5fWvtkAvkYKRrcJ4/rrxczGKRbAzSiwlk6VkThDHNYAzSSwd+AFjZjbeBHwFjpvzQsUiax8mFcwu5cG4ht545lbd31PHSxipe3lTNE2vKsdsUZ0zP4+rjSjl9em6sW1QQhKFBa31J/GulVCnw25GJZvDxhyIJvt5PHT+eTx0/nnN/8zbrypqOeP/VLX5uePADrl82gWuWjuuxPhjuEsiBcLxYjmJTkOp2ENXQag4c9MhkHYIwphkMi8UDwCbgSvP1Z4AHgU8Mwr6FUYDLYeOcWfmcMyufQDjChvIWXttaw1NrKnhtaw15qW6uWFLCFYtLZfY+QRg+yoGZIx3EYBEMR3udkW5BaQavba1NqCxxqLR0hLjugVXsqGnjvV31vQrkRFGcmEH2OO0x8d7cGcJuUz2mlhYEYWwxGAJ5stb6k3GvfyhTTY9d3A47x03I4rgJWXzr3Om8sa2Wxz8s409v7ebuN3ezdGIWVywu4cK5hSS7pcayIAwWSqm7MGbPA7ABCzBm1BsTBMNR3L30RM0vzeCfq8spa+xkXPbhzQj6nWc3sqeunXFZSeyta+91m0AfGeTObgK5qSOEx2E7bLEuCMLRwWAomE6l1Mla6/cAlFInAcNbm0cYEZx2G+fNLuC82QVUtXTy9EcVPLG6jNue3MCdz2/monmGRWPhuEzSvc6RDlcQjnZWxz0PA//QWi8fqWAGm2Ak2mtliAWlGQCsK28+LIH8/PpK/rWhitvOm06dL8A/V5f1mo0OxGWNAwkZ5Cgehy0WW3NHUCr7CMIxwGAI5C8AD5teZIAm4PpB2K9wFFGY7uXLZ0zhS6dPZvX+Jv75YRn/2lDFP1eX47Apzp6Zz9VLSzllaq7UWBaEw+NJwK+1jgAopexKqSStdccIxzUoBMPRXm+kp+Wn4nHaWHegmUvnFx3yfu9/dw8zClL5/KmT+PuqA3QEI9T5AuSleRKPH+nDgxzunkEO4hb/sSCMeY54ZJXWer3Wej4wD5intV5IP6OqlVLnK6W2K6V2KaVu72ObK5VSW5RSm83Z+oSjAKUUx03I4pdXzGf1d8/m0c8ez40nTeDDfY3c8OCHnPqLN/ntazuobJZOBkE4RF4HvHGvvcBrIxTLoBMMR3H1YrFw2m0sLM3k3Z11tHSGOOlnb/DC+soB7bPVH2JjRQvnzsrHYbcx0Rwjsae+p80iEOrdgxwIRXA77XhdRmxN7SEp8SYIxwCD9i3XWrdqra36x9/oazullB24G7gAmAVco5Sa1W2bqcAdwEla69nA1wcrTmH4SHI5WDYlh+9cNIsVd5zF3dcuYlJuMr99bScn//wNbnzwA/6zuZpQXOZGEIQ+8Wit26wX5vPDM+WOQoKR3gfpAVw4r5CdtW38/OVtVDR38sSa8gHtc/W+RqIaTpiUDRATyPt6E8gHqWLhcdpiVStaOkNisRCEY4ChGkV1sD70pcAurfUeAKXUY8BlwJa4bT4H3K21bgLQWtcOUZzCMOFy2IzZ+eYVUtbYweMflvHEmjI+/7c15Ka6OW92PmfNzOfESdkyhasg9E67UmqR1vojAKXUYsbQeI++qlgAXDingDuf38yjqw4AsGJ3PT5/iFTPwcc2rNzTiMtuY9H4TACKMry47Db2NvQmkHvWPraeexz2WN3jtkBYSrwJwjHAUPUTHWyq6WKgLO51ubksnmnANKXUcqXUSqXU+b3tSCl1i1JqtVJqdV1d3ZFFLAwbpVlJfOu86Sz/9pncd90SFo3L4Kk1Fdz44Ics+clr/PSlrVS3+Ec6TEEYbXwdeEIp9a5S6j3gceDWkQ1p8AgcRCBnp7g5aUoOAJctKCIU0byzo77ffa7Y3cCCcRmxm267TTEuO6n3DHIfFgvDg2xLEMWSQRaEsc9hZ5CVUj56F8KKRJ/c4eAApgKnAyUYU1jP1Vo3x2+ktb4HuAdgyZIlBxPlwijEYe+a5tofirBiTwNPrSnnvnf38ODyvZw/p5CzZ+Zx2rRcMpJk1j7h2EZr/aFSagYw3Vy0XWsdGsmYBpNgONKrB9nihmXjqW3188NLZ/POjjpe3VLNRfMK+9y+pTPE5soWbj1zasLyCdnJ7O1FIPc5SC8UNQfpdcUmg/QEYexz2AJZa516mG+tAErjXpeYy+IpB1aZjf9epdQODMH84WEeUxjleJx2zpiexxnT8yhr7OD+9/bywvpKXlhfiU0ZHsJL5xdx/pwCEcvCMYlS6svA37XWm8zXmUqpa7TWfxzh0AaFYCSKu48MMsCZM/I5c0Y+YLQH68sPPlmr5T8+0fQfW5Rkelm1p6HH9okWi8RsstdpT8gaSwZZEMY+IzEU90NgqlJqolLKBVwNPN9tm2cxsscopXIwLBd7hjFGYQQpzUrizktn88F3zuaZLy3jS6dPoarFz+1Pb2TJT17jpoc+5Jm15bQFwiMdqiAMJ5+L70Uzx2h8buTCGVwO5kHuTn6ah3pf4KDbrNjdgMthY+G4jITlaR4HbcEw0Whip2O8xaK7WHY77QkWC88A4xQE4ehl2Kc601qHlVK3Av8B7MADWuvNSqkfAau11s+b685VSm0BIsBtWuuet/zCmMZuUywcl8nCcZl889xpbK5sjWWV39hWi9uxkTNn5HHJ/CLOnJEng/uEsY5dKaW01hpiFYHGRHdKOBIlqjmoxSKe3FQ3vkA4Ng10b6zc28CiOP+xRYrHgdbQEYqQEjfbZ3dbRWx5yPAgSwZZEI4tRmQuYK31S8BL3ZZ9P+65xigV12e5OOHYQinFnOJ05hSn8+3zZ7C2rIkX1lfxrw1V/HtTNckuO+fMyueS+UWcMjV3wJkoQTiKeBl4XCn1F/P154F/j2A8g4YlTgf6vc1NcQNQ5wtQmtWz0l1LR4jNla187aypPdaluI3KF23+cIJADpoxuB22xAyyOVFIvP1DbsYFYewzIgJZEI4Em02xeHwWi8dn8b2LZ7FqTwMvbKjkpY3VPLuuknSvkwvmFHDJ/CJOmJQtM/cJY4VvA7dgzF4KsAEoGLlwBo/goQrkVFMgt/UukFfsqUfH1T+OJ8Vj/Oy1BUJA12x6lihO9zpjGeRwJEooovE47Cil8DhtsUF7giCMbUQgC0c1dpti2ZQclk3J4YeXzuG9XXW8sL6KF9ZX8tiHZeSkuLloriGWF43LxCZiWThK0VpHlVKrgMnAlUAO8NRA3muWyvwdhq3tPq31z/rY7pMYU1ofp7VerZSaAGwFtpubrNRaf6G39x4JVgWJgQrkHDOD3N2H3NIRory5g+89t5nCdE8P/zFAqpk19vkTxzAEwlFsClLcjphY9pvC3apg4XHaYxOHCIIwthGBLIwZXA5bbKS7PxThzW21vLDBEMp/XbGfonQPF88v4pJ5RcwpTkMpEcvC6EcpNQ24xnzUY9Q/Rmt9xgDfb81eeg5GhaAPlVLPa623dNsuFfgasKrbLnZrrRccyTn0RyyDfAgeZDAyyI+uOsCc4jRsSnHZ3cuJRDUZSU4e/eyJvZZjS41lkHsKZJfDhtsUwdBVD9nKGHuddpoJyUQhgnAMIAJZGJN4nHYumFvIBXMLaQuEeW1LDc+vr+SB9/Zyzzt7mJCdxCXzi7hkfhHT8g+3YqEgDAvbgHeBi7XWuwCUUv91CO8fyOylAD8Gfg7cdsQRHyKH6kHOTjHGJlY0dfKXd/YwLiuJafkpJLns3H7BDE6anMMEc1rp7sQsFt0yyMFwFLfDqHccyyDHBHJXBhlkkJ4gHAuIQBbGPCluBx9bWMzHFhbT3BHk5U3VvLChkrvf3MVdb+xiRkEql8wv4vLFJeSnefrfoSAML5/AKIf5plLqZeAxjAmZBkpvs5ceH7+BUmoRUKq1flEp1V0gT1RKrQVage9qrd/tfgCl1C0Y/mjGjRt3CKEZxA+QGwhOu43MJCer9jYSiWr21rezt76dL54+mU8dP/6g703p02IRwe2wGYP0Yhlky2JhT4hPLBaCMPYRgSwcU2Qkubh66TiuXjqOWp+ff2+s5oX1lfzyP9v5zas7OG1aLqdOy2VBaQazi9JwDLDLVxCGCq31s8CzSqlkjMzv14E8pdSfgGe01q8cyf6VUjbg18ANvayuAsZprRuUUovNOGZrrVu7xXhEs5oeqgcZDJvFurJmAMZnJ1HV7OfGZRP6fV+qWcXC191iEYridtrwOO00tgeBrgyyZdWwMsdeGaQnCGMeEcjCMUteqofrl03g+mUT2FffziMr9/Py5mpe31YLGBMKHDchi1lFaWLFEEYcrXU78CjwqFIqE7gCo7JFfwK5v9lLU4E5wFumL78AeF4pdanWejUQMI+/Rim1G2PiptVHfkZddHmQBy48c1Lc7Khpw2lXPH7LidS0+skbQA9Qsts4RneLRSAcxWVPzCBbVouYxcIUym4RyIIw5hGBLAjAhJxkvnvxLL5z0UzKmzpZX97M29vrWF/ezFs76rjrjV0sHJfBxxYUs3h8JjMKUiW7LIwY5ix6saxtP8RmL8UQxlcD18btqwWjIgYASqm3gG+ZVSxygUatdUQpNQmYyhDManqoZd6ga6De5NwUCtI9FKQPzB7lsNvwOu1mmbcuDIuF3ahUEfMgJ1osJIMsCMcOIpAFIQ6lFKVZSZRmJXHxvCIAGtoCPLO2gsc/LOMHz28GjIzSSZNz+MSiEs6aKbP4CaOXAc5e2henAj9SSoWAKPAFrXXjYMcYjBiC9JAEslnq7XB6dlI9jl6rWLid3T3IiVUsug/WEwRh7CICWRD6ITvFzWdPmcTNJ0+kvKmTtWXNfLS/iX9vquL1bbWkeRxcMr+Ii+YVsmhcpvx4CqOO/mYv7bb89LjnTzHAWstHwqGWeQPIMTPI0wsOXSCneBy91kF2O2x9ZJC7VbGQ77ggjHlEIAvCAInPLl86v4jvXTyL5bvqefqjcp76qJy/rzqAy25jQWkGp07L4ZxZBUzLT5F6y4LQD4da5g26MsjTDyeD7O5dIKd7nb1mkL2xDHJiJlkQhLGLCGRBOEzsNsWpZtWLtkCYD/Y2sHJPI+/vrudXr+zgV6/sYFxWEufMyuecWfksGZ8pvmVB6IVDLfMGcPykLE6fnstxE7IO+XgpvVksQhHcqe5YBllrHcskx4SxI1EoC4IwdhGBLAiDQIrbEZvFD6Cm1c9rW2t4dUsNf1uxn/vf20tmkpMzpucxqyiNucXpLJmQhV2mvhaEwyrzVpKZxEM3Lj2s46W4HdT7OnrEYNVB1hpCEU1n0BTIsTJv4kEWhGMFEciCMATkp3n41PHj+dTx42kLhHlnRx2vbqnhze21PL3WqLCVk+LiuAlZnD+ngAvmFB6SOBCEscTheJCPhBS3s5cMcjRWxQLAH47ErB9u01KRnezG47SJB1kQjgFEIAvCEJPidnDh3EIunFuI1pqmjhDLd9Xz+tYaVu1t5N+bqrnDtZH5JRksHJfBCZOyWToxS7JUwjHD4ZR5OxJSPQ58/u5l3swqFub3LhCK4g9FUKrL+nHN0nGcOi1XbmYF4RhABLIgDCNKKbKSXVwyv4hL5hcRjWre2VnHG9tqWXugmXve2cMf39qN3aYozvBy7qx8zp6Vz7isJIoyvCMdviAMCSMhkNsCYbTWsUG0gXAkNlEIGAP0/CFj+mlrG6/LzpS8lGGJURCEkUUEsiCMIDab4vTpeZw+PQ+AjmCYVXsaWbO/iW3VPh56fx/3vbcXgBkFqZw2PZdlk3M4bkImSS75+gpjg2AkilLgGCZPforbQVRDZygS+x5ZGeQ0jzEV9aaKFlo6Q9KTIwjHKPILKwijiCSXgzNm5HHGDEMw17cF2FblY1t1K69uqeGB9/byl7f34LQrTpiUzZkz8jhrRj7jspNGOHJBOHyC5jTPw1USMcVj/PT5/GGSXA601gTDhgf5jBm5zChI5fanN+LzhzhvdsGwxCQIwuhCBLIgjGJyUtycPNXNyVNz+Owpk+gIhlm9r4l3TVvGD1/Ywg9f2MKE7CROnWaUvJpVlMaknGSpvywcNQTC0WH19aa4jZ++yuZOUj2OWDUZo4qFnd9ctYDL/rCceSUZ/OqK+cMWlyAIowcRyIJwFJHkcsRqL3/nolnsq2/nze21vLOjjidWl/Pwiv0AjM9OYvG4TKYXpDKtIJXp+akUpntENAujEqvE2nCRamaQL//zCi6YU8BPPzEX6BqMN7Mwjde/eRq5Zl1kQRCOPUQgC8JRzIScZG7MmciNJ00kEI6wq7aNjw4089a2Wt7f3RArKQeGh/lTJ4znzBl5FMuAP2EUYVkshotU02cciWre3FZLVbMfgGR3109iaZbYlgThWEYEsiCMEdwOO7OL0pldlM5nThgPQEtHiO01PjZXtvD4h2V879lNfA+YkpfCSZOzWTwhi8XjM0UwCyNKcJgtFjMKUrlkfhFT81L49as7+J+XtgJw6rTcYYtBEITRjQhkQRjDpCc5WToxi6UTs7hh2QR21bbx9o463t5RxxNryvmrackoTPewaHwmS8Znsnh8JjML03DKtNjCMDHcAjnV4+SuaxbS6g/xu9d38s6OOpbIjaIgCHGIQBaEYwSlFFPzU5man8pnT5lEOBJlW7WPNfubWL2/iY/2N/HihioAvE470/JTyEhyMaMwlVmFaYzLSmJCdjKZya4RPhNhrBGMDK9AtkjzOFk0LoMP9zVxyfyiYT++IAijFxHIgnCM4rDbmFOczpzidK5fNgGAqpZOQzDva2J3XRv1bQEeeK+eUETH3leS6eW4CVksGp/J5NxkZhemk57kHKGzEMYCw+1BjufsmflsKG/hwrmFI3J8QRBGJyMikJVS5wO/A+zAfVrrn/Wx3SeBJ4HjtNarhzFEQTgmKUz3cvE8LxfP68qmBcIRyho72FffwZ76NtYeaObdnfU8EzcAcHp+KksmZLJwXCYLSjOYlJOMbZgmfRCOfobbYhHPTSdP5NIFReSmukfk+IIgjE6GXSArpezA3cA5QDnwoVLqea31lm7bpQJfA1YNd4yCIHThdtiZkpfKlLxUIB8ArTUVzZ3srW9nfVkzH+5r4vl1lfx91QHAKKM1vySDBaUZzC81/ooAEfoiEImS7hqZXgin3UZhuniPBUFIZCQyyEuBXVrrPQBKqceAy4At3bb7MfBz4LbhDU8QhP5QSlGSmURJZhKnTDVG/kejmt11bawra449/vT2biJRw55RnOFlQWkGc4rTmZKXwuTcZMZlJeGQwYDHPCNpsRAEQeiNkRDIxUBZ3Oty4Pj4DZRSi4BSrfWLSqk+BbJS6hbgFoBx48YNQaiCIAwUm61rEOAVS0oB6AxG2FzZkiCaX9xYFXuP064Yn53MhOxkolqT7HYwpyiNucXpzC5OJ90r3uZjgWA4MqwThQiCIPTHqBukp5SyAb8GbuhvW631PcA9AEuWLNH9bC4IwjDjddlZMiGLJROyYsta/SH21LWzu7aN3XXGY199Bw67orkjxAvrK2PbTspJ5rgJWbFSdTJ5w9hkpKpYCIIg9MVICOQKoDTudYm5zCIVmAO8ZU6LWwA8r5S6VAbqCcLRT5rHyQLTl9wbje1BNlW0sLGihbUHmvj3pioeX210OuWkuChI95Cb4iYv1UNuqpu8NDfzSjKYW5yOXQYGHpWIxUIQhNHGSAjkD4GpSqmJGML4auBaa6XWugXIsV4rpd4CviXiWBCODbKSXZw6LTc2q1k0qtle4+ODvY1sqWyl1uen1hdgc2Ur9W0BTIszHqeN0swkxmUlMTkvhSm5KWQmu5hZmEpxhhfzhlsYhYxkFQtBEITeGHaBrLUOK6VuBf6DUebtAa31ZqXUj4DVWuvnhzsmQRBGLzabYmZhGjML03qsi0Q1db4Aq/Y2sLG8hQONHRxo7ODdnfUEI9HYdvlpbhaUZlCamURRhpeiDA8F6V6SXHbcDhsZXpfUch5BRCALgjDaGBEPstb6JeClbsu+38e2pw9HTIIgHH3YbYqCdA+XLSjmsgXFseWhSJTqFj/1bQE2VrSwel8TmypaeGt7HYFwtNd9TcpJpjjTS2lWEgtKM1hYmkFemockl12m3R5ixIMsCMJoY9QN0hMEQThSnHYbpVlJlGYlsXBcJtedOAEw6jc3dYSobO6kptWPPxQlEI5Q1eJnfVkztb4AL6yr5FGznrOFy24jyW1nSm4KC8dlUJjuZUZhKnOK00nzSOb5SIhGNaGIFg+yIAijChHIgiAcMyilyEp2kZXsYk5xeq/bRKOaPfXtbKxoprE9REcgTHswQlsgxObKVv66Yj/BuCz0pNxkHrn5eIoyZLKJw8GywkgGWRCE0YQIZEEQhDhsNsWUvBSm5KX0ul5rTUN7kM2VrWwoa2ZzZSt5MkvgEfHxhcXMKEgd6TAEQRBiiEAWBEE4BJRS5KS4OW1aLqeZlTaEw8fjtPObqxaMdBiCIAgJSJ+WIAiCIAiCIMQhAlkQBEEQBEEQ4hCBLAiCIAiCIAhxKK31SMcwKCil6oD9h/HWHKB+kMM5HEZLHDB6YpE4ejJaYpE4enKosYzXWo85E7O0xYPGaIkDRk8sEkdPRkssR3McvbbFY0YgHy5KqdVa6yUSRxejJRaJoyejJRaJoyejKZajkdFy/SSOnoyWWCSOnoyWWMZiHGKxEARBEARBEIQ4RCALgiAIgiAIQhwikOGekQ7AZLTEAaMnFomjJ6MlFomjJ6MplqOR0XL9JI6ejJZYJI6ejJZYxlwcx7wHWRAEQRAEQRDikQyyIAiCIAiCIMQhAlkQBEEQBEEQ4jimBbJS6nyl1Hal1C6l1O3DeNxSpdSbSqktSqnNSqmvmcvvVEpVKKXWmY8LhyGWfUqpjebxVpvLspRSryqldpp/M4chjulx571OKdWqlPr6cFwTpdQDSqlapdSmuGW9XgNl8HvzM7NBKbVoiOP4pVJqm3msZ5RSGebyCUqpzrjr8ufBiuMgsfT5v1BK3WFek+1KqfOGOI7H42LYp5RaZy4fsmtykO/ssH9OxhrSDsfiGfG2eCTbYfP40hb3H8ewt8MHiWVst8Va62PyAdiB3cAkwAWsB2YN07ELgUXm81RgBzALuBP41jBfh31ATrdlvwBuN5/fDvx8BP431cD44bgmwKnAImBTf9cAuBD4N6CAE4BVQxzHuYDDfP7zuDgmxG83TNek1/+F+dldD7iBieb3yj5UcXRb/3/A94f6mhzkOzvsn5Ox9JB2OCGeUdUWD3c7bB5T2uL+4xj2drivWLqtH3Nt8bGcQV4K7NJa79FaB4HHgMuG48Ba6yqt9Ufmcx+wFSgejmMPkMuAv5rP/wp8bJiPfxawW2t9OLNxHTJa63eAxm6L+7oGlwEPa4OVQIZSqnCo4tBav6K1DpsvVwIlg3Gsw4nlIFwGPKa1Dmit9wK7ML5fQxqHUkoBVwL/GIxj9RNHX9/ZYf+cjDGkHT44I9kWD2s7DNIWDySOgzBk7XB/sYzVtvhYFsjFQFnc63JGoHFUSk0AFgKrzEW3mt0ADwx1d5qJBl5RSq1RSt1iLsvXWleZz6uB/GGII56rSfyiDfc1gb6vwUh+bm7CuBO2mKiUWquUelspdcowxdDb/2KkrskpQI3WemfcsiG/Jt2+s6Pxc3I0MSqu0yhoh2H0tcWjoR2G0fkdG+m2eDS1wzBG2+JjWSCPOEqpFOAp4Ota61bgT8BkYAFQhdFlMdScrLVeBFwAfFkpdWr8Sm30UQxbLUCllAu4FHjCXDQS1ySB4b4GvaGU+g4QBv5uLqoCxmmtFwLfAB5VSqUNcRgj/r/oxjUk/oAP+TXp5TsbYzR8ToRDZ5S0wzCK2uLR2A7D6PiOjYK2eFT8L7oxJtviY1kgVwClca9LzGXDglLKifHP/bvW+mkArXWN1jqitY4C9zKI3SN9obWuMP/WAs+Yx6yxuiDMv7VDHUccFwAfaa1rzLiG/ZqY9HUNhv1zo5S6AbgY+JT5xcfsRmswn6/B8JtNG8o4DvK/GIlr4gA+ATweF9+QXpPevrOMos/JUYq0wyajrC0eLe0wjKLv2Ghoi0dTOwxjuy0+lgXyh8BUpdRE8275auD54Tiw6de5H9iqtf513PJ4X8zHgU3d3zvIcSQrpVKt5xiDEDZhXIfrzc2uB54byji6kXAnOtzXJI6+rsHzwHXmyNgTgJa4bp1BRyl1PvD/gEu11h1xy3OVUnbz+SRgKrBnqOIwj9PX/+J54GqllFspNdGM5YOhjAU4G9imtS6Pi2/Irklf31lGyefkKOaYb4fNY462tni0tMMwSr5jo6UtHmXtMIzltlgPwSjDo+WBMbpxB8bdzXeG8bgnY6T/NwDrzMeFwN+Ajeby54HCIY5jEsao1/XAZusaANnA68BO4DUga5iuSzLQAKTHLRvya4LxQ1AFhDD8STf3dQ0wRsLebX5mNgJLhjiOXRj+Ketz8mdz20+a/7N1wEfAJcNwTfr8XwDfMa/JduCCoYzDXP4Q8IVu2w7ZNTnId3bYPydj7cEx3g6bsYyatpgRaofN40hb3H8cw94O9xWLufwhxmhbLFNNC4IgCIIgCEIcx7LFQhAEQRAEQRB6IAJZEARBEARBEOIQgSwIgiAIgiAIcYhAFgRBEARBEIQ4RCALgiAIgiAIQhwikIVjBqVURCm1Lu5x+yDue4JSajhrgwqCIBx1SDssHC04RjoAQRhGOrXWC0Y6CEEQhGMYaYeFowLJIAvHPEqpfUqpXyilNiqlPlBKTTGXT1BKvaGU2qCUel0pNc5cnq+UekYptd58LDN3ZVdK3auU2qyUekUp5R2xkxIEQTiKkHZYGG2IQBaOJbzduvauilvXorWeC/wB+K257C7gr1rrecDfgd+by38PvK21ng8swpgxCIzpNO/WWs8GmjFmExIEQRC6kHZYOCqQmfSEYwalVJvWOqWX5fuAM7XWe5RSTqBaa52tlKrHmMYzZC6v0lrnKKXqgBKtdSBuHxOAV7XWU83X3wacWuufDMOpCYIgHBVIOywcLUgGWRAMdB/PD4VA3PMI4vEXBEE4FKQdFkYNIpAFweCquL8rzOfvA1ebzz8FvGs+fx34IoBSyq6USh+uIAVBEMYw0g4Lowa5sxKOJbxKqXVxr1/WWlslhjKVUhswsg/XmMu+AjyolLoNqANuNJd/DbhHKXUzRobii0DVUAcvCIIwBpB2WDgqEA+ycMxjet+WaK3rRzoWQRCEYxFph4XRhlgsBEEQBEEQBCEOySALgiAIgiAIQhySQRYEQRAEQRCEOEQgC4IgCIIgCEIcIpAFQRAEQRAEIQ4RyIIgCIIgCIIQhwhkQRAEQRAEQYhDBLIgCIIgCIIgxCECWRAEQRAEQRDiEIEsCIIgCIIgCHGIQBYEQRAEQRCEOEQgC4IgCIIgCEIcIpCFoxqllFZKTRnpOARBEARpk4WxgwhkYdBQSu1TSnUqpdriHn8Y6bgGE6XUBPMHIP4c15vrCpVSzyulKs1tJvSzr5OVUu8rpVqUUo1KqeVKqeOG5UQEQRjzHGNt8kvdlj+ilLrTfH66uc0z3baZby5/K25ZD4GvlPqPUurcuNc3mNtd1W2705VSUfM6+5RS25VSN3bbRm4gjhJEIAuDzSVa65S4x60jHdAQkRF3jvPNZVHgZeCT/b1ZKZUG/Au4C8gCioEfAoHBDFIpZR/M/QmCcNRxrLTJxyullh1kfR1wolIqO27Z9cCOg+1UKZUMLAHe7va+RuC6Xt5SqbVOAdKA/wLuVUpNH0D8wihDBLIwLJh33MuVUn8wM6bblFJnxa0vMrOvjUqpXUqpz8Wtsyul/lsptdu8K1+jlCqN2/3ZSqmdSqlmpdTdSinVy/GLzExKVtyyhUqpeqWUUyk1RSn1thlbvVLq8UM9R611jdb6j8CHA9h8mvmef2itI1rrTq31K1rrDXHxfU4ptdU85y1KqUXm8plKqbfM892slLo07j0PKaX+pJR6SSnVDpxhnvtTSqk6pdRepdRXD/XcBEEYW4zBNvkXwP8cZH0QeBa42joH4Crg7/3s9yxgudY6YL5vPHAacAtwnlKqoLc3aYOXMIT0vH6OIYxCRCALw8nxwG4gB/gB8HRc4/gYUA4UAZcDP1VKnWmu+wZwDXAhxl35TUBH3H4vBo7DaISuBM7rfmCtdSWwgsTs7rXAk1rrEPBj4BUgEyjByOwOJTuAiFLqr0qpC5RSmfErlVJXAHdiZCjSgEuBBqWUE3jBjDUP+Arw924ZimsxfihSgffN7ddjZKnPAr6ulOpxjQRBOOYYS23yH4FpSqmzD7LNw3Rlfc8DNgGV/ez3QuDFuNfXAau11k8BW4FP9fYmpZTNTF7kALv6OYYwChGBLAw2z5pZA+vxubh1tcBvtdYhrfXjwHbgIjPzcBLwba21X2u9DriProbss8B3tdbbzbvy9Vrrhrj9/kxr3ay1PgC8CSzoI7ZHMRp1zIzG1eYygBAwHigyY3ivn/OsjzvHb/V7VbqhtW4FTgY0cC9QZ2Zr8s1NPgv8Qmv9oXnOu7TW+4ETgBTznINa6zcwrBrXxO3+Oa31cq11FJgL5Gqtf2Ruv8c83tWHGrMgCEclx0qb3ImRGPhJXxtord8HssyEwnUYgrk/LgTi/c3XxcX4KD1tFkVKqWYznmeAb2it1w7gOMIoQwSyMNh8TGudEfe4N25dhdZax73ej5GdKAIatda+buuKzeelGFmOvqiOe96BISB74ykMD1ohcCqGZ/hdc93/AxTwgWlbuOkgxwPIiTvHX/Wzba9orbdqrW/QWpcAczCuw2/N1X2dcxFQZopfi/hrBVAW93w8ZoNtPYD/BvIRBOFY4Fhpk8EQ8flKqUsOss3fgFuBMzAEbJ8opeYCLVrrMvP1ScBEjOw6GAJ5rlJqQdzbKrXWGRiZ9d8DZyIclYhAFoaT4m5etHEY3VuVGHf1qd3WVZjPy4DJR3pwrXUTRpfdVRhdeY9ZPw5a62qt9ee01kXA54E/qmEcaay13gY8hCGUoe9zrgRKlVLx3934awVGVtqiDNjb7QcyVWt94eBFLwjCUcqYapO11kGMwc4/xhDXvfE34EvAS1rrjj62seiePb7e3O86pVQ1sCpuefdYAsC3MQT0x/o5jjAKEYEsDCd5wFfNARhXADMxGqkyDK/s/yqlPEqpecDNwCPm++4DfqyUmqoM5qnEkciHgtUldjld3WQopa5QSpWYL5swRGa059sPjlLKA7jNl27zdW/bzVBKfdM6ptmleQ2w0tzkPuBbSqnF5jlPMQeHrMLIyPw/8zqeDlxCV0ajOx8APqXUt5VSXnNwzRwl5eQEQRibbfLfAA9wfm8rtdZ7MQbZfWcA+4r5j822/EqMwXkL4h5fAa5VSjl6OVYQ+D/g+wM4ljDKEIEsDDYvqMSam/FdWKuAqUA9hlfs8jjf2jXABIzMxTPAD7TWr5nrfg38EyPT0ArcD3gPM77nzRiqtdbr45YfB6xSSrWZ23zN9OseKp1Am/l8m/m6N3wYA2RWKaPaxEqMASPfBNBaP4FxjR41t30WyDIb3EuACzCu4x+B68wMdA+01hGMATMLgL3me+4D0g/j3ARBOPo4ptpks837Pkb5zL62ec8cJNgnSqkMYBbGjQLAxzDa84fN7Ha11roaeABw0IcgN9eP68f2IYxCVKL9SBCGBqXUDcBntdYnj3QsgiAIxzrSJh8cpdSVGDcMV450LMLIIBlkQRAEQRCERJqB34x0EMLI0cMzIwiCIAiCcCyjtX5lpGMQRhaxWAiCIAiCIAhCHGKxEARBEARBEIQ4xozFIicnR0+YMGGkwxAEQRgQa9asqdda5450HIONtMWCIBxN9NUWjxmBPGHCBFavXj3SYQiCIAwIpdT+kY5hKJC2WBCEo4m+2mKxWAiCIAiCIAhCHCKQBUEQBEEQBCEOEcjCYfP+7noa24MjHYYgCIIwAHz+EK9vrRnpMAThqEAEsnBYRKKa6+7/gEdWHtxGuamihRsf/IBWf+ig2/191X4eXXUArTXlTR3sb2jHH4oMZsiCIBwFaK257A/vcd+7hzPTu3Awfv/6Tm7+62rq2wKAca2rW/yx55Ho6Cz7Olrjiqe21S+/WWOMMTNITxheQpEo4aimsT1IdYufWx/9iD9+ahF5aR42VbTw5Uc/4tdXLmB9WTNvbq/jkZX7+dLpU6j1+fn2kxu46rhxnDkjj8b2IE+vLecXL28H4L5397Cnvh0Ap10xuyid8+cU0NAWoD0Y4atnTqUg3QNAOBLlL+/sYdnkbBaOyxxQ3G2BMMFwlKxk19BcGGHMUuvzk+p24nXZRzqUMU1Fcyfry1soyvDy2VNGOprRTySqOdDYwcScZCqbO2nuCDGrKK3HdqFIlGfWVgBQ3xYgO9nFD57fzN9W7ueJz5/Iyj0N/OODMh7//AmUZCb1e1yfP8SDy/fx6RPGJ7Sn339uE9urfdx1zULy0jy9xlvd6qc4wwtAU3uQZ9ZWsL68GafdRmaSE7fDzhdPn0yy28HjHx7ghy9s4Y4LZvCZEycc5lU6fMKRKJsrW2kPhDl+UjZ2m+qxTXlTBxf89l0+feJ4vn3+jGGPURgaRCALh0UoEgXA5w+zqaKF1fubWFfWzNySdG566ENqfQG2VrXi84cBuP/dvdy4bCIf7TcE85vb6xL2d9HcQuYUp/PEmjK+de408tM87Klv5/1d9fzs39tw2hVKKV5YV8mDNx7HkglZ/M9LW3lw+T5sCm6/YAa3nDo5tr9gOMpLG6s4d3Y+SS5HLObL//Q+rZ0hXvvmabHlFlprHl6xn5c3VfO7qxeQ7HYQ0Zo0j7PH+b+3s568NDfT8lMH5Xp2BiM8saaMq44rxe0YuABbva+R93bV8/Wzpw1KHEIi7YEw/lCEzCQXl961nMsWFHHHhTNHOqwxzZr9TQBUmZlNoYv9De1keF2kJ3W1Sf9cXcb3nt3EB985m//99zb+s7maR24+nqUTs9he7cMfijC/NIM3t9VS32ZY4hrbg9zzzh4eXrEfpeCB5Xt5f3cDzR0hbn5oNf/z8TnMLUnvsy3SWnP70xt5cUMVBxo7+NUV8wHYU9fG31buR2u46K73OH1aLl88fTL5aR4eeG8vVy8dx91v7uLhFfv430/MpaE9yJ/e2o3PH6Yw3YPW0NwZxB+KkpfmxmGz8d/PbCTV4+DH/9rKovGZzCpM49l1FTy66gBNHSEunlfIF0+fjNth50BDB9c9sIpfXTEfj9PO/7y4lbs/tYgn15Txwd5GfnXFfILhKA67LSbqq1v8uBw2klx2Hly+j1e2VDMhO5nfXLUAgD+/vZtfvbIDgG+dO42rl47j7e11XDK/CJfDZlyLpzbiC4Rj2fiN5S3MLkrD1ouYbguESXEPn/TqCIbZ39DBzMKeN03CwRGBLBwWoYjR5eXzh2L2iRpfgHUr9tNg+pJb49Y1tAd5bl0FNmU0GF8/eyp2pchKcVGQ5uHUabk47Ta+ePrkHseqbO4k2e2guSPIdQ98wK2PruXieYVm9mIcDW1BfvrSNuaVZHDCpGy01nz32Y38c3U51ywdx08/PofWzjD/+PAA26p9ALGMdXsgzMzCNE6fnsuf397NP1eXA3D1PStp6giSmeTipa+dgsfZ9UOxu66NGx/6gHNnF3D3tYt6xPu3lfs5fmIWJZleHly+j08uKollvfvit6/v4C9v7yEzycUl84sAeGNbDR6HnYXjMnvNWvpDEb7++DrKmzr5yplTe81sCEfGV/+xlj317dx97SKqW/0i2oaBj0yBXC3XugfX3ruK06bn8tOPz40t+3BfI+GopqbVT02rn2A4yvUPfEBmkpPKFj9JLjubf3geT39UgcOmCEc1Te0h3tlZx+yiNBaOy+CRlQcAuPWMKdz77h4u//MKAGYUpHLvdUsozUqiormTFzdU4nHaWbO/iRc3VDE5N5mnPirnuhPHM68kgz+/vRuX3cY91y3hoeV7eWljFTtr2zhjeh6/eW0Hr2ypYUtVK8kuB99+aiMAZ83I47bzpzOjoEvAnfebd3huXSVN7UEWlGZw73VLuOj373L1X1YyJT+FtQeamZSbTFaSi9++tpPjJmSxbHI233tuE/saOthS1YrWsGJPA3c8vYE3t9URjEQ5+9dv09AeRGsozvBitykONHbgsCmykl3U+gIUpHlYe6CZb547jZLMJKpa/KR5HCyZkMXdb+7mhfVVbK/x8dD7+/jVFfN5aWMV7+2qx6aM38M9dW1c8of3eOCGJZw5Iz/h//fB3kauumcFt54xha+fPa3PNvtAQwdKQWlWEpsqWnA7bEztlowJRaI47Tb2N7QTimim5KX0uq+/rzzAL1/Zzvrvn4vXZaczGKGypZPJuT239/lDHGjsYHZRen8fxWMCEcjCYRE2M8htgTCtnYYIrmv1U97USXGGl+oWPy2dIVo7QxSkeWhsD7KvoYOcFOOu/caTJpLu7ZmZ7Y0isysu3evkD9cs4hN/Ws597+3lmqWl3HnJbIKRKFuqWvnKP9aSn+amtTPMgcYOJuUm848PDrClqpX1Zc0AnDkjD6/LzkPv78Nlt5GR5OSJNeX86F9gtym+ePpkjp+YxS0Pr2FKXgpbqlr56UtbyUlxc+q0XOaXpPOD5zYTiujYeQOs3NNAitvBzMI0vvfsJk6dlsvp03L55X+289f393HPdUuYlJvM717byWnTcjl1Wi4r9zRw+1MbmJqfylvba2P7uWR+EWWNHdz0kFFLdkZBKk9+cRkvbahiVlEac4qNxuvPb++mvKkTgPZgmLvf3EWS08HXzp56JP/aQSEa1fz0pa1ce/w4JpkN8SMr97N0YtagZd2Hmp01Pl7fZvxfHnp/L2DcUAlDy5oDhkCu9fkJR4xsn2C0uZUtnWytak1YvrG8BTCywo3tQRaOy2BqXgqhiGGBe3tHHS2dIbZVt7J4fCar9jbS2BGk3hdkQk4SVy0ZxyMrDzApJ5lvnjuNz50yifd317O9xseDy/fxmftXsXh8Fv/aUEkgbLT7qW4HnzlhPN86dzpn/t9bfOKP71OS6WVfQwfXnTie06blctq0XB774AC3P72RzZUtFGd42VjRQqrbwcv/dSpPrC7jhEnZnDApu8e5XjK/MJa1/b8r5pOb6uaxW07gFy9v592ddfz4stl8+oTx7Kxt49zfvENTR5BXt9Tw9g6jZ7K1M4Q2bcv/2VyDx2njN5fP58Hl+7hm6Ti8Lju7atrwhyN86vhxsR7P3161gOJML6f98i1e2ljFLadOxucPk5ns4s5LZnP2b95mV10bXz1rKg+v2McFv3uHqIbLF5dwoKGDVn+YWp/h765tDRCJalbsbmB3XRsXzyvkQGMHWsNdb+wi2e3gC6clJoSC4Si/emU7D7y3l7kl6TzzpZO45t6V+PxhlozP5NdXLmBcdhJPf1TOD57bzE8+PocfvrCFiTnJPPXFZb1+buraAgTDUSqaO/noQBM/emELHcEwy28/k8J0b8K2D6/Yz+9f38nmH56X8L2LRHUPMV/R3Mn6smYunFvY5+d1W7WPGQWpR+13WASycFgE4ywWraaNoqY1QFVLJ4XpHjqCYVo7w/j8YdK8hlWhpTNoWiWMBvZwmFuSzoM3LMWmYNmUHAAcdhu/vnI+tz2xgcwkFxNzUrhySQk3njSRi37/LuWNHXz97KmkuB18clEJoUiUkkwv1xw3jgk5yWytauWNbbWcNzufKXmGeFv9vbNJdTv4xj/X8/AKYyDiX97ezQmTsnlvVz0uuw2fP4zWmjue3shjH5axaFwGD96wFIB3d9axq8bHlLwU/KEIV/5lBaWZXnbXtXP/e3vJSnbR1BGkKN3Luzvr8DjszC5KYeWeBgCaOwzxfdWSUv65pozTf/lWbGDNtceP4+rjSvnjm7tJ9Tjw+Y3r/Pb2OlI9XQK5pSNERyhMYbqXa+5ZSUtniM+fNonLFhT3em3LGjv4xwcH+OpZU3l2bQX3v7eX31y1ICbIo1HNnS9s5uMLi/v1fNf4/Nz33l4K0j1Myk1h+a56vvvsJm46aSK3nTed/3lpC986dzoZSS46gxEu+v27/ORjc2L/0+68vrWG/DQPc4rT+efqMs6bXdDrDVZ9W4AfPL+ZWYVpfOn0ySg1sKx6NKp58P19XDCnIHZD9sDyvbgcNkKRKE+sMXoW2kQgDyntgTBbq3zkpbqp9QWo9QVi/49jnUYz87mrtg2tNUop2gNhdtW1AUYvXWN7kOMnZvE/Zob5+fWVvL2jLnYtT5uWy6q9jTS1B6lrC7BkQiZzitO4/sTxnDg5B6UU6UlOLphbyAVzCzllag43PbSaN7bVcMn8Ir5y5hS8TjuZyS6cpuh58ovL+OfqMnbVtnHlcaXcsGxCLOZPLi7h7rd2UdbYyZ8/vZj3d9czPjuZ4gzvQW1hl8wv4lev7CDd6+SieYYAm5Sbwp8/s5hoVMesCxmm1aS5I8T+hnbcDiMmnz9MVGtcdhuZyU5uWDaRjy8s4eMLSwZ0recWp/PiBksgh0j1OBiXncQfr12E02HjtGm53LhsAr97fSfhaJQ7L5nNFx5ZQ0WzP5Y48fnDPLG6jNufNjLlwXA0JjK9Tju7a9tobA9y7b0rOW1aLidOzuZPb+1m1d5GI5vdGsAfiuDzhzlxUjabK1u46Pfv8tLXTmF3XRu+QJivPbYOgDRP1+/pH9/axRtba3nSFMw+sxe3ormTh5bvIxCOENXG7/VLG6tZuaeBe69bAkCdL0AgHI3dFAC8tb2Wrz++jtvPn8FZM/P5r8fX8durF/D3lfv589u72fk/F2K3KbTWBMJRPE47O2t8fOUfa9lW7WNybjJ3XbOoV198b/x7YxWPfVjG769ZSLrXSUfQaBMWj8+kpSNEIBzp1ds+FIhAFg6LeIuF9QWs9fmpbPazdGIWdW2BmMUizeM0vGUdIZx2G6luR6/erIFy8tSeImrx+Cze+NbpPZb/66un4LCpBIsEwB0XdPlIZxam9fBnWb7jOy+dzbySdBaOy+Qbj6/jrR113HbedDZVtLCjxkdFcyePfVgGGOdnWUq0hsoWP7/45DzOmpnHF//+EevKmvnzpxdT1dLJjpo2itI93HjyRDoCYTpDEf6zuZqfvrSN2lY/voCxn48tLKYk08tvX9/Jdy+aSVWLn/vf28sTq8vITHLx1bOm8t1nN9HmDydktMubOrjm3pWkup289LVTWFvWhD8U5bYnN3Dp/CLe3F5LVYufTywsoc4XYHNlC99/fjN1vgBnzcxjfXkzO2vb+MSf3ufGkybwxdMmE4xEeXjFfv6zuZprlo7j0VUH+NdXTiYvzUNVSydn/9/b/PMLJzK7KJ0286apLRAmEtX85MWtgGG7WV/ezCMrD3DylFzOn1NAdaufPfXtbKpsiQnkJ9eU8/CKfeSlerjv+iV8/7nNLCjN4I4LZ/D/ntxAKBLlU8ePJxiOUtPqpyjDS0tniIt+/y61vgAvbqgiEIrwjXOnD+gztae+jR//awv3vbuHv928lAnZyTz9UQWfWFjM9hofaw80x85HGDo2VrQQiWounFvIQ+/vo6qlUwSyiZWZ9PnD1LUFyEv1xKwEAPW+AE0dQbLjBszlprgB2FvfTkcwQnGml1SPg1qfn8b2ILmpbpRS/PCyOb0ec/H4LNZ892zsNtXnzebEnOQ+B6Y57TZ+8cn5bK5sYW5JOnNLBtZ1Pz47mU8uKmFGQWqPtjv+t8O6SW7pDNHYHiI72UUoqmn1h4hGISvZxXvfPuOQM5gXzyvkf/+9jfKmDnz+MKlu4zhnz+qyTGQmu7jz0tmx16keJ20BHy0xgRyKtRd2m6KxIxgT8MWZXlr9IXbU+NhWbTz+8s4eXHYbv71qAevKmnlyTXlsXxfPL+Rb503jk39awYbyFnz+MEkuOydPyaGqxU9Fc2csji2VrWyJ62WwElgVTZ3sb2hnZmEaG8pbaOkMsWZ/Iyt2N8RtG4r9zUx2sWZ/Izc99CFRDTtr28hJcfPerno2VrTQ1BEiqqHNH+bDfY384j/bKG/qZMUdZ3HXG7uoaOrk9gtmcNfrO3lw+V5+afrUe0NrzUcHmlk8PpPlu+t5e0cdX/jbGv5601Ke+qiC7z27iX9/7RR+8uIWdtW28cY3Tyd5GHzcIpCFwyIcn0HuNL6AVS2GB64g3cPeeietnSF8/jA5KS6UMgSk22FLGGAy1BzpYIh0r5MbT5oIwLO3nkS9L8Ck3BS+/eQGfP5wLNObk+JO8Fwnu+zYlOLi+YUkuRz843Mn0NoZit2V9xbjiZMMcbhyb2OsIU31OPjKWVO56eSJsQZhQk4yv/rPdn595QKiOv5GJYxSiqhZgq+ssZOclAiBcAR/KEqyy0570Hj+i5e3s63ax3ef3RT7gfWaP0StZq9AYbqH4yZkcc87e6j3BfnSGUZ3YE1rgN++thOA/Y0d5KV52FvfTnswwq7aNmYXpeMzfxg6ghHe3VnH1qpWlDK6Pi0h3/2vNaAzGtXc/tQGwlFNssvIjrV0GtfWut4tnSE+2NvIp+9bRTAS5TsXzmRqfgo1rQHuvW4Jz66t4A9v7uIrZ02NZboOhvVDVNXi56cvbeNXV8wnEI4yoyCVcdlJrD3QjMtuE4vFEFNnisDF4zNNgSw+ZIs6swcJjCxyXqqHDaa9AoybPK1JqCiRm2oI5M2VhmDKS/WQlexiZ01bwvqDcaTd4ydOzubEyT1tFP3xf1f2Lags3A47SS47zR1BmjuCZCS5CIQjtHYaGeQ0r+Ow4l9QmgHA/gZDII/P7r+qh9WbZwnSVn841lvqdtpp7gjhddpJdTvITHLS2hmOtTt3XbOQgnQPk3NTyEp2sa+hnbZAONZrmO51xm4UW/1GG5qT4uae65bwi5e38Zd39sR6FVo6Q3QEIzGPstWubihvpj0YYW5xekwgN3cYIr77ttZv+obyFqLa+G1o6QzF4k1ox/0h7npzFzvMz1R1i5+G9gBT81P4wmmTeXZtRex9ffH+7gY+dd8qXvzqybFjr9jTwJvba6k324SfvrSV5bsMMf/Ht3Zx23lDXy3k6DSGCCNOzGIRCMdE4a7aNsJRTVG6hzSv0xRaIdK8TjKSXDSbX7CBeo9HG2keZ8xPm+pxJPivS7O8tHZ23Sz87JPzePpLy2KVMuw21as4jmdWURqpbgcf7m2MZWBTza6z+Lvlz5wwnrXfO4eTp+bE1rd0hvAFwvj8xjXeU9+Ox2mL2VyAWOkmn9nALhqXwRdOm8zPPjGXp764jCe+cCLQ1fjlp3n4/TULWTohi7LGjti5Xnfi+Fg3an9ity0QprbVaOCK0r3mTUQ4FjN0ZS2s97QHw4SjmlSPwxT0kdi1jmU4OsNsq26NfQ4rmjtj+5uYk8zi8Zmx7MZAsGLKTHJS5wvEziPN6+TyRSVctqCIc2bl0xYYW3VOlVLnK6W2K6V2KaVu72ObK5VSW5RSm5VSjw5lPFbGzfKpVzUfmwJ5b30733lmI6v2NKDNO1jr5gFgd51RCnPtgSYK0jxkJjnZVWsIlKyULtGbl2YK5ApDSOeluslMcrGjxhisnJvSv0Ae7WR4nTR1hGjsCJKV7DJ/e4y2IrWXCkQDwWqrmzqCtAXCA9qPJZDj27WWTuP3L93roLWz63Wax5kgOBeUZnDchKzYzY31G2mNMUn3OhOy5a2mddFaF4lqOoKR2HqIa4PNNnP57noA5pdkGPF1diUcrL+t3dpka3lpltFD19zZtTzhPM1rb6wLJvzOp3mc/c6DUNNqfM9rW42e5wLTQlHnC8SO8+7Oepx2xZkz8rj33b3U+oa+bRCBLBwWlsUiGI7G7nLDZjH3wnQvaR5HTGileZxkeJ20dASNL/ZhNlqjiVSPk45ghMYOo2JHaWYSwUg0luWZkJ3cY9Rxf9htisIMD7U+f0wo9JUBt7oZLYFcaWba2gLhWCMWi8n8YS3OjMtA+MMsKM3k2+fP4Oql41g8PjP2Y2plkNPMBi7d64w1ygCXLSjieksg+7syutZ7oUuYtgfCsWxyUYbH7HHoXRh3de8lCvpKs/uwNa63whL5APlp7oT40ryOWOy+fgTyb17dwSubq2PbWV2fVixpHid5aR5+d/VCijO9tAUO3tAfTSil7MDdwAXALOAapdSsbttMBe4ATtJazwa+PpQxWXatogwPyS77MZtB/v5zm/j7qgNcdc9Knv6oq3YxgNthY3t1K3c8vYF/bajitGm5ZCW72FVriOaspK4b8VS3A7fDxqZKUyCnuc3xD2bP1wAyyKOd9CQXzR0hmtqDZCa7TEFmtBXx3txDIcPb5W1uNT3I/ZHiNoRqrSn2rLauK0EUjO0r3RLxcTfiCedkvj7Q0BF77XXacdqNDLHPH4rZPqz3dm+LuwvlskajHbVsLvECvaXTqjxlZZAtIRwkzeMgM8nVbftQwv5b/WHGZSUlrIsJZK8j1m73Rfx+WztDlGZ5E15brprz5xRy88kTCYaj7DFvEocSEcjCYWFZLAAqu2V5CjM8MVHl84dJ9TjISHIe9RnkeFIsYWqKN+sLXWHe8Q+kQe0N67rFBHI/+7EyG1YcxuAL4/9RYgpiKwthvW5sN/ZvZSAsrBuX1s4Qvs6uHwWrMffFiUbrh8dq+Lpngy0h2R6IxMRygZlB7t6Ad886t1hZCzPeMjP+hAyymanxOu3kpLhjDakVnxV7f5mLh97fxwsbqmLvLclIin1ujevbdY2SXQ78oWjCZ/8oZymwS2u9R2sdBB4DLuu2zeeAu7XWTQBa69qhDKjN7JZOdjkoSDe87ccCa/Y38rXH1vLM2nKeWF3Guzvrue286eSlulm+y8j81fkCpLodTC9I5bEPyvjHB2V84bTJ/OTjc8hOdscEdLzFQilFbqqbGrMXJy/NQ2ZST4/y0UyG10lLZ5CmjhBZSU7SvE58ZlvRXXgOFOt9Te1WBrn/9tzaxvIDGzfxYdK9jq4kg5VB9jpjGeXeBq1bgw/3N7ab5+hCKRXLPLd2JmaQoacw7t6uAtgUTM5NweWwmRlkQxg39ZVBNm2B6Wa8XcI5vjfPOA/LhtJsZqYzzM9Z6gAyyC2dXYK81R8mN9WNx2mLWeumF6RxxwUz+Na502Kf7yaznOxQIgJZOCyCcSKhutWfkOksSveS5nXS2B4kHNWxO+iOYIQ6X2CMZJDNxjAmPo3GoaK5I2H9oWI0pIYtwmW39TtpiHXdK+MGaVgxlZp39BVNRkzWzFVWjN3/Dx6nPVadIz7T39W4W6LRGfsB6WqME71rvrgMclvAELKZSU5z392zzl2DWuJfW/GXNXbE9tnV6FvdlYk/Pm6HDY/THrv+B8sgR83BPM0dwcQMclx2JP4HNtlt/C/ag2PGZlEMlMW9LjeXxTMNmKaUWq6UWqmUOr+3HSmlblFKrVZKra6rq+ttkwHR6g+T4jIG8RZleI/aDPIza8tZva9xwNs/9VEFz62r5L8eX89tT26gOMPLZ0+ZyPSCVHbUGnaIOl+A3FQ3k3NTCEc1Vy4p4fYLZuCMm/QCIDsl0cqVZ2aJPU5jgHT8+oF4kEc7GUlOGtqMbv2MJBepHkcsO3u4vzUepx2v005lSydaD6w97/6bYNktLHuEISrDsQSDLxCmqSNImsfZY9B6LIPc2JnwOiZU/V3n1pXYCBON6l6SFV1tYFGGF5fDRrrXSX1bMNaWxSwW/sT2vKkjRIYZf0ucoI7PINe0+olEdSyD3NQeNKtXWfE5+u3J6xL3Xdcsw+uKs2s4+PxpkxmfnRz7rFu9t0OJCGShX/yhSMIoWeiyWIBRI9EqUu5xGrWF4xumNE+if2o4B+kNFVYGtbyp07BGmBOBdGWQDz9z0doZoi0Q6jd7DJDksmNTXceFrgxG9wyyZbEo79boJh7f0VV9xMxQpHlNO0l7ILaN027MPNXa2ZfYtQbphY2ZozwOo+uz20AP42+iqI75umMZZEMgx1tYrMGh6XGNd3zGyPr8+Q6SuTDK9HVlQxw2RV6qm6jumqQi/ofRen6MVbJwAFOB04FrgHuVUhndN9Ja36O1XqK1XpKbm3vYB4vP1hWkedhZ4+PO5zcPS7ZosAiEI9zx9Eb+9NbuAb9nT10bC0ozeOHWk/nzpxfxyGePx+2wMy0/lV21bUSimjpfgJxUN+fNzufUabkJFRSy4kRvRrf21RLBeakelFKxDHKq29GjQsTRSEaSM9ZGZJkWi+4+3cPeb+PA23OrzamIWcLMm3iPs1sG2bCAaW30vvbWDlvLyhqNCUOs70Rat0y0sczqzTPGoViDrls7jQpCbYEw+aZ9bkJ2cmz/VuIBDK911NzWih2gpSNIepIrFn9Cptd8bvXwFZkTr1j/i4xYfE58/hDRaJdmaA+EeWNbTex1bL+dwdiNTfwx46+R9fmWDLIwKnhk5X7O/807CR/w7t3MlkAuSvcaXUHeRGER32iPCYuFu6sxTDM9ZWCIUY/ThstxeF+tmMXCP7DpSJVSpLgdvWeQzax2ebcst/W6t+7HNI8xSC0YjiZkkK1ztdtUrNpF/OCLHgNDAl1/jTJJDlI9jgTxGV8OKf693T3IlqCPj701ruHsrSEdSAY5vlH2+a3BNImDYxIzyMY+x1AliwqgNO51ibksnnLgea11SGu9F9iBIZiHhDZ/OHZjeN7sAvLTPDz0/j7e2Dakzo5BZe2BZvyhKHvqB+6R3FPXzpS8FOaWpHP+nEIm5hhCZnp+Kv5QlLLGDurajAzy+XMKefimpbEBwECstJvhOU4UvZZAtkRSVrIzYfnRTrrXFUvYZCa7SPM6CEU0kag+ot7KdK+T8qaB9wha21iTqVi9ZVYb5fMbGeN0b1cP3IHGjj4EsvH/LG/qSCiLmuZ10tRhZH7jLXDQ5de1aI0rMzfdnKXQskGke50x+wYYtra2YLy4jrNYJDnNesSR2FTlFc2dWHKgPE4Qp3kc7I/zTYPxOxHVxuBri6c+Kuemh1bHfgtik42ZdZjTvE7Sk8ysu5kIsXA77KS4HTS2D/14EBHIQr/UtwXxBcIJtopQN4E8MScZmzL8x5DYfZ/mdSb43g534MRoIjUug5wW1+BVNHcedvYYjEbFGmg30BJ1qR4n1a1dXdFdGeSkhNeWxaK8ObEBS9iX1xkT2GndGuCyRuNmwKqHmuZ19MgcWw1dWyyDHKHdyiDHXSPoObDP120f48zG3MpIQGL3pdXNaGXd4wflWP+Dg3nfms2BKc3txntTE250jMxNSpwIsQTyGMogfwhMVUpNVEq5gKuB57tt8yxG9hilVA6G5WLPUAXkC3RVHjh7Vj4vfe0UgKPKi/y+6Rk+0NhBMNy/X93nD1HrCzApN7nHuqn5RuJhR43PsFj04Rm2up2zutkrAHJTjDY5L9X4a7XFY2GAHiRmzLOSXD1+e45kv1ZbNZA2vXuPX2unUW4t3euMxdgRjJgWi652pnvGH7ra3FBEx7y81vLYzXt3i0VcGUzr+FZbNbPAGDAeL5AtXzoYGeREcW1aLNqDhsUiqUvQAwnZ5/hKGxlJrtg28YP04vcJXeOWrPEyLd2y0Wkeh+kt733cUmaycaMw1IhAFvolEDZ8SoFQvEDWCdtkJDkZn53MpByjQY//QMdnWOHIGq3RQnx3e7q3q8EzGsDDvwGwrlNlc+eAfcxWZtaiorkTh02Rn278AJY3dWBTRpbJZbfFZUd77j/N44hlBLp34ZU3dST87wzLRB8l2wJd/re2gJENt65RfFUKSBxMorWO7SMm6Huxj1jdl1Z2JhCOUuvzx+I7lAxyvBcwXsSndJvQxhpIM9DScaMdrXUYuBX4D7AV+KfWerNS6kdKqUvNzf4DNCiltgBvArdprRt63+OR073nxOO0k53souIoKvf2vjnxQiSqORCXpeuLffXG981qO+OxKuFsrDAmh+gr6xsTyL2UkrSq01jvtbYZKxnkjLg2KSPJmdBuHkkGOTOpKzM9kGRFdxFttcnpSc4ev39Wm+oPRXv9PXQ5bLGeuvj3pnsdMRHcva2Lr6sMJAysnleSwW3nTedj5iyq3QVnc9wYE2NfISJRTas/TIZpsYCuNjN+HEZ8b1t6XILFEv7xg78trBJtVoWlmEBu7EjYV50vQGco0uP/mJXkonEYLBZHfypPGHKsLiNDKFt3tomZkTSPk0c/d3ysIYn/0qd6nHicXfdiY0Egx2cL0uMaPDh8/7G1LzAypdagh/7oLqQrmjsTRHtTR4g0jyH2Uj1ddozefjys+tXx+423WEwv6Cpdl+7tylx3t1jED9LzmSWArP1ZPzrdRXU4qvGHorR0hkh1O0hyGYMG4xtCq0HtCEZQBBOy92WNnbEZEZ12Gx6n7aAe5PhsS3mTMUW6dU3KGjt6XJ8xaLFAa/0S8FK3Zd+Pe66Bb5iPIcfnD8cGZ1oYg/WOjgxyeyDMurJmTp6Sw3u76tld1x6bvr4v9tQb9Ysn95JBTnE7KM7wxipZ9JVBzk42xW9Sbxlk04NsCmWrxu9YqGAB3TLIyS7q2uJ/e47Mg2wxkKRH/LFyUrqqihg33vGi3ZHQtvRlOcxIctLZEumWbOoZk8NuI8XtSPAIAwk18NO8Dr58xpRez8flsJnVI4z32m0qodpQRjeB3x2rfbaSFVa5164Mci8C2cxeW2NKrGNZ+0rzGFn3Bmvf3bLsmcnDI5Algyz0iz9kZpDDfVss0rxOCtO9MXEY/wVM8zp6dBMd7XTvxnM77LGbgMFolNuDkQFbLKztrJlgg6aHy+O0x2bkS4trrCyB2usgPU/Pxji+u6/7eXcf9RyzWJgiMqoNi068xcIiGI7iD0USsrxWaaQ0r9P0svf9WWkPRhJ8w90zDake54AyyGBmx+N+yFr9PUs7pYw9i8Wow9dLSa3CdE+Cx360ET8248WNVYSjmutOHA8Qq9X6zo463tze5aN+Y1sNP3phC5sqWthd145NdVmKujMtP4V1Zc1A31nfgWSQ802LRU5yomA+2rH8umBkfQfLYhG/3wFZLFyOWBtsDZA29tMzg5yYFe593/GVK3rbNrWbWG71h2K2MY/TlpBB7v5bEr+f8VlJNHd0lbYsSPPQ2hmOVazIjMsgW8ey6J746m2sUdeA6a52s68Mcvy+DnaNJIMsjBoSM8gG3S0W3e+wu3fFux02HDZFOKrHhEB2O2w47SpBNKZ5nPhDR1bGLv7aDKSKBXQ1lLkpbmp9VqWJLkEcX1rP+j/ZbYokV88R7AmZjm4NnHGsxExIS0fIsEWYxdwD4SiBcCTBhtDQHogN0rOwMixWbU2Xw0YwHI3NvtiVvXZQ3xbA47ThNy0+NtXVfdnTvpM4OHSgAjkUMWbuO9iP6xj0II86fP6e3vuiDC8rdg+ZqyOBd3fW0RGMcN7sgn63fXVLDXe9sZOtVa1cf+IEPn/aZH7/+k7mFqdzzqx8clPd7K5rY3ddG597eDXhqOaBG45j4bgMvvXEBhrbgzywfC+5qW5KMpP6LOn4lbOmkuJxUtncGZvkoTsH8yDPLkrn9gtmcO7sfMDIxv3lM4tZOiFroJdlVGOJMq/TjtdlJ71btvZI9wsDS3rYbIoUl1G+rTjTG7up6S724q1c0LdAjk3U1McA9+5tdXyFoNLMJKOqRaw3MPEY1r5tyiinWdXi76oFn+nlQGNHrDZyd4vI+OxkNpozM5ZkJrGrti1WyznD27P97K0mveV/rvX5CYQj+ENRlCI2SDDd6yA9ftxSDw+yS6pYCKMDy3vsD/XMILvsiRlKC0toGLV8bSileniSjmas6hHQsyvpSEoLJQhk98CukyWkM5NcMdFr/TB0DVpLtL6kmxna7vSWQe5+sxN77nXiC4TpCEYIRqKx6UF9fqNrz2H6d7U2xGX8exNmSvKHY35ja4a8+Diha8AhGDM1WnTPznTPsBxskF5vWYuD+RdjdZBFIA8JoUgUfyja48e8KMOTMKX9UHL3m7v4zas7eo3tlodXc/97ewF4cUMVn//batoDYc6bXcD9y/dywv++TnlTJ988dxpKKSbnJrOlspXbnliPx2lnal4KX3xkDbc8vJqmjiCPfu54zp2VT10fA/QsFo3L5K5rFvLUF5eR05fFIsVFYbqHWabFKB67TfGF0yYnXNfzZhfErBZHO9bvSmYvvy9HNEjPfG9fyYTesNrig2eQHaS6u7LNGX3E2FsG+WBtsWWxcDls5KW5afXHWSw8vWeQ073GAPqWOItFSWaSua/eM8jx1j/rPK1KG9Z2HqctVkKwu8XCH4rE2t74qaQLzd8P69wy+jhXMG4I24ORWO/2UCECWeiX2CC9XiwWmcmJd4kW1iCDNG9X1QPLZnEkAnI0Yf3gdHUlJVZQOBwSvdsDH6Rn/e3uAe/+N7WbcB7I8XuzaoBx3lp3VRgoMRtOa/R0flyDl+JJzCBbJegazZmqLIEcm+a6mzjPS3XjtBufI2tbK4a0PkRtfwXqWzoSBVeqxxHz81nvj8ftMDzRbYExM1HIqMK68eieQbZuiIbDZtHcEYr5HuP535e28cqWGt7bWUdLR4j/enwdi8Zl8sJXTuYP1y7i3187hU8sLObq40o5bVouAJNyU9hS1crasmZ+/LE5/PWmpRw/MYuVexr5xMISlk3O4a5rF3LlkhI+vrD7/CyHhtNuY8UdZ3HZgiPbz9FIhmmFsAR/ah89Xoe8X1Nwp7gdvSYTesM6XklcG2VNZmSR7jUmBumeYOlx/H4sFj0GTPvDtHSEYuNP4jPI3Xsjrf1kJLnITHLS1NE1SK8402uUdPMFY3HEH8uyAtkUsfr/VpbbyvpmJNhTEqtYWLYK63n3qkXWuR3MYmFVYmnuGNqb5rGhVIQhJWaxCPW0WGQlG9OY9j7gy5FQqzPDawzW6292uKOFLjGaKEq7Txt6KCRmkAcokONEcYrHQa0v0CP70CWMe2aF4+nLgmFZNXrLsFrF9EsyvXyw1xgR3RYIMy0/patMkjkpgWWlsDLIlS2JJeisDPLMwtSE+K1Gv6E9aBxnX1dcB/vROJioau4MUpjuic3WFu+fN6bi7nmNkt322DTawuDS2/TeYFgsAKqa/cwo6JkhHUxaOkM0thuTJlgVTHbU+Hhg+V6Ugob2IOXNHQQjUW4+eWKsfZtRkMYvr5ifsK+L5xVS2+rn1jOnsqA0A4AHb1zKjhpfLAvndtj5xeWJ7xMODavuvGUz8TgN+5vdpo7ot8byIA+0HYauNqS4WwbZ5TAmVuowx01Yy33+cJ8CuT8PcnxcaV4HW6uMDHKGJZD9xoRT8bXru7bv+h3ITHbRGYpQ3xYgyWUnq1tJt8wkF067jWSXnfZghPHmZzft/7d33nFyldX/f5/d2dnZXtM3nSSkkIQk9N5BIAEBpaiACuIXBAVR/OpXsaBgQUWxoIL6U0OxJQhIB0F6SQgBElLJpm62ZstsmX1+fzz3zr0zO7Ml2dmd7J736zWvuf2euXPnmc89z3nOyfEGgkcFdwKb44tKufHHJblZVDV6HuQJpbm8tKEm2uvcXe0EN5d3TVMbo4tCpAr1ICs94sUgd/Ugl+bZH3+iikxuSU2XnkbD7m/EZ3lwG4t98Vr4B/v1JQ+yPX/AN53kPUED5scfq+z3msR/Rnssa5/bkLpe4Z2O4PQ3XPlxnms3ZMIV1+4filtOOr7h9SfXj//zSRbP15sY5HFO9Se/bf4SqfHkZQdoUg9ySkgukJ0qlQPgQa5tbnPSW3kPQZucgh/TRxZQ3dgWLZbQUx7hI6eW89tLD4mKY5fpowqGRAW7dEFEKM0NRgWyiMTkGt5bkvWOdoe77bhi2775HULFOVkxudV7clZ0J5ALsgPRdstd7i+eVJgTiGaxKAh19YD7Ba07/UGNO1DZzm+uselB4//nJvhyKcevS2Sz+1nd35SbwWLOuKKYEIuJTpU/d4C23wsd3+vsepBTnQtZBbLSI63RLBZ+D3InmRndN0QTy/KYUObF1p00cxRnzR2bWmMHkC4hFnGe5L0l3uvbE66QLghlRb3JyWwqjPMkx+NuHx8mEh9n7Z92c1e68WiukIkJsciOFdhelT+7r+slrGu25VLjG1p/fPC4mO7LrKh3I/5zFTgju5NR19xOca4X6xb/cJEoVCY/O6CD9FKEO+I+/rqPLAiRmSEpT/UWbo9Ex1n4wyzcVFQHjilgd2Mru50u4mTxwMrAc9v5c2PTmMU9OO8NrkDri9B2793Rhfaeje/diq2K10OIRW6sV9ZvS6IxP3taO6hpaqM41/4nt7RHqGlqS+ho8UIsvCJeW2qaKczxxoq4Vf78VfzAi0G2Ajm2zSyOhlrE2ZfjOSvc4iCzxhYSbu/0Kr9GPdOx1yVRr7P7MJTqTBYaYqH0SCIPckfEkJUpnDRzVFTcxPOziw7G/+B60aETUmrnQJPcg7zvAnlnQ2sfslh4oR7+ab9N8fHRyUMsYoW13yb/ufzbxpeydgXy6BiBHDtY0A2xcPcdUxRCxItnjs+g4c8dOjYuBtl9t2nfYvNRh9s7aY90kpXZ1RfQ0NJO0diiaL5N72Ei9t1PfnZgyBQKSTcak8QgZ2YIowtDvL+zEWMMb26pY9aYwn73wvrjGWua2phqQ4mp2tOKiPX8LluxLdpjUp4gY4QyOLhx3y4FoVgP697gir2+eJDzncF3Bc6YC7+4Ls7Ninm4jvaSJaikB15MtX8wpfUGd7UpWuCotoVZYwuj89uSVHb1e5BdT/mW2mbmVRR7VfOqm2LSsxbnZjlxxzmIxOb/9wtu/7z/s0Y9yHtaCWQIM5wiOOt22TzgrvD298S650l2bfZrD7KInC4ia0RknYjclGD9VSKySkRWiMjzIjLLt+4rzn5rROS0VNqpdE/Ug+zLYtEW6SQrI4PzF1bwf2fNSrhfTjBzSHclJovr3ZcQC/B3o/VOaOf7xG/SzBpxwjfZQMlEqd3sfFfPs3sOtxR0NK7YFci+EIv4LBqleTbjhrtvUY61PVmZa3/1qZLcIPlOF2PUc5yga6+nanpud2R08GgvPMh52QGa2lQgpwJXPCT6/Zx44Egee2cnx/7gaT78ixf4yt9X9fv53RyyANWNsQOJSnODjHRCKtbs2EN2IKNPsanKwHLhIRP46KLx+3QMd3ByX9rzgycUc9jk0mhRJn97dODoQqaPii20lJkhScesnDxzFD+8YB4H+oozZTjbx7fP7nnc3je3rdyapCJrbjCTccU5TBtVwMKJJcwYVdAl1WVtc2yJZzcbR7TnOCcr+h8V/3/TRSDneFVXd+1pZURBdrSHcV2VFcjjnR7IaAo65zyJBLLrVXfDnVJFyn7hIpIJ3AmcAlQCr4rIcmPMO77N/mKM+ZWz/WLgduB0RyhfCMwGxgJPiMh0Y4wG/w0CifMgd5IVGN4ROsk8yPsa++Yer7ceZP95k8UgdxHzyUIsksRRd+dBdj1qowrdrvBwdN7F70HOEMgL2j+PbU4JYXcQnut9js++4a63y6x3JitTorF10Wvm+7Nxr8WecHuXAgrtkU6a2iJOF2P8Q0Tya5QfCkRFvdK/NCQZcQ/wzcWzKc0LsmzFVk6eOYp/vLmVs+aO4aSZo/rt/H4PcnVc9cYRBdnRkIq1O/dQnp/d68wGysBz8WH901s5b3xxtDpnb/jIovF8xBHmYwpzGOVzEty8eHbMtrPHFrKuqjHpfRTKyuT8hRVdlvudBS5HH1DO4nljaW6LcNbcMdF7eWdDK3PGds2dLSI896UTELHTP7lwPkt+/l9K87IZUxyiMBRgbHEOVxwzJbrPIZNKCTg9cYvnjWVuRVEXx0dxjnV8xPcqF4QCrK9qpLmtg/d37mFkQXa06M26XY3kBjMpyQ2SIbFjP5KNWwpkZjCmKMSdT6+jsraZby+Zw+uba8kQ4ehp5Qmv596QykfgQ4F1xpgNACJyL7AEiApkY0yDb/s8wK0+sQS41xjTCmwUkXXO8V5Mob1KEroLsRjOzKsoZm5FUbRxWDixhEMmlTAxSUWs3lKYQOx1x/jSXCaX5zFnXGG09HP8k3wiwZkIdwR4Mg9FvIdWhOhI7KzMDApDnhe4NC8YLabiFtkoyQ1SnBskI0M4dHIpy1Zsix6rIOT3IGc52/s9yJ5wdYvP+K9ZfnYg2oC7x4SuHuS2js5oHJz1igRjtu8un3V+UEMsUkVjNGdr13szI0P4winT+cIp02nr6OSsnz3HDx5d088C2RPFNY2xMcgjCrIpc0IqNlU3cVBFcb+dV0lf7v/MEXu9752XLOj2P/KyoyZz2VGT+3zcK46Z0iVzw+iiEHdcdHB0fqVTpARgcnniHNsZvhCUmWMKeeCqIygvyKYwlMXKb5zaRbh/2ieWv33OHADe3W4lnNtmBgMZPPr5Y7tUfCwMZbG9Lswxtz1NdVMb158yPVrqfGdDK2OKQmQ4oVT+0LwDRuQnrR75wFVH8Pv/buKeFzbxn7VV7G5s45hp5fuNQB4HbPHNVwKHxW8kIlcD1wNB4ETfvi/F7Tv8EjymCYnyILdFOglkDG8P8qmzR3Oqr+LWjNEFPHDVkft83L4O0ivKyeLpLx4PwMsbamKOMXNMARUlORwwMh8g2k3s9+76EREOn1LGwRNKYpaPLsohK1NiUu9kZAhTyvOIdBq+8qGZjs1ZUY9yQShAXnaAumavMt5Vx03lzLljAPjRBfM4cHQh7+1ocLzftgoVeOJ04cQSvr1kNkdNLaeytiU6crogFCA74t1/k8vzouLaJVEFJ4CvL3ubf67YChDjQY7PtJEsxKK+pZ1dDWFGFoaIdBp2N7YmvZ5K79kTbieQITEPPokIBjI486Cx/OTJtewJt+9zzL9Ldx7kyWV50V6ITgPlQ6TIhpI6kgm7feXSIyf1uM3ciiLuufwQxhSFmD6yoMftwXrLXXrbOzKxLJdDJpWwaKL3fzG+tKuD6ICR+RgMCyeWcOWxU1jkVHG87qRpPPXeLuaNt17upVceHhP3/OuPL0xqS0VJLl87axbHTh/BNx9czWVHTuKKY6ck3HZvGfQgKmPMncCdInIx8DXg0t7uKyJXAlcCTJgwtAaApQuRThPNeezPg9wRMQSHeYhFqjh4QglvfFDXo1BIxPwJxcweWxhN4D5lRD7Pf/nE6PqJZXksv+aohN1uLv/vU12eYzlv4TgOmVTSRYw89oXjEDxvxIkHjuT3L2yKxqnlOR5X97OML82NNqCBzAw+e/zU6LFOnjkqmnptSnl+dJuPHzEJgIsOGc/Zc8cQyMzgymOnEOn0yp3fcOp0PneiN4odPE/kSxtq2FYXJkPg7HljeXjV9mi2gsKcLJbMHxf1gAMsmlTKIZNKotfQz5lzx3Dvqx+w5M7/8pcrDue/63bz3Yff5cHPHc3UEflJr6nSM42tHeQnSEmViHnjizAGVm2t58ipiT1GkU7DO9saaGmP8OL6ap5fV8WRU8v55NGTE/ag1DnppkYWZEcFsjGGqj2tlBdkU5bnCR7NYKGkMyLCCTNGpvw8ucFAr5xClx45iYsPm9BlsLTbK+QysSzW2x1IMLg6nmOnj+DJG47vncF9JJUCeSvgj5KvcJYl417gl33Z1xhzF3AXwKJFi0z8emXf8ccdx+dBHu4hFqli8byxLJ63d+nwDplUykPXHtPtNnP3ons4O5DJtFFdPRHxI8VvXjybTx41mZ17wuRlB8jLzuy16PnMcVP5zHFTk64PZGZEvQt+z71rX3wqIFfE3PHk+9Fl7+3YQ0O4gyuPncJLG6qZObqQ0UUhDqrwHhjmjy9O2ugvnFjCA1cdwSW/fZlr/vIGW+tamFdRzJQk3ZhK72l0crb2Bje38IotdTECubPT8OBb23j8nZ28tKGG3b7BdjNGFXDHU++zta6FH17QtThHbXMbwUAG40pyqGmy++1p7aC1o5MR+dnkBDOjxRLKC9SDrCh9IVEmoXQnlQL5VWCaiEzGitsLgYv9G4jINGOM++91JuBOLwf+IiK3YwfpTQNeSaGtShL8mSviBfJwD7FQEjOhLDeaTD4vO0B+2+CMrR1dFOJvnz2CSKdNyfWJu1/hrv9sIJiZwbUnTeN/nbCQvjJ7bBHfPfcg/ufPb5CZIXxzyWwdsNUP7GntIC/Yu7+k4twgk8pyWbmlLjporq2jk2v+8gavba5lTFGII6eWcdLMkZTlZTOuJIfJ5Xl86a8reXjVDr5zzpwuGXbqm20VsrK87Gh+brcsrttdXpofpKmmRT3IijIMSJlANsZ0iMg1wKNAJnC3MWa1iHwLeM0Ysxy4RkROBtqBWpzwCme7+7ED+jqAqzWDxeDgF8WxWSzMsM9iofRMXjBAS/bg/XQXTiyNTn/muKn83z/f5rAppfucoutDB43hxtNmUJiTFZO6Sdl7WtoiMeXNe2Le+GKefHcXT777HPmhALlZmTSEO/jB+XM5b0FFzCAklyXzx3H/a5U8+e6uaCy8S21zGyW5QcrygrxVWQd0FchledlsUYGsKMOClMYgG2MeBh6OW/Z13/R13ex7C3BL6qxTeoNfFIfbYz3IQQ2xUHrgsiMnpU3e4AsWVvCvldu4pJ9SQPkrdyn7TnNbB7m99CCDDbNYtmIbB44uIDeYyQc1zSy94vCYcJl4Dp9SxoiCbJat2NpFINc1t1OUm0VpfpCaprZo/DF4AtktDqICWVGGPr1qjUTkaGCaMeYeERkB5BtjNqbWNCUdSO5B1hALpWdOntV/abj2lVBWJvftQ9omJbU0t0Uo64PwPH3OaFZtrefLpx/IyIJs2nsxcDgzQ1g8byx/fHET1Y2tMeerb2lnQmkuZXlBOjoNDS0dnkDO9zzIoFX0FGU40KPCEZFvAF8GvuIsygL+lEqjlPQhJgY5xoOsIRaKsr/Ti2qnl4lIlVPtdIWIfDpVtrS09y3EYkxRDrd/ZD6jCkOISK+z6nz0kPG0Rwz/eDN23LcbYuF6i1dvr6eqsZWsTIlmvShVD7KiDBt640E+FzgYeAPAGLNNRDTobpgQ7iaLhYZYKMr+Sy+rnQLcZ4y5JtX2NPcxBnlvmT6qgAUTiln6ygd86ujJ0QGWdc3tFOdmcdLMUYwrzuErf19FfUs7M0YXROOZT51lUxH684ErijI06c0jd5sxxuBUuRMRzWc0jHC9xlmZoiEWijK0iFY7Nca0YVNtLhksY1raIuRkDUxq/gsPncD6qibO/cULPLZ6B+H2CK0dnRTnBsnPDvC9Dx/E5upmgpkZ/OLihdH9Dp5QwnfPPUizlijKMKA3rdH9IvJroFhErgA+CfwmtWYp6YIrigtDWV1LTWuIhaLsz/Sq2ilwnogcC6wFvmCM2RK/wb4WbTLGOIP0Uu9BBjhn/jgqa1t4cOU2brh/JZ89webfdsvyHjt9BL+7dBHTRxUkrAymKMrQp1uFI/Yx+T7gr8DfgBnA140xPxsA25Q0wBXFhTlZMTHIbVooRFGGAw8Ck4wxc4HHgT8k2sgYc5cxZpExZtGIESP6fJLWjk46DeQMkEAOBjK4/pTp/PbSRbS0R/j+v9dw6KRSTvUNKj1p5igVx4oyjOnWg2yMMSLysDHmIGzjqAwzoh7knCzqm9uiy9sjnWRpiIWi7M/0WLHUGFPtm/0t8P1UGNLiFJMZKA+yy9QR+Xz6mCn8/oWN3HLunIS5kxVFGZ70RuG8ISKHpNwSJS1xvcaFoUCCEAv9M1GU/ZhotVMRCWKrnS73byAi/mTBi4F3U2FIc/vgCGSAL58+g5e/cnLCUuqKogxfehODfBhwiYhsBpoAwTqX56bUMiUtiAmx6IgPsVAPsqKkCyKSA0wwxqzpzfa9rHZ6rYgsxlY0rQEuS4XtLU4xmZw+FArpL0SEIs1KoShKHL1pjU5LuRVK2hJu9w3Sa/eyWHREjApkRUkTRORs4IdAEJgsIvOBbxljFne3Xy+qnX4FLwd+ymh2QyyyBt6DrCiKkogeFY4xZjNQDJztvIqdZcowwPMgBwjH5UHWQXqKkjbcjE3bVgdgjFkBTB48c/pG8yDFICuKoiSjN5X0rgP+DIx0Xn8Skc+l2jAlPWjtiBDIEPKCASKdho5IJ8YYOjrVg6woaUS7MaY+bpkZFEv2AneQ3kBlsVAURemJ3oRYfAo4zBjTBCAitwEvAprqbRjQ2t5JdiCDbCfncWuHF3usAllR0obVInIxkCki04BrgRcG2aZe43mQBz4GWVEUJRG9UTgCRHzzEWeZMgxo7egkOyszRiC3R7zqeoqipAWfA2YDrcBfgHrg84NpUF9odgbpaYiFoijpQm8e1+8BXhaRfzjz5wC/S5lFSlrR2hGxHmRn8ExrRwQ3Vah6kBVl8BGRTOAhY8wJwFcH2569oaVdQywURUkvehTIxpjbReQZ4Ghn0eXGmDdTapWSNoTjQyzaOwk4BUICKpAVZdAxxkREpFNEihLEIe8X6CA9RVHSjR4FsogcDqw2xrzhzBeKyGHGmJdTbp0y6LR2RAhlZZIdcD3InQQDNsQiqCEWipIuNAKrRORxbL56AIwx1w6eSb3HFcihgApkRVHSg96EWPwSWOCbb0ywTBmitHbED9KLEIroID1FSTP+7rz2S5pbO8jJytRSz4qipA29EchijImmCzLGdIqIDjUeJtgsFplkZ/kH6dnbQUMsFCU9MMb8wSkXPd1ZtMYY0z6YNvWF5vaIhlcoipJW9EbhbBCRa0Uky3ldB2xItWFKetDaESE7K8MLsWj3slhoiIWipAcicjzwPnAn8AtgrYgcO5g29YWWtogO0FMUJa3ojUC+CjgS2Oq8DgOuTKVRSvqQKMTCS/OmHmRFSRN+BJxqjDnOGHMscBrw40G2qdc0t3WoB1lRlLSiN1ksdgEXDoAtg44xhua2CHnZ6RFB8u+3t1MYyuLIA8q73e6ND2p5ZNV2jjygnBNmjIxZt6+emXB7REMsFCX9yTLGrHFnjDFrRSRrMA3qC81tEXK0SIiiKGlEUoUjIlc4FZkQy90iUi8ib4nIkBug19lpuPbeFRz/w2cG5dxvflDbZfkPH1vLTX9fRWdn8oqxj63ewYd/8QK/eW4jdzz5fnT59voWPvun15n9jX/znX+9Q11zGxuqGrn1kff4/X838srGGhpbbXL+Z9bs4sl3d3Y59luVdWyrC1OYkxUNsQi3R7RQiKKkH6+JyG9F5Hjn9RvgtcE2qre0tEXIzVIPsqIo6UN3j+zXAb93pi8C5gFTgIOBnwLHpNSyAeZHj6/hwZXbALc4xsA11s+t282ld7/Ckzccx9QR+dHlLW0Rtta18MqmGg6fUgZYL/fLG2t4fXMtB4zM59v/eofpo/I5fEoZS1/5gKbWDr7z0Ds88FolmRnCCTNG8tvnN3LPC5sQoNMYXL1dkpvFCzedxDeWr6a9o5MTDxyJiBW9lbXNXPKblynLD/I/x0+lLD9IZoawvqqRkQUhAILqQVaUdOGzwNXYEtMAz2FjkfcLmtsijCnabxzeiqIMA7oTyB2+UdBnAX80xlQDT4jI91Nv2sBhjOEPL2wmmJlBW6STxnAH2fkDJ5Brmlqd9zamjvCWu+VX739tC4dPKaO1I8KND7zFckfIu/zlisNoao3wxxc386tn17P0lS1csLCCa0+axvjSXFZvq+eht7YT6TR8+pgpGGN4eNV2bn7wHf788mY2VzcDsHF3E1Mcgf7Iqh3sae1g2TVHMb40F4BZYwp5bVMtiyaWAhpioShpRAD4qTHmdohW18seXJN6T0u7DtJTFCW96E4gd4rIGKAWOAm4xbcuJ6VWDTC79rTS2NrBvIoiVlbW09jaQVn+wP23uEny3XcXt/zqI6t2cOuHO/nuQ++yfOU2bjhlOh87fCJPvbeLlvYIR04tp7rRiuy7/rOBguwA3z5nDiGny3L22CJmjy2KOfbFh03kR4+t5ae+sIz/rtsdFchPr9nFjFEF0XmAhRNLuPfVD6J2aoiFoqQNTwInY/PUg22jH8MOsE57dJCest9TXwk5JRDMG2xLlH6iOxfg17ExbJuA5caY1QAichy9TPMmIqeLyBoRWSciNyVYf72IvOPENT8pIhN96yIissJ5Le/Lh+or66vsf8rcimKAaGzuQNHiCM6WNu+8nZ2GcHsnZXlBWtoj1Le0s2bnHhZOLOFzJ02jJC/IeQsr+Njh9pKV5WczpTyP1o5OTpszOiqOkxEMZHD8gSPZE+5gXHEO44pzeH7dbsB+/lc31XD8jBEx+yyaVEK4vZOVlXX2GOpBVpR0IWSMccUxznTuINrTJ5rbIuT6B+k9eB28s2zwDFIGntZG6GhNvC5cDyb5WJwYertdIra9Cc01fd9v13vw80Pg2dv2/txK2pFU4Rhj/gVMBGYaY67wrXoN+GhPB3a6+O4EzgBmAReJyKy4zd4EFhlj5gJ/BfyhGy3GmPnOa3GvPs1esqHKVmadW2G9rI3hwRHIfg9yuMNOlzue7Oa2DprbIhSEkjv9F04sAWDxvLG9Ou/JM23Gi2Onl3PMtHJeWF9N1Z5Wnn9/N+0Rw/FxGTHc0IoX11cDGmKhKGlEk3/wtIgsAloG0Z4+EZNtZ88OeP338N5Dg2rTkGTbCvjbFRBx/uOMgdrNe3eszk7Y/IJ3LJdNz8OKpV2Xu0TaocbnY1v1VysuvzcOvjMSfrYIXvkNdEasaH74RrhtEvz9Cmh3bulIBzx1Czxwub1fXLa+Ad+fAhuetdtUrbXL1z8FT38XNj4HL/4C3nrAE90N2+z0O8vhruPhZwvsepf6SnjkJrjrBNj8IjRW2c/X5lR0b6mDBy6D9mZrS2cnvPxrb/3e0NFqr1N/8MFL8I+rrF1Kn+g2r44xpgMbYuFf1ttv/VBgnTFmA4CI3AssAd7xHetp3/YvAR/r5bH7lQ1VTeRkZTJ1pA0nGHAPcntXgexOlxcEWbPT2tTU2sH4kuROofMXVtDcHuHIqWW9Ou+JB45k3vhiPryggnB7hHtf3cJh332CTgMF2QEWTSqJ2X50UYiKkhxWba0HIC9bu0QVJU34PPCAiLgDFMbQO0fG6dhB15nAb40xtybZ7jysE+MQY0y/Zsdo6+iko9N4WSw2PW/fm6r68zQKwH9/Cqv/Did9HYrHw8p74Z9XweWPWLG4/ik44auQ0YPzwxh47Kvw0i/gmBvs8cCKxfs+Di01VpAWVcBxN0LxRPjHZ+C4m+D1e+zDz3Ffhl2r4d0HYcw8OOFrgIH3H4OHvwidHbB9pbXxgJNh1QPWwzvnfFj7b9i+AjKyYOOz8NkXICPgnbtqjb1//vYpOPp6eOUuaGvs6uHNCNjzZGaDCIw9GCQTlv0PTDwSisZZsfvyr2z4xAOX2feqd+Hxr8PkY2HTc9C0G7ILoXUP7HgLHvkS5JXDnPNiz9ewDR76Isw+x66TDFjzsP38RRWw4217Td9ZBhMOh4/9zZ6npQ6mnQozzoCMTOvl3vgsTD3RToeKILfU+w7CdVAyyc6//zisXArHfQlKp0DjLti5GqaeAC21EG6AEqfzfv1T8Pof4ILf2+sBULcFnr0VFn4SKhZCUzXkldmHhXeWwRkJmwx7TT54yV6jUGH391NPtLdA1sBH9qYy8eQ4YItvvhJbZCQZnwIe8c2HROQ1oAO41Rjzz3630GHD7kYml+dRGLKjqAdaIDdHQyw8gexOex7kCE2tkW5F6WFTyjhsSu/EMUBBKItlVx8VnX/i+mP511vbATh8SlnCQiA3njaDFVvqOHXW6Gg2C0VRBgcROQTYYox5VUQOBD4DfBj4N7Cxh33dXr5TsO3zqyKy3BjzTtx2BdisRi+n4CMQ6TSceODIqIOCTc/Z90YVyL2isxPqNkPp5O63a22ENc5fbEst5I+CZ75r51/+NexYBTXrrQAsnWw9mAecDNn5scfpjMCT37RCrnAcPP8TmLkYxs6H52+3xz71Fvugs2MV/P0zMGo2VL4Kfz4fMDBythVdWblw4v/BUZ+HTEeOHHsj/L9z4anvWFF79Bfg5Jvh/SfgiZvtfuXT4bzfWVv/9GErpLe/BQ2Vzmeth0ibnX7+dsgphSuftd7gMfOgfosVb+E6KKyA6vdh17tw3m+t9/ZnC+x+Z/7Ifp6C0XDJX+G3J9l9zvwRrHvKfqaSyXDxffDv/7ViM1xnzxuutx7lF++0Ivboz1s71zxkX3t2wJTj4d6LrVAOFdlzZeVBdgFUr7ff7Qs/A9MJb/zBit5LH4TV/7DCWTLBRGDycXCpE4n67G1WdF+30rkWe+z7znesB/2RL0NHi13/ws+tKL72DbvNhmfgnX9ab3gwzz5o/PYUez3zRkAgCL86xj6QvPcvePmXcMq3YPPz9vvJHwlHXWcfgh75sv0OQkVw/t32XuoNG5+zn7lonH1o2vgMLPscXPEk1H1gv8NFn/QEfApJi8zsIvIxYBFwnG/xRGPMVhGZAjwlIquMMevj9rsSp6rfhAkT9vr8G3c3cdC4IvKdAiEDLZDDCTzIrlfZFciNrR00tXXExun1MweMLODzJxd0u82S+eNYMn9cymxQFKVP/Bo7OA/gCOB/gc8B84G7gPO72bfHXj6HbwO3ATf2m9U+coKZ3H3ZId6CqAd5VypON/R484/WK/nFtVD1HuxeCwsutQJix9vWazn9VCuOO5wQhXAdrPizFRxj5ltRBFaAPfZV79jZRbDk51b8rn0U1j1hwyN2r4WFl1vP8S+OgD9fAAdfYsMX5l0ER15jX9tW2LCFDU/DkddC5WswYgacebsVieMWQeGY2M8jAqfdAr862or4Y26wy6edDAecBM3V1jsLVkSCFZaNO6xgbmu2QjXQBggceqX12I6db19gvecTuxm/evDH4I0/WrHe2mC9w6PnwCeWQWYQxi2AQz4du0+o0AnXaHCucYP1er9wh50vm2LFIljPd9V79pgAs8+168qmwbwL4elb4O2/2wcE02kfEEJF8K8v2DCSpt32GEf8D6x70opGl4at0LDdm2917Nm5Gt78k/Wag30AbdhmXy7heu89mAcb/2PFsWTaZTUbAQO1G70HgdYGG+6y1elYmn2O9VrnjYCzfmx7Dt66v3uB3NEGb90H8y+xXun3H7XLJxwBtZugvQnuvcQ+CHZ2WO/5+fdYb3oK2Su1JSIHGmPe62GzrcB433yFsyz+WCcDXwWOM8ZEI/SNMVud9w0i8gw2/3KMQDbG3IX9E2DRokV7FZnf2hFhS00zS+aNJd+J7x3oGORoFot277zxHuQmJ8QiP02q/CmKkhZkGmPcUUUfBe4yxvwN+JuIrOhh3x57+Zy45vHGmIdEJKlA7i9nBQ3boXqdFSRNu60Hrafu/uHEfR+DScfAYZ/xlm14Fjrbbdf5i3daz17lq9Yz+vztdpuv7bKhFW5IQUutDVMoOwA+fBfceaj1yl72EDz2NdudXzAaHvs/uP/j3rnKDrChAMfcYIUcWM/l0gvh+R/D9DOsuHUZO996FNc9aUM3sny9jjPPTv45R822XseiCdab6iLiiWOwghjs52mptZ7ijIAVbZE2ex99aC+y0s4538bBV62xwtAVthMOT75PdoE9rytIWxsAsd7hjIANfXApHm+P6wrSY74Io3xDtEJFznpnn9wymHKCd9zWBsgptt7b1kbvAQfsfpFWaA/b6+16kNc+AvUf2NCOt//mnb+jxXrNA9mxArlwrGdz0bhYe7tM10Egxx6rpdYuK5kE00+D4gl2WXesfxKWX2MfnsJ1ECyAtj32/K4NNeth5Cz7kPTCz+zDV8XC7o+7j+yt2noM6KkVfBWYJiKTscL4QuBi/wYicjDWA3K6U9LaXV4CNBtjWkWkHDiK2AF8/cYH1c10GpgyIp/crExErBgdSFxvcUuiGOT8IGBzJHcayNW4X0VRPDJFJOCMFzkJR6Q67NPTtIhkALcDl/W0bX84KwAbVwow7RT7J95Sa+MdFRv3+/4TVjD4BfIWJ/IlXGevVyBkPYVgBWRLrRVUu9fC2AVQ+Yo9RlMVFI23ouSUb8O4hbaL/MN3ecf+5L+tUMwIwPjDPI+nnxEz4MpnbDjFxKO6dn2f8k3rAe1rl/jsc3veJlQEiCOkaj3BHG6AQKsnbPtKNJ7XidF157vDjUGOCscGwFgbMoP2+xGx8c75o2JFZrydoWIbOlG/1Zt343jD9fbY2c58TrH9/MbY47uCMlxvBbJ7jm1v2vcDz3QEcp0nwFvqoGCUt617jJZaCOZDbnmsvX7h2tpgp0sm2dhsd50bAx0qjn04SERztffu7rtzlXP962woz4d+ABWHWo/yCz/z9kkhSRtQEbkj2SqguKcDG2M6ROQa4FHsAJC7jTGrReRbwGvGmOXAD4B87OASgA+cjBUzgV+LSCc208at8XFx/cW2+jAAFSU5ZGQI+cEAewYpzVtMFgs3xKLAepB3NVjnunqQFUXxsRR4VkR2Y7NWPAcgIgcA9T3s21MvXwEwB3jGaZ9HA8tFZHF/D9SL4v6Rjpxp35t2qUB2aWuyHrqdqz0xVF9pu9TBE4nTToEP/dB2wb//KPzzs1ZMNO22IrfyFbtd0247aAvgqGsTnzOQHSvGkxEqgklHJ1+fqnjRjEwvdrel1go5E7GirSN77weHhYrte7jOisKe4rvBepDDDZ6IbG2w4RGhYiuQW+qsNzmn2C5rqPTu9y4C2Zmv2+zNBwsAscdvbfA+W6jIfua2Jhsv7vfsFozyPMhgHyAmOKElLbU+MV0XK5CjQth56Ij3aLvXxd02XA8Vi6xAdoV3TrF3Tn8YRyJcD7MriPPK7AOAa2NOiRX27nX175NCulNblwM3AIkSE17Um4MbYx4GHo5b9nXfdMKgFGPMC8BBvTnHvuIKUTfFUF52IK08yCOcEItde6yQz0thDLKiKPsXxphbRORJbNaKx4yJJoHNwMYid0e3vXzGmHog2p/thLp9MWXiGLw/3bID7HtTFdZfokSzerTUQONOGwLxwUveelckhortOrCCEWDPTis8iidY4Ryus6I51xeusL+SU2w/d3ONjeGNtFmhmhncew+yP3Sj1eet7Y5QoRfqAtaGzg5rQyDbXnNX0IeK7INO2InvjS8u4trtpuDLKbahRqFCR4Q3eNv4xXx2fuwgQbD2Z+XZON4JR/q87D7B2xK3T/S9zhH0RfZBzO9Bdqf37LSfu3iit66lzrMrp9g7j8v2lfDMrXDBH+zAP79AbqmzYTyhYk8wu8cC33ezF/mq+0h3autV4G1HrMYgIjenzKIBxhXIbmGN/FBg0LJYNPsKhbiiuSgni6xMYdce+5yiqdUURfFjjHkpwbK1vdivN718A4vrHSqbZt8bdyXfdijT2WkzLbjptyC2S3nn21YEb3nZiyt2QyxcAQE2dhVslgZ3PqfYipq2xqHhnXfDSFrqbChER4t9gMjIskJrb8jK8by+/hjk7nBFtOvRb22wmUByim1YxZ7t9rsKFTmisd47dryHPepB/iB2PrvI8yC7D0Gup7alzoYidBG5DTDxCBsHPvlYG3YRCNn7qc2pLRQvqv0e5FCxz4PsE87uPvWOje692lRlxbjfg9xS6/V6AKx/2mbaqN8CZVM9gd5c4wliV1i31Ho9HdFrIYPuQT4fCCdaYYzpRX/D/kFru02enR2wA0HyswPsGeBBegmzWDhiOZSVSV52IBpikachFoqi9BM99fLFLT8+5QaF623qr0Kn2FHT7pSfMu3o7IRlV8PKv9iY4fN/ZwWCPy/0thXw3sM29dfk4+wgpz3boSMcJ5Cd2NmqNc58mV1fvc6ZHwoe5BJo3m2zLeSU2EFr4QabNi40e++OKWKPtWeHk6qsFx5kdzChm1Ei7AwULBxjBWnVu1Yg55Zakdfa4DzQFCf4TM6yaIiFMx8Vqv4QC2dduM6GU5hObx7sslGz4fivwOi53j6u+IbkHuSWWjt4M14gN9d42TrqnHG++aPsQ0VtnM05JfYBzg0BAe9ebqpyBLLrQa5xQiqKYx98/B5k1wu/NxUP+0h3w4PzjTHNKbdgkHEr1kU9yIMRYuHmQW7vmuYtN5hJXjAQ9SCnMs2boijKoBKuc7qgi23X8/6a6u0/P7CV2XrL+0/AH8+xXc//vMqK44M+Yge+vXaP3cZ9WMjIsrmHX/udTed27q+t97J2k12fyIO82/Eg55Xba+sK5LwhIpD9nz1UaMVnbz2/yQgVewK1NyEW7jauQG6tj72fW3we41ARYKwHNZGNMSEW4h3bFdbheutNhlgPsitgwclQ0WozWmQX2BjhQNDbx71mYO1sD3u5o6OhF74Y5I6w9cxHP6MTzeUKbTe2OvpdOHa54tbv8fULZP+6hm02XMP1ILshFvEPEbmlA+JB7k4g/9OdEJG/pdySQaJLiEV2/4dYtLRF2N2YpMY8XmhFokp61oOcSXWTDtJTFGWI48ZWZmTYPKr7Y4iFMVbArvhL7/dZ85DNFfzrY23O2BO+ZrNJlEz0BIgrJsYfalNgTT8Dzrod8kdYQVGz0a73C+TsAiuod7se5HLHM1fjze/vuLGqYD9bdqENHWjds28V3HJKunpDu8P1ILthQu6APTdEobXeXndXMIP9bhMKZGd9Q6X9DG6qw1Ch9Zy2NyX2IPtjfcP13gC97LhzhIpiS4y7qdn8+xrjDZCLD/mo8+1bv8Wzw/+w4vcgu/a5JBPI0XvYOVbjTlu0JF4g++/hFNKd2vIHxUxJutV+TtgJsQi5IRahQL/lQTbG8I83t3LrI+/RHunkxa+cFBXiiWxoiSsUkh3IIDNDyA0GcIfe5AY1BllRlCFKuN7zluWN2D9DLBp3WYHWsLXnbV3qt9pBTpOOhrkfsRXWwC5zxUhztR1sNfEo2Po6nP5db/+c4lhx4SJivciuGMorj10/VDzI/mlXOJrOffMg5xR7KfR6I7TjtwnXE03z5pZJbqn1eZCxAjBRbuVs/2co9p2jyPNQu8dI5kF2Pc0Qm0sa7DHbfNktEnmf21us99n1DIMXB9/uCy5wQyzc2Orda2PtitqXyINcHbvOL65zSnxp8Ipj7c8ptWE1KaY7gWySTA8pwu0RAhlCINOLQe4PD3JzWwc33L+SR97ewfjSHHbtaeXF9dWccODImO06Ip20RRyB7A+xaItEM2v4vcbqQVYUZcgSrrfCGKxndH8Msahx6lnt2d79dn7qK22c6Dm/iF1eMtHLX9tUZQXtMdfDgo/bjBQuOcWe4PELRrACuXGHs640cQjGXtLe3k5lZSXhcMLhSgND2Wlw2qF2OjwScovhtPvtfG4pvPtunw8ZCoWoyBtDlit9ejVIL74KrbNvTrEtohE9eFHsQ0qiY2cGvGIZ/vWhIu97dkV0sMCmj/OnXoNYD3K8eI/3yCba1++V7+4BIdLq2RYqJvq54z3I/lzI7oNv1INcF3ss14MctTfuns4p8QaeppDu1NY8EXFKwZDjTOPMG2PMPvRdpA/h9s4Yr64rkI0xyD7kbvzdcxt55O0d3HTGgVx25CQWfecJHl29o4tAdkVxZobEZrFoi5Dr2OX3GmuhEEVRhiytDV6Kt7yRsHvd4NqzN7jlj5uqvAplPdFQmbj0cfFE25XcuseKirxy6430i2NInAbLxR2oFyp2Bq4520pm70IHuqGyspKCggImTZq0T/+X+0Rztdf1P3KGjaWtdbzpJZO6Xo8eMMZQXV1N5ehTmYwT/92rGGSfkM0p9UIAQsWeBxliPcjufCJcMewXs347XNGakeHkgq7zhGZm0Mt2AQk8yL5z5o2I9SC7ntsYgezbPivX8yC76ePcY/ptTRaDbExsiEVnxIafxNhXHOc5L45dn1MCzYMYg2yMyTTGFBpjCowxAWfanR8S4hjsIL1QlncZ8kMBOo0Vri9tqObMO55j3a493PWf9fzg0Z6qa1ua2zq454VNnDBjBFcdN5VQVibHzxjB4+/sJNIZ64x3wypK84KE2zvpdNY3t0cIxXmQszKF7IAKZEVRhijheu+Pv2yqTSH15LdtZof9BdeDDDYLQk+41dcSpSRzU2fVbnY8yCMSHyNGmMQJQjeMwn131+eW7XMZ73A4TFlZ2eCJY7BCPzodsN7UROt6ezgRysrKCAd91fN65UHO96aLffV3uoi9eIHsW+cnPs9xvB0xYrko1gtcND4uBjlOsvmPWTIpNn7Z3TeZQHYr5IH3OQM59kEwkaj155QGe55OxxnYVBUrzF168iDnllpRHUltQoVhX+Q+3B6JEZ1uGrXG1g6WvvIBq7c1sOTn/+W7D7/HnU+vZ/W2+mSHinLvK1uoaWrj6hMOiC47bfZoqpvaePOD2Kce14NclheMmQ+3RaKeY9cmzWChKMqQxZjYzANHfg7mfwye+yGse3xwbesL1T6B3FMFMfDKCScSyK6nuG6z9SAnG1TnCoiMgC0N7McNo3D3dcV0P8UfD6o4BvuZo9OZ9uWf3wtEJFZo9yYGOZBt8x2DFZnRfROEVCQTvX6iHtgk3uZ4kd1S54hcsfeSmw4OunqQ3WO7Za/9HuTiCbFFRNxBhi5uQRB3W78t7nGzcr2MGcE8rzgN+MYViJ12hXNMruPiroI5xv4EA/9SwLAXyK3tnTEe5AJHjNY3t/PMmioOmVRCMJDBBQsryM8O8KtnN3R7vLaOTn7z3AYOnVTKokneE+jBE4oBWLerMWb7Zp8H2T/f3BYhxw2xyO4ai6woijKkaG/xKo+B7ZY++WY77U9Jle7UbPCEw57eCGRn0FVCgTzJvtdutoOSkonaaJ7c4q5FJ1yBnMiDPBRwRbBk2s8e41Hehx5XVyBLRteHjmS4QjpeIMd7VoP53vF78iDHiOsEIRbuNq4HOVTohUlEY5ATZLFw9/PvC1YAh+u9PMPxHuRoeI94+crjvd3+zyTipWwDLzNNySR7T3cRyE5au5jP7ZsGG8ICKU/1NuwFcrg90iUGGeDZtVXUt7Rz+VGTefWrJ/ODC+ZxyeETeOitbVTWJk8P/c8VW9leH+azJ0yNWT6yIATAjobYwQyux9gVyP6cyNHUc0HXg6zhFYqiDFGiI+59f/y5ZVbkuPlX0x1jrECedIyd740HuaEbgZxbasXUzrdtjtqeQiwSxdtGPcjOuys2hkIGC0CCudzwzdujnuQf/vin3PyjXwFw87dvQURYt86LZf/JT36CiPDaa7Zi+qRJk9i9O0FGBFfAZhd2fehIhuup9YdYuCLUxU1jGBWV3cQgx6+PCbFI4EFuqfNCOML1XmxvoiwW7nvU+1xvPb0Fo8BEvCwsOSXWI+x66t0QC1eI++1y5xOmZauz02788chZNn7c9Si7Atm9Pv57Of4auetSXCxEBXJHrEB2wxmWrdhGVqZwzLTyaIaL8xZU0Gng5Q2Jv5T1VY3c+fQ6Zo0p5PjpsQ1ZMJBBeX6QnfEC2RHE5fm2a6a5vSO63BXEuY5NWkVPUZQhizugyP9nmJEB+SP3H4G8Z7sdwDT2YCsqGpJksmisgp2r7XR9pRVj+aO7bidiPXqVVsz16EHuTiB38SAPDYGcnZ3N3x95it21zv0TE4OcwUEHHcS9994bXfTAAw8we3YvKuxFPbx9GHLlPtz5H3ZCRY7AzPLmE73H01MMclIPcrEnkMMNNowifqCoP3wjp9iW526qivV2126yNgfz7H3ontuNiw8VxRYwiT9uzGcp9ry9UYE806axq3F65V2BHP+wFyywg0v95MbFNaeIYa+4wvEhFiF7SVZtrefkmSMpCGVF100dkU9uMJO3Kus4ZFIpL22sZsn8sVx//0r+s7aKxtYOcrIy+c7H5ySMyxpVGGJHfWKBHB9i0dLuhVjka4iFoihDnWQ5T/NHpm/BEGNszmPXQ7f+afs+Yobtfm7Yard58FroaIMld9qQgPsugS2vwBFXW/FfMLarCHApmWQLiUBygdytB9npjnaFcj/HILt888HVvLOtoecN+8CssYV84+zuxWwgEODKS87jx3f9kVtuP9zx9jovEc455xyWLVvG1772NdavX09RURFZWVndHhPwCeQ+5FJ274OiuMFrYK97U1VXUZlUIBc7+/kLvxR6x83Mit3WjUF2PcgdYeud7ZJ+jlhB6x7fLVoSreK3ya53tUyoyHp83RjkULEn0rsLsXA/g5tq0PUYj5hh3928yVEPsrNvVq7NxpHono4O/Kuxv6+Nz9rqkPmjYeZZXbffS4a94gq3RyjO8W60scU55GcHOGnmSL61ZE7MtpkZwpxxRayorOd7j7zLI2/v4KdPvM/WuhbOW1DBpLJcLjpsQtQbHM/owhDb4gRyczchFjnR0AoNsVAUZYgTFchxgiF/VHp4kNvD9g/bzfyw4Vl46jtQ+YqtanfIp+CJm2HcIph4NBSMsR7ll38Nb/zR7hMIwrTTbAGKikPhxZ8DYqvjJePoz0Mw116DMQcn3iZZ1zZ4YRl5TorR3HJYeBlMP71PHz+dufpTlzD3xPP40je+ZxeIRGOTCwsLGT9+PG+//TbLli3jox/9KPfcc0/PB42GWPRBILv3buFYu3/8QLrWPZAV8uYh8XfmP1aijBddQg6KbYnmPdth9EHe+votiT3g8SEWYOPc88rjBHKCMAf/wLzsOBvji4P47aty8lE3VdkY4gKnx8Qte14yOXZfEWewXoLr78+M8cz34Nnb7PwBp6hA7k/iY5BL84K89Y1TychIHHM0f3wxv//vJtbu2MPUEXmsr2riupOm8YVTpvd4rlFFId7cUhd7/miIRZwHuc3vQQ7EvCuKogw5ogI57g89fyTsWDUwNtRusqmjyg+IXd5SB785AaadCqd9F+77GKx5GArHwSFXwKoHYO0jgMDF91kRXTgO3l0OW9+wAnrkgfD8j61YLpkElz9sxfNjX00cf+wy/tDuBTR0H2Ixag6cfQcceKadz8iAs3/aq8vRF3ry9KaSwvGz+cQnPsEdd9xBTk4OkBEzQO/CCy/k3nvv5dFHH+XJJ5/sm0DeGw9yqMhO+/fNKfbCiPzH7VOIRWHse3S5s03dFluN0Z2vr0x8/PgQC7Cx8GVTve0bd3qi1d02M2g/V7DAqbAXH1oR9x49X4lTIrvFS1foPrjtft8K7dxSQGL3zSlJPIgxu8h+Py//ynq+518CJ/5f8hj9vWTYK65weyfZWbGh2MnEMcDciiJb+S4C31oyhzljiyjK7UV3DdaDXNPURmuHl1rOG6TnxCC32SIlLe2+GORoLLJ6kBVFGaJ060HeZQsK7GXarl7zyJftH/mnfWnljIF/fcHGSlavsyJ6zcNw6JVwyretR/CUb8G7D1r7xi2w+xVV2HjkqSfCub+0f/QTj4ZXfwOHfNp2kR95jR3QVTZt3+yOFyh+RGDhpft2/HQnO5/PX/9FFixYwOWXXx7jQQY466yzuPHGG1m0aBGFhb2MKRaxQrCvMciZQQiErIiLz08d9gnknGJv20SMWwAjZ1vR6pKZZUMP4vMau8V1TCQ2LVv9lsQPX8F8KyZLJ9sej9Ip9v4OFXkPWdmFcNyNsZ8tVGSvS9lUKJ3aNcQip8QO5suPE6pTT7QPg39YbIu4lM/wYuAbd1ivdEam9WDn+4qpLbo88T2dkQFjF9hBsIdeCad9L3mI0j4w7AVya9wgvZ6YV1EMQEluFodNLo0O4OsNowvtD2FXQyvjS3MBz2Nclu+FWLRFOol0mmip6TwdpKcoylAnqUAebf/4m2u6/vH2N3u2d63QteMtWP1367FqrvFGzh9witddHsyFeR+N3e+wq2z56FlLPLE27WT78jNryb7bHSq2HrT+ONZ+SmlpKR/5yEf43e9+xycv+UjMfZSbm8ttt93G9Ok99/TGcPhVVkD2loWXweg5VkTmj4j1aB57Y2w552mn2XsqWYaMkTPhf17oujxU1FW0Tz4GPvcGrHkEZpxhM55AbNpEPyJwzatWKGdmwZXP2jCFycfZ3o0ld9rKjv7cxDMXe/OXP2L32/2+ZxPY38MnlsOoWbHnm34anPNLWHa1XXfsDTYm/qALbDGdGR+y2118v5c6DuDwzya+NgCffsL7LCli2CuucHsn2YHei9yKkhzGFedwwoEj+iSOwYZYgE315gpk14NckuuFWITbbNUoN8QiKpC1UIiiKEOV1gY7aj7eo+Z6lBp3pl4gt9TagUh+3EIepVPsereEsDv4LRn5I2DOh/vfxkSIwLFfHJhzpTE33HADP//5z21Vu4LYrCAXXnhh3w944tf6tv2oWZ44PPfXsdkj4sNkZp61d/GypVNiQx9cyqbaHgmXix+wIQjTTk18nJj44kI47RZv/uCPdd1+7gXABXY6mOuc8wBYcClMPcnbbtJRic83/yI48EOxafPO+23sNm7vS28YgAI1w15x9dWDLCL863NHR727fcH1IPszWbS02cwXbhhFS3skmuotJ6gxyIqiDBPcKnrxf3z5o+x7405gTpfd+pXmWmhvsgPyXO9wszPqvnw6bP5vbAEFZdBpbPSKb40aNYrmZq9Owc0335xwn2eeeSY6vWnTptQYVr6PYTPJuOSB2OqByZh+qn2lkkAQFt/R++37Es+dBgzrPMiRTkN7xBAK9E3sluQF+ySqXVyB7M+F7MYaZwcyyBAbg+xmsnBF84iCbG45dw5nzxvb9aCKoih7iYicLiJrRGSdiNyUYP1VIrJKRFaIyPMiMivRcfoFtwpYPFEPcopTvXW0QZtTecz1EoOXlqrsAGujm8e1Jw+yoqSCYF7XvMZKShjWLsmwE94QyhqY54TCnAChrAzW7tzDmh17mDG6gOY268EWEUYXhrj/tUrW7mx0tvcG/11y2MRkh1UURekzIpIJ3AmcAlQCr4rIcmPMO77N/mKM+ZWz/WLgdiA1+cFaar0Ssn5iPMgpJFznTTdXe7GQzdV2YFThODtfu9HGjvYl/ZeiKPsdw9qD7AnkgckO4RfBp//0P7z5QS0NLe1RT/Fdn1hEWV6Q/6yt4qrjpnLstBTH2ymKMpw5FFhnjNlgjGkD7gViRnkZY/yVH/IAkzJrmqu9YhZ+svMhKy/1HmR/2dqY6Wo74t71GFevc0brD+u/T0UZ8gxvD3KHHQw3UB5kgGtPmsa6XY088Hol1977JpW1LVx8qE28PWdcEQ9fewwdnYZgHwYOKoqi7AXjgC2++UrgsPiNRORq4HogCJyYMmuaa2xaq0QUjII921J2aiC2bK1/oF7TbiuO3Zjj6g2JPd2KogwphrUKG2gPMsCHF1TwpdMP5CtnHMiWmhamjcznq2fOjK7PyBAVx4qipA3GmDuNMVOBLwMJh/WLyJUi8pqIvFZVVbV3J2quTh7XO3YBvP9ErGe3v/HHHfunm3fb/KyuKG6o1PhjRRkGDG8PsiOQs/s4SK8/OGf+OFraIxw3fUS0lLSiKMoAshUY75uvcJYl417gl4lWGGPuAu4CWLRoUd/DMNqabVGNZMLzmBvg7b/Cg9dBzUaYdyEccXX/pnqK8SDHhViUz4BcX9YKzWChKEOeYe2qDLcPfIiFS0aGcMlhE6koyR3wcyuKogCvAtNEZLKIBIELgeX+DUTEn6vqTOD9lFgSzS2cIAYZbG7ZWefY0s21m2x55mdv618bXFGcEYgLsXBio/2iWEMs0op//vOfiAjvvfceYFO35eTkMH/+fGbNmsUnPvEJ2tvbAZvi7ayz9iL/sDLsSKky7EUKoetF5B0ReUtEnhSRib51l4rI+84rJXUyWwchxEJRFCUdMMZ0ANcAjwLvAvcbY1aLyLecjBUA14jIahFZgY1DTk3NYleQJhPIAKffal83vAfTT7ela00/jhlsqbXiuHCcJ5bbW2xe5Lwym7VCnL9MDbFIK5YuXcrRRx/N0qVLo8umTp3KihUrWLVqFZWVldx///2DaKGyP5Kyvv1ephB6E1hkjGkWkc8C3wc+KiKlwDeARdhR0687+8bVAN03wh0qkBVFGb4YYx4GHo5b9nXf9HUDYkhzDx5kgMIxXunZaafC2n9D3QdQ0ssUmE3V8OLPYMaZMP6QrutbaqyXOK/cE+xuDuTccpu1IqfErtMQi648chPsWNW/xxx9EJxxa7ebNDY28vzzz/P0009z9tln881vfjNmfWZmJoceeihbt3YXPaQoXUmlB7k3KYSeNsa4ZW9ewsbAAZwGPG6MqXFE8eOkIPfmYIZYKIqiKA698SD7GXuwfd++oudtN/4Hll0NP1sAz/8Y/v3lxNu5eZhzSj173Pe8cvvuCmP1IKcNy5Yt4/TTT2f69OmUlZXx+uuvx6wPh8O8/PLLnH56atJ3K0OXVI4O61UKIR+fAh7pZt9x8TuIyJXAlQATJkzos4HRLBaDMEhPURRFceiNB9nPqNmQkQXb3oRZSxJv09oID10Pb91nS9xOOR4KK+ClO6HydahY2NWG3FJrw+41zjLXg+zY5cYeawxyV3rw9KaKpUuXct11tqPjwgsvZOnSpVxzzTWsX7+e+fPns3HjRs4880zmzp07KPYp+y9pkT5BRD6GDac4ri/77evIac+DrAJZURRl0GiuBgRCxb3bPpBtB+5te9PGIcdns6heDw9cBjvfhuO+DEdfD1khCDfAG3+AV3/TVSC31EHxeCuSXcHe5Hq21YOcjtTU1PDUU0+xatUqRIRIJIKIcPXVV0djkHfv3s1RRx3F8uXLWbx4cc8HVRSHVMYW9CqFkIicDHwVWGyMae3LvvvKQJeaVhRFURLQXG29vJl98NmMPRgqX4OfHAR/uwJqNtg42D8ugZ8vsvMX3Qcn/K8VxwChQpj7UVj9D5tazk9LjfUM55ZCWyN0tHoe5DzHg5yrHuR04q9//Ssf//jH2bx5M5s2bWLLli1MnjyZLVu8Dujy8nJuvfVWvve97w2ipcr+SCqVYW9SCB0M/Borjv11RB8FThWREhEpAU51lvUrOkhPURQlDUhWZro7xh7sCNkwrLof7jgYXrvbeoKPuAaufROmn9p1v5ln2X02/ifOhhrIKfbsaK62L8m0GSzAE8bqQU4Lli5dyrnnnhuz7Lzzzusihs855xyam5t57rnnBtI8ZT8nZSEWxpgOEXFTCGUCd7sphIDXjDHLgR8A+cADYrvIPjDGLDbG1IjIt7EiG+Bbxph+L6HkhlgEM9WDrCiKMmjsjUCec74dWLfgUljzCGx6znqLi3sYjzLxKAjmw/uP2rjkjAB0tkNHixW+I2fZ7R79Kux4C4oqbAYLsNOBHPUgpwlPP/10l2XXXnst1157bcwyEWHlypXR+eOPPz7VpilDgJTGIPcihdDJ3ex7N3B36qyzeZCDgQwyMvqxGpOiKIrSN1pq7AC6vpCdD0d/wU4ffIl99YZANkw9Ad79F6z5N5RO8fYtnggTDofjboJnb7VC+mJf/txFn4Tpp3khG4qiDFnSYpDeYBFujxAKqPdYURRlUGmugdHzBu58006Ddx+EYAFsfh42/xcqDoHZTnf98TfZ1G4Vi7yUcmCFcdnUgbNTUZRBY5gL5E6NP1YURRlMjHFCLAYwbGHWEpsB49Ar4PXfw5t/giW/gAzn/0DErlN6xBiDxGcR2c8x/VmhUdlvGd4CuSOiAllRFGUwaW+2g+b6GoO8L4QK4azb7fQZt8FJX4dg3sCdf4gQCoWorq6mrKxsyIhkYwzV1dWEQhpGM9wZ1gL52pOmsSfcMdhmKIqiDF8yg/Cpx6FgzODZoOJ4r6ioqKCyspKqqqrBNqVfCYVCVFT0MSZeGXIMa4E8dUT+YJugKIoyvMnMgvGHDrYVyl6QlZXF5MmTB9sMRUkJOkJNURRFURRFUXyoQFYURVEURVEUHyqQFUVRFEVRFMWHDJV0JiJSBWzei13Lgd39bM7ekC52QPrYonZ0JV1sUTu60ldbJhpjRqTKmMFC2+J+I13sgPSxRe3oSrrYsj/bkbAtHjICeW8RkdeMMYvUDo90sUXt6Eq62KJ2dCWdbNkfSZfrp3Z0JV1sUTu6ki62DEU7NMRCURRFURRFUXyoQFYURVEURVEUHyqQ4a7BNsAhXeyA9LFF7ehKutiidnQlnWzZH0mX66d2dCVdbFE7upIutgw5O4Z9DLKiKIqiKIqi+FEPsqIoiqIoiqL4UIGsKIqiKIqiKD6GtUAWkdNFZI2IrBORmwbwvONF5GkReUdEVovIdc7ym0Vkq4iscF4fGgBbNonIKud8rznLSkXkcRF533kvGQA7Zvg+9woRaRCRzw/ENRGRu0Vkl4i87VuW8BqI5Q7nnnlLRBak2I4fiMh7zrn+ISLFzvJJItLiuy6/6i87urEl6XchIl9xrskaETktxXbc57Nhk4iscJan7Jp085sd8PtkqKHtcNSeQW+LB7Mdds6vbXHPdgx4O9yNLUO7LTbGDMsXkAmsB6YAQWAlMGuAzj0GWOBMFwBrgVnAzcAXB/g6bALK45Z9H7jJmb4JuG0QvpsdwMSBuCbAscAC4O2ergHwIeARQIDDgZdTbMepQMCZvs1nxyT/dgN0TRJ+F869uxLIBiY7v6vMVNkRt/5HwNdTfU26+c0O+H0ylF7aDsfYk1Zt8UC3w845tS3u2Y4Bb4eT2RK3fsi1xcPZg3wosM4Ys8EY0wbcCywZiBMbY7YbY95wpvcA7wLjBuLcvWQJ8Adn+g/AOQN8/pOA9caYvanG1WeMMf8BauIWJ7sGS4A/GstLQLGIjEmVHcaYx4wxHc7sS0BFf5xrb2zphiXAvcaYVmPMRmAd9veVUjtERICPAEv741w92JHsNzvg98kQQ9vh7hnMtnhA22HQtrg3dnRDytrhnmwZqm3xcBbI44AtvvlKBqFxFJFJwMHAy86ia5xugLtT3Z3mYIDHROR1EbnSWTbKGLPdmd4BjBoAO/xcSOwPbaCvCSS/BoN533wS+yTsMllE3hSRZ0XkmAGyIdF3MVjX5BhgpzHmfd+ylF+TuN9sOt4n+xNpcZ3SoB2G9GuL06EdhvT8jQ12W5xO7TAM0bZ4OAvkQUdE8oG/AZ83xjQAvwSmAvOB7dgui1RztDFmAXAGcLWIHOtfaWwfxYDlAhSRILAYeMBZNBjXJIaBvgaJEJGvAh3An51F24EJxpiDgeuBv4hIYYrNGPTvIo6LiP0DT/k1SfCbjZIO94nSd9KkHYY0aovTsR2G9PiNpUFbnBbfRRxDsi0ezgJ5KzDeN1/hLBsQRCQL++X+2RjzdwBjzE5jTMQY0wn8hn7sHkmGMWar874L+Idzzp1uF4TzvivVdvg4A3jDGLPTsWvAr4lDsmsw4PeNiFwGnAVc4vzwcbrRqp3p17HxZtNTaUc338VgXJMA8GHgPp99Kb0miX6zpNF9sp+i7bBDmrXF6dIOQxr9xtKhLU6ndhiGdls8nAXyq8A0EZnsPC1fCCwfiBM78Tq/A941xtzuW+6PizkXeDt+3362I09ECtxp7CCEt7HX4VJns0uBZam0I46YJ9GBviY+kl2D5cAnnJGxhwP1vm6dfkdETge+BCw2xjT7lo8QkUxnegowDdiQKjuc8yT7LpYDF4pItohMdmx5JZW2ACcD7xljKn32peyaJPvNkib3yX7MsG+HnXOmW1ucLu0wpMlvLF3a4jRrh2Eot8UmBaMM95cXdnTjWuzTzVcH8LxHY93/bwErnNeHgP8HrHKWLwfGpNiOKdhRryuB1e41AMqAJ4H3gSeA0gG6LnlANVDkW5bya4L9I9gOtGPjkz6V7BpgR8Le6dwzq4BFKbZjHTZ+yr1PfuVse57zna0A3gDOHoBrkvS7AL7qXJM1wBmptMNZ/nvgqrhtU3ZNuvnNDvh9MtReDPN22LElbdpiBqkdds6jbXHPdgx4O5zMFmf57xmibbGWmlYURVEURVEUH8M5xEJRFEVRFEVRuqACWVEURVEURVF8qEBWFEVRFEVRFB8qkBVFURRFURTFhwpkRVEURVEURfGhAlkZNohIRERW+F439eOxJ4nIQOYGVRRF2e/QdljZXwgMtgGKMoC0GGPmD7YRiqIowxhth5X9AvUgK8MeEdkkIt8XkVUi8oqIHOAsnyQiT4nIWyLypIhMcJaPEpF/iMhK53Wkc6hMEfmNiKwWkcdEJGfQPpSiKMp+hLbDSrqhAlkZTuTEde191Leu3hhzEPBz4CfOsp8BfzDGzAX+DNzhLL8DeNYYMw9YgK0YBLac5p3GmNlAHbaakKIoiuKh7bCyX6CV9JRhg4g0GmPyEyzfBJxojNkgIlnADmNMmYjsxpbxbHeWbzfGlItIFVBhjGn1HWMS8LgxZpoz/2UgyxjznQH4aIqiKPsF2g4r+wvqQVYUi0ky3RdafdMRNMZfURSlL2g7rKQNKpAVxfJR3/uLzvQLwIXO9CXAc870k8BnAUQkU0SKBspIRVGUIYy2w0raoE9WynAiR0RW+Ob/bYxxUwyViMhbWO/DRc6yzwH3iMiNQBVwubP8OuAuEfkU1kPxWWB7qo1XFEUZAmg7rOwXaAyyMuxxYt8WGWN2D7YtiqIowxFth5V0Q0MsFEVRFEVRFMWHepAVRVEURVEUxYd6kBVFURRFURTFhwpkRVEURVEURfGhAllRFEVRFEVRfKhAVhRFURRFURQfKpAVRVEURVEUxcf/B4CsmTl6SklDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Controls:\n",
    "# File = [Pre-training file, gene_expresion data file, labels file]\n",
    "File = ['../02-Data/Controls/controls_pre_train.pkl', '../02-Data/Controls/controls_X.txt', '../02-Data/Controls/controls_y.txt']\n",
    "# Para = [batch_size, lr, epoch]\n",
    "Para = [1024, 1e-3, 200]\n",
    "# model_para = [n_enc_1(n_dec_3), n_enc_2(n_dec_2), n_enc_3(n_dec_1)]\n",
    "model_para = [500, 500, 2000]\n",
    "# Cluster_para = [n_cluster, n_init, n_input, n_z]\n",
    "Cluster_para = [5, 20, 2000, 10]\n",
    "\n",
    "model = AE(\n",
    "            n_enc_1=model_para[0], n_enc_2=model_para[1], n_enc_3=model_para[2],\n",
    "            n_dec_1=model_para[2], n_dec_2=model_para[1], n_dec_3=model_para[0], n_input=Cluster_para[2], n_z=Cluster_para[3], )\n",
    "\n",
    "\n",
    "x = np.loadtxt(File[1], dtype=float)\n",
    "y = np.loadtxt(File[2], dtype=int)\n",
    "\n",
    "dataset = LoadDataset(x)\n",
    "pretrain_ae(model, dataset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fb521d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('enc_1.weight',\n",
       "              tensor([[ 0.0119, -0.0103, -0.0060,  ..., -0.0051,  0.0006, -0.0067],\n",
       "                      [-0.0240,  0.0168,  0.0233,  ...,  0.0130, -0.0137, -0.0334],\n",
       "                      [ 0.0049, -0.0339, -0.0170,  ...,  0.0191,  0.0144,  0.0193],\n",
       "                      ...,\n",
       "                      [-0.0133, -0.0012,  0.0305,  ...,  0.0031,  0.0313,  0.0111],\n",
       "                      [ 0.0107, -0.0340, -0.0047,  ...,  0.0191,  0.0241,  0.0272],\n",
       "                      [ 0.0264,  0.0169, -0.0133,  ..., -0.0122, -0.0107, -0.0365]])),\n",
       "             ('enc_1.bias',\n",
       "              tensor([ 1.9371e-02, -7.4625e-03, -8.1335e-03,  7.4744e-04,  1.8030e-02,\n",
       "                       8.2633e-04,  2.1022e-02, -6.5681e-04,  2.1209e-02, -1.7023e-02,\n",
       "                      -1.3881e-02, -9.2084e-03,  1.7176e-02, -8.5008e-03, -1.4536e-02,\n",
       "                      -1.4098e-02, -1.0662e-03, -1.4935e-02, -8.1932e-03,  7.1314e-03,\n",
       "                       4.1561e-03,  1.1137e-02, -1.3311e-02,  1.8341e-02,  1.9488e-02,\n",
       "                      -7.2077e-03,  1.9110e-02,  1.4317e-04,  1.6945e-02, -2.2244e-02,\n",
       "                      -3.3497e-03, -1.2623e-02, -1.3477e-02,  4.7253e-03, -1.7082e-02,\n",
       "                       1.4301e-02, -6.4391e-03, -2.1024e-03,  1.1629e-02,  1.6858e-02,\n",
       "                      -1.3591e-02,  1.1761e-02,  1.2851e-02,  1.4585e-02, -1.8465e-02,\n",
       "                       1.9508e-02, -1.2595e-02, -1.7743e-02,  1.5710e-02,  1.1269e-02,\n",
       "                       8.0853e-03,  1.7246e-02, -1.4331e-02,  6.0813e-03, -2.0283e-02,\n",
       "                       1.4093e-02,  8.3811e-03,  1.9609e-02, -1.7017e-02,  1.0659e-02,\n",
       "                       8.5572e-03,  2.0413e-02, -5.6819e-03, -8.2286e-03, -1.7963e-02,\n",
       "                       1.6139e-02, -1.0391e-02, -6.7519e-03, -2.8660e-03, -1.4597e-02,\n",
       "                      -1.7692e-02,  1.6046e-02, -1.7073e-02,  1.1614e-02, -1.5659e-02,\n",
       "                      -1.0688e-02, -2.5326e-03, -4.9727e-04,  8.1721e-03, -2.8561e-03,\n",
       "                      -9.0289e-03, -1.7755e-02, -1.5583e-03,  5.3404e-04, -9.4552e-03,\n",
       "                       1.0068e-02,  1.2073e-03, -8.2352e-05, -1.1608e-02, -1.0857e-02,\n",
       "                       9.6409e-03, -5.7189e-03,  1.0571e-02,  1.2750e-02, -8.9523e-03,\n",
       "                      -2.0794e-03,  1.7148e-02, -2.8568e-03, -8.5811e-03, -1.9506e-02,\n",
       "                       3.1877e-03,  8.2510e-03, -7.2408e-03, -1.7660e-02, -2.0134e-02,\n",
       "                      -6.1101e-03, -2.0433e-02,  8.9030e-03, -9.0706e-03,  1.8341e-02,\n",
       "                       1.5743e-02, -1.7766e-03,  2.1558e-02,  2.1054e-03,  4.7978e-04,\n",
       "                       9.1637e-03, -1.4080e-02, -3.1754e-03,  2.1337e-02,  1.6935e-02,\n",
       "                       2.4259e-03, -2.0833e-02,  2.0532e-02,  1.1088e-02,  9.0503e-03,\n",
       "                      -2.2103e-02,  2.2115e-02,  1.8246e-02, -1.1994e-02, -1.4783e-02,\n",
       "                      -1.0351e-02, -9.0762e-04,  9.1330e-03, -1.1863e-02, -7.8561e-03,\n",
       "                      -2.1681e-02, -2.0366e-02, -1.6071e-02,  9.9891e-03,  4.8823e-03,\n",
       "                       2.1439e-02, -6.8831e-03,  1.4552e-02,  8.3509e-03,  3.1095e-03,\n",
       "                      -2.4446e-03, -6.3446e-03, -1.9066e-02,  1.8559e-02, -1.6544e-02,\n",
       "                       2.0244e-02,  1.1337e-02, -1.8035e-02,  1.1405e-02, -1.3516e-02,\n",
       "                       1.4740e-02,  1.4266e-03,  1.3783e-03, -1.7558e-02,  1.1620e-02,\n",
       "                      -4.2082e-03,  1.5924e-02, -1.6022e-03,  2.0244e-02, -1.9384e-02,\n",
       "                       1.4107e-02,  1.2665e-02,  3.5630e-04, -4.8773e-04, -8.3081e-03,\n",
       "                       1.4104e-02, -2.1917e-02, -2.1983e-02,  1.9275e-02, -1.6034e-02,\n",
       "                       1.2608e-02, -2.1243e-02,  1.7310e-02, -2.1723e-02,  1.7963e-02,\n",
       "                      -6.2360e-03,  1.8718e-03,  5.2414e-03,  2.2045e-02,  5.7372e-03,\n",
       "                      -3.4472e-03, -2.0773e-03,  1.3716e-02, -1.5145e-02, -1.6266e-02,\n",
       "                      -2.0509e-02, -1.2475e-02,  1.2717e-02, -2.0773e-02, -2.0489e-02,\n",
       "                       5.8431e-03, -2.1092e-02,  6.2025e-03,  9.6989e-03,  6.1434e-03,\n",
       "                      -1.3679e-02, -1.2823e-02,  4.7199e-03,  2.2340e-02, -1.8989e-02,\n",
       "                      -9.4900e-03,  1.2510e-02, -9.6518e-03, -1.1977e-02, -7.9804e-03,\n",
       "                      -1.3767e-02,  1.1877e-02,  9.5928e-04, -1.5514e-02,  3.9359e-03,\n",
       "                      -8.9792e-03, -2.7879e-03, -8.6225e-03, -1.7643e-02,  8.4035e-03,\n",
       "                      -1.1070e-02,  2.0082e-02, -2.0623e-02,  1.1207e-02,  1.1190e-02,\n",
       "                       7.3142e-03, -1.9428e-02, -5.6720e-03,  9.7529e-03,  1.7920e-02,\n",
       "                      -2.7233e-03,  2.1116e-03,  1.3396e-02,  7.1702e-03, -1.1484e-02,\n",
       "                       1.2564e-02,  1.3871e-03,  1.0744e-02,  3.3517e-03,  1.7609e-02,\n",
       "                      -1.5879e-03, -1.8544e-02, -1.2724e-02,  1.5703e-02,  5.7630e-03,\n",
       "                      -2.1017e-02, -7.2584e-03,  1.6389e-02,  6.0408e-03, -1.4336e-02,\n",
       "                       9.5489e-03,  1.3182e-02,  2.0154e-02, -1.6411e-02, -1.5527e-02,\n",
       "                       8.1058e-03,  1.5266e-02,  9.6416e-04, -2.0406e-02,  6.3578e-03,\n",
       "                      -1.6485e-02, -1.7526e-02,  1.4416e-02,  1.4813e-02,  1.8876e-02,\n",
       "                       5.3756e-03, -1.4692e-02, -2.2301e-02,  5.8040e-03,  2.0748e-02,\n",
       "                      -2.1963e-02, -1.2388e-02,  4.5462e-04, -1.4939e-02,  1.1956e-02,\n",
       "                       6.3307e-03,  5.5759e-03, -8.1510e-03, -8.9541e-04, -2.2288e-02,\n",
       "                       7.2564e-03,  1.7293e-02,  1.3408e-02, -9.0527e-03,  7.1379e-04,\n",
       "                      -1.2061e-02, -5.4457e-03,  1.1837e-02,  4.7125e-03, -8.4947e-03,\n",
       "                       2.1979e-02, -7.1278e-03,  5.6223e-04, -1.2061e-02,  8.6264e-03,\n",
       "                       8.9994e-03, -8.7495e-03,  1.5910e-03, -8.6625e-03,  8.0672e-03,\n",
       "                      -9.2313e-03,  1.7937e-02,  4.2906e-03, -3.2055e-03, -8.5208e-03,\n",
       "                       2.7064e-03,  3.8081e-04,  1.0626e-02,  4.4967e-03, -3.0770e-03,\n",
       "                       1.0035e-02, -1.7954e-02,  1.4435e-02,  3.3893e-03,  3.1565e-03,\n",
       "                       1.4166e-02,  9.3231e-03, -1.1304e-02,  3.4621e-03,  1.5186e-02,\n",
       "                       2.1236e-02,  1.4182e-02,  2.1800e-02,  1.0725e-03,  1.9003e-02,\n",
       "                       1.1119e-03,  1.5216e-02, -1.8539e-02,  1.7525e-02,  1.5745e-02,\n",
       "                       3.1436e-03, -1.2590e-02,  8.5380e-03, -8.2514e-03,  1.8147e-02,\n",
       "                      -4.8129e-03,  1.6948e-02,  1.0952e-02, -7.1005e-03, -3.6465e-03,\n",
       "                      -8.1853e-03,  1.0174e-02,  9.4443e-03, -9.0289e-03,  3.8880e-03,\n",
       "                       3.8656e-04, -2.9065e-03,  1.3056e-02, -1.5447e-02,  1.3093e-03,\n",
       "                      -8.8574e-03,  1.5813e-02,  6.2342e-03,  1.2003e-02,  2.1819e-02,\n",
       "                      -1.8044e-02,  2.1056e-03,  1.7630e-02, -1.6011e-02,  1.3806e-02,\n",
       "                      -5.7798e-03, -1.6404e-02,  8.2117e-03,  7.0270e-04, -4.5782e-03,\n",
       "                       6.4375e-03, -7.3102e-03,  1.4726e-03,  4.7555e-03, -4.2048e-04,\n",
       "                       1.2668e-02,  3.5564e-03, -1.6808e-02,  8.3390e-03, -1.7178e-02,\n",
       "                      -2.2000e-02,  5.8708e-03,  6.8905e-04, -1.8576e-02,  1.6746e-02,\n",
       "                       1.1762e-02,  9.3504e-03,  1.9157e-02,  1.8794e-02,  5.0244e-03,\n",
       "                       8.3008e-03, -2.2023e-02, -1.8644e-02,  5.5156e-03, -1.3874e-02,\n",
       "                      -4.1954e-03,  1.0680e-02,  1.6158e-02, -1.5211e-02, -3.8005e-03,\n",
       "                      -2.2216e-02, -9.8373e-03, -2.0938e-02, -5.9845e-03, -8.0555e-03,\n",
       "                       5.0155e-03, -1.3747e-02, -5.8569e-03,  2.1356e-02, -8.0753e-03,\n",
       "                      -2.2135e-02, -2.1853e-02, -2.1298e-03,  2.2026e-02,  1.5072e-02,\n",
       "                      -1.5443e-02, -8.7615e-03,  7.4616e-03, -1.2681e-02, -2.2043e-02,\n",
       "                      -7.5321e-03, -4.9496e-03,  1.5697e-02, -1.3657e-02, -2.7826e-03,\n",
       "                      -1.0592e-02,  1.3529e-03,  6.5091e-03, -1.3994e-02,  9.1156e-03,\n",
       "                      -3.5891e-03, -6.5269e-03, -1.4675e-02,  1.0784e-02, -1.7456e-02,\n",
       "                       2.0061e-02, -1.0898e-02, -1.3384e-02,  1.8363e-02,  1.8792e-02,\n",
       "                       2.1363e-02, -5.9911e-03, -1.2377e-02, -7.9170e-03,  6.0265e-03,\n",
       "                      -5.7992e-03, -9.3562e-03, -4.4550e-03, -1.8749e-02, -2.1558e-02,\n",
       "                       2.0919e-02, -1.6007e-02,  1.6281e-02,  1.3609e-02, -8.9270e-03,\n",
       "                      -1.5673e-02, -9.3766e-03, -1.4376e-02, -1.5595e-02,  1.2143e-02,\n",
       "                      -1.3875e-02, -9.9642e-03, -6.7407e-03, -1.2076e-03,  1.1487e-02,\n",
       "                       5.8051e-03,  1.7391e-04,  2.1386e-02, -2.0358e-02, -1.7332e-02,\n",
       "                      -1.3812e-02, -1.0519e-02, -8.3981e-03,  8.6098e-04,  1.2383e-02,\n",
       "                      -4.7904e-03, -1.7967e-02, -2.0898e-02,  1.5476e-02,  1.0801e-02,\n",
       "                       1.5653e-02,  4.4916e-03,  1.1570e-02, -2.1917e-02,  1.7649e-02,\n",
       "                      -7.8876e-03,  1.8403e-02,  1.3069e-02,  1.5719e-02, -1.9565e-03,\n",
       "                      -2.0652e-02,  4.5654e-03, -1.5604e-02,  1.5607e-02, -5.9237e-03,\n",
       "                       2.2416e-04,  1.7554e-02,  2.1177e-02,  1.6578e-02,  4.7266e-03,\n",
       "                      -1.3884e-02, -8.2985e-03,  1.1705e-02, -1.1994e-02, -1.6381e-02])),\n",
       "             ('BN1.weight',\n",
       "              tensor([0.9992, 0.9859, 0.9834, 0.9890, 0.9989, 1.0039, 0.9932, 0.9961, 1.0113,\n",
       "                      0.9972, 1.0000, 0.9943, 1.0288, 1.0003, 1.0074, 0.9899, 0.9717, 1.0002,\n",
       "                      0.9988, 1.0294, 0.9973, 0.9726, 1.0127, 0.9931, 0.9948, 1.0023, 1.0013,\n",
       "                      0.9824, 0.9837, 1.0016, 0.9868, 0.9699, 1.0008, 0.9701, 1.0032, 1.0142,\n",
       "                      1.0019, 1.0138, 0.9994, 0.9918, 1.0219, 0.9905, 0.9863, 0.9883, 0.9889,\n",
       "                      0.9869, 0.9964, 1.0118, 1.0013, 0.9889, 1.0135, 0.9878, 0.9963, 1.0012,\n",
       "                      0.9989, 1.0119, 0.9868, 0.9756, 1.0156, 0.9940, 1.0033, 1.0029, 0.9969,\n",
       "                      1.0042, 0.9997, 0.9969, 1.0074, 0.9896, 0.9843, 0.9787, 1.0517, 1.0044,\n",
       "                      1.0185, 1.0159, 1.0059, 1.0249, 1.0002, 1.0023, 0.9999, 1.0031, 0.9929,\n",
       "                      0.9869, 1.0030, 1.0007, 1.0133, 1.0029, 1.0219, 1.0037, 1.0021, 0.9841,\n",
       "                      0.9846, 0.9892, 0.9965, 1.0064, 0.9944, 1.0068, 1.0049, 0.9824, 0.9968,\n",
       "                      0.9863, 0.9975, 1.0065, 1.0075, 1.0023, 1.0030, 0.9937, 1.0014, 1.0032,\n",
       "                      0.9909, 0.9837, 0.9940, 0.9772, 1.0042, 1.0013, 1.0018, 0.9892, 0.9968,\n",
       "                      1.0016, 1.0039, 0.9992, 0.9973, 0.9964, 0.9932, 1.0197, 0.9879, 1.0219,\n",
       "                      1.0038, 0.9927, 0.9867, 0.9963, 1.0080, 0.9939, 1.0258, 0.9939, 1.0038,\n",
       "                      0.9843, 1.0004, 1.0021, 1.0000, 0.9868, 0.9817, 0.9937, 1.0290, 0.9977,\n",
       "                      1.0072, 0.9935, 1.0325, 1.0280, 1.0127, 1.0014, 0.9840, 1.0030, 1.0029,\n",
       "                      1.0003, 0.9861, 0.9980, 0.9948, 0.9989, 0.9862, 1.0046, 0.9834, 1.0033,\n",
       "                      0.9951, 0.9951, 0.9823, 1.0102, 1.0260, 1.0016, 1.0033, 0.9872, 0.9874,\n",
       "                      0.9883, 0.9884, 1.0067, 0.9727, 1.0285, 1.0050, 0.9948, 0.9893, 0.9997,\n",
       "                      0.9881, 1.0096, 0.9912, 1.0032, 1.0137, 0.9992, 0.9992, 0.9886, 0.9910,\n",
       "                      1.0010, 1.0181, 1.0175, 0.9968, 1.0066, 1.0011, 0.9814, 1.0199, 1.0088,\n",
       "                      0.9961, 1.0003, 1.0137, 0.9830, 0.9958, 0.9907, 1.0302, 1.0068, 1.0206,\n",
       "                      0.9826, 1.0055, 1.0030, 1.0096, 1.0004, 1.0063, 1.0024, 0.9940, 1.0035,\n",
       "                      1.0056, 0.9846, 1.0125, 0.9827, 0.9833, 0.9974, 0.9962, 0.9888, 0.9927,\n",
       "                      1.0138, 1.0256, 1.0115, 1.0063, 0.9991, 1.0126, 1.0079, 1.0015, 0.9925,\n",
       "                      0.9923, 0.9996, 0.9868, 0.9962, 0.9982, 0.9963, 1.0016, 0.9934, 1.0022,\n",
       "                      0.9951, 1.0059, 1.0030, 1.0011, 1.0008, 0.9976, 1.0054, 1.0231, 1.0254,\n",
       "                      1.0104, 1.0000, 0.9958, 0.9937, 1.0072, 0.9837, 0.9987, 1.0017, 0.9921,\n",
       "                      0.9794, 0.9885, 1.0205, 1.0199, 0.9939, 0.9847, 0.9960, 1.0034, 1.0016,\n",
       "                      0.9972, 0.9946, 0.9948, 1.0032, 1.0084, 1.0314, 1.0337, 0.9908, 1.0054,\n",
       "                      0.9907, 0.9928, 0.9882, 1.0169, 0.9953, 0.9948, 0.9864, 0.9980, 1.0035,\n",
       "                      0.9934, 0.9729, 0.9991, 1.0088, 1.0126, 0.9979, 0.9741, 1.0194, 0.9960,\n",
       "                      1.0068, 0.9888, 0.9930, 1.0111, 0.9918, 1.0300, 1.0121, 0.9968, 0.9967,\n",
       "                      1.0196, 0.9911, 1.0028, 1.0013, 1.0144, 0.9929, 0.9873, 1.0078, 1.0206,\n",
       "                      0.9821, 0.9938, 1.0120, 0.9993, 1.0216, 1.0135, 0.9938, 0.9996, 0.9968,\n",
       "                      1.0037, 1.0374, 1.0140, 1.0150, 1.0043, 1.0175, 0.9948, 0.9881, 1.0326,\n",
       "                      1.0344, 0.9952, 0.9939, 0.9820, 0.9939, 1.0090, 1.0078, 1.0114, 0.9940,\n",
       "                      0.9746, 1.0038, 1.0000, 0.9795, 0.9886, 0.9948, 1.0130, 0.9950, 0.9772,\n",
       "                      1.0126, 0.9937, 0.9991, 0.9953, 0.9978, 1.0026, 1.0067, 0.9818, 1.0105,\n",
       "                      0.9874, 1.0073, 1.0134, 0.9763, 1.0027, 0.9766, 0.9976, 0.9966, 0.9875,\n",
       "                      0.9988, 1.0026, 1.0186, 0.9997, 0.9989, 1.0361, 0.9951, 0.9923, 1.0160,\n",
       "                      0.9969, 1.0090, 0.9989, 1.0301, 1.0181, 0.9997, 1.0139, 0.9915, 0.9818,\n",
       "                      1.0037, 1.0544, 1.0069, 0.9869, 0.9855, 1.0027, 0.9814, 0.9896, 0.9957,\n",
       "                      0.9763, 1.0115, 1.0017, 1.0083, 1.0203, 1.0001, 1.0202, 1.0147, 1.0108,\n",
       "                      1.0021, 1.0104, 0.9911, 1.0448, 1.0067, 1.0238, 0.9971, 1.0061, 0.9942,\n",
       "                      0.9963, 1.0240, 1.0061, 1.0034, 1.0053, 0.9975, 1.0129, 0.9813, 0.9981,\n",
       "                      0.9792, 1.0123, 1.0106, 0.9898, 0.9895, 0.9954, 1.0004, 0.9832, 0.9882,\n",
       "                      0.9864, 1.0065, 0.9941, 0.9956, 1.0042, 1.0054, 0.9965, 0.9969, 1.0101,\n",
       "                      0.9905, 1.0004, 0.9970, 1.0046, 0.9986, 0.9946, 1.0217, 0.9943, 0.9739,\n",
       "                      0.9977, 0.9894, 0.9993, 1.0071, 0.9959, 0.9940, 0.9983, 1.0151, 0.9781,\n",
       "                      0.9842, 1.0255, 1.0125, 1.0008, 0.9833, 1.0034, 1.0118, 0.9846, 0.9935,\n",
       "                      1.0105, 1.0072, 0.9874, 0.9906, 1.0196, 1.0023, 1.0005, 0.9896, 1.0046,\n",
       "                      0.9968, 1.0019, 1.0449, 1.0081, 0.9964, 0.9836, 1.0007, 1.0185, 0.9876,\n",
       "                      0.9836, 1.0154, 0.9909, 1.0118, 1.0327, 1.0184, 1.0286, 0.9947, 1.0055,\n",
       "                      1.0282, 0.9883, 1.0006, 0.9925, 0.9882])),\n",
       "             ('BN1.bias',\n",
       "              tensor([ 1.7580e-03, -1.7954e-02, -1.3226e-02,  2.3437e-03, -6.2532e-03,\n",
       "                       2.4142e-02,  2.5794e-02, -4.8888e-03,  2.1762e-02,  1.0079e-04,\n",
       "                       4.9929e-03,  1.6413e-02,  7.5557e-03,  1.7015e-02,  1.9383e-02,\n",
       "                      -5.3040e-03, -1.5023e-03,  1.6656e-02,  5.5742e-03,  8.7937e-03,\n",
       "                       3.1737e-03, -1.4586e-02,  1.0438e-02, -5.1480e-03,  1.0365e-02,\n",
       "                       9.3012e-03, -1.3749e-02, -8.4929e-03,  3.5207e-03,  5.4144e-03,\n",
       "                       5.6144e-03,  1.1720e-02, -2.9241e-03, -6.1763e-03,  3.0120e-03,\n",
       "                       1.2373e-02,  2.7325e-03,  2.0321e-02, -9.4170e-03, -5.3308e-04,\n",
       "                       1.2953e-02, -1.4397e-02, -9.0233e-03,  5.8523e-03, -7.0004e-03,\n",
       "                       1.6859e-03, -1.4068e-02,  2.5908e-02,  5.5594e-03,  1.2319e-03,\n",
       "                      -2.0483e-03, -6.4007e-03,  1.4942e-05,  1.3160e-02,  2.6694e-03,\n",
       "                       2.6806e-02, -1.5759e-02, -6.4267e-03,  1.2225e-02, -1.7562e-02,\n",
       "                      -9.1380e-03, -6.2052e-03,  8.8177e-03,  1.2720e-02, -4.7774e-03,\n",
       "                       6.7077e-03, -5.9012e-03,  6.5348e-03,  3.9427e-03, -9.8733e-03,\n",
       "                       4.0568e-02,  5.1417e-03,  5.5863e-04,  1.5341e-02,  2.8585e-02,\n",
       "                       3.5024e-02,  5.5264e-03,  3.7846e-02,  8.3377e-03,  1.2283e-02,\n",
       "                       5.2170e-03,  2.7306e-03,  3.3853e-03, -9.4381e-03,  2.0339e-02,\n",
       "                      -4.6817e-03,  1.0763e-03,  1.7919e-02, -1.8817e-03, -2.3348e-03,\n",
       "                      -1.5929e-02,  4.1897e-03, -2.2074e-02,  3.3821e-02,  9.1214e-03,\n",
       "                       3.4880e-03,  1.1835e-02, -6.4286e-03,  5.7788e-03, -2.2411e-02,\n",
       "                       5.0358e-03, -6.8011e-03,  1.1036e-02, -1.6668e-02,  2.3784e-02,\n",
       "                       1.3974e-02,  1.3615e-02, -3.5939e-03, -9.4632e-06, -1.1228e-02,\n",
       "                       8.0791e-03, -1.5588e-02,  1.4775e-04,  8.9942e-03,  3.7315e-03,\n",
       "                       8.5151e-03,  9.4682e-03,  1.2166e-02,  2.1450e-02,  1.7058e-02,\n",
       "                      -7.8445e-03, -1.1251e-02, -2.1059e-03,  6.8921e-03, -4.8461e-03,\n",
       "                       1.8918e-02,  1.7010e-02,  5.0146e-03, -2.3825e-03,  2.2119e-02,\n",
       "                       1.2104e-02,  7.4640e-03,  1.5796e-02, -1.0185e-02,  1.8246e-02,\n",
       "                      -6.4409e-03,  5.2933e-03,  9.7723e-03,  1.3230e-02,  1.3824e-02,\n",
       "                      -9.7293e-03,  3.4212e-03,  1.1896e-02,  3.4724e-03,  2.9988e-02,\n",
       "                       2.3647e-03,  3.7512e-02,  2.9485e-02,  7.1912e-04,  4.7224e-03,\n",
       "                      -1.1508e-02,  1.3234e-02,  7.1925e-03,  8.4820e-03,  7.3577e-03,\n",
       "                      -3.2625e-03, -1.1188e-02, -4.0088e-04, -6.4195e-03,  1.4626e-02,\n",
       "                      -1.1707e-02,  2.0979e-02, -2.9357e-03, -1.4591e-03, -4.7147e-03,\n",
       "                       1.8213e-03,  4.0406e-03,  8.3137e-03, -2.2299e-02, -1.7910e-02,\n",
       "                      -6.2758e-03,  9.2562e-03,  4.6663e-03,  1.0787e-02, -1.4114e-02,\n",
       "                       3.4029e-02,  2.2595e-03, -3.4212e-03, -6.9611e-03, -1.2659e-02,\n",
       "                       1.5719e-02,  7.7280e-03, -9.1091e-03,  1.5371e-03,  3.3156e-02,\n",
       "                      -2.2150e-03,  1.3172e-02, -3.8013e-03, -2.1249e-04,  1.4877e-02,\n",
       "                       2.3097e-02,  1.2845e-02,  2.2701e-03,  3.0711e-03, -2.3532e-03,\n",
       "                      -8.7540e-04,  6.3220e-03,  2.5135e-02, -8.9117e-03, -1.4332e-03,\n",
       "                       2.9157e-02, -1.4330e-03,  9.5076e-03,  1.0001e-02,  1.0569e-02,\n",
       "                       1.0530e-02,  1.7080e-02, -1.0418e-02, -6.4667e-03,  2.3006e-02,\n",
       "                       3.5599e-02,  4.8018e-03,  3.0108e-03,  1.4454e-02,  1.0625e-02,\n",
       "                       2.5815e-02,  1.8227e-02,  1.0776e-02,  2.2486e-02, -2.0828e-02,\n",
       "                       6.3847e-03,  7.2326e-03, -2.2602e-04, -3.7621e-03, -1.1677e-02,\n",
       "                       1.9655e-02,  1.5515e-02,  1.0136e-02, -1.0259e-02,  8.1906e-03,\n",
       "                       1.3237e-02,  1.7624e-02,  2.0560e-02,  5.0994e-03, -3.4359e-03,\n",
       "                      -1.2972e-03,  9.5158e-03, -6.2246e-04,  7.6567e-05,  1.2807e-02,\n",
       "                       5.6926e-03,  1.9006e-03,  8.6841e-03,  7.3102e-03,  1.5836e-02,\n",
       "                       2.2661e-02,  6.8838e-03,  9.9133e-03, -2.2789e-04,  4.0393e-03,\n",
       "                       2.5282e-02,  1.0345e-02,  2.3903e-02,  1.1167e-02,  9.5509e-03,\n",
       "                       1.2123e-02,  3.3946e-05, -4.3713e-03,  2.1572e-02,  1.5881e-02,\n",
       "                      -7.5290e-03, -1.2344e-02,  5.2224e-03,  1.1729e-02,  1.3519e-02,\n",
       "                      -1.0049e-02, -1.8044e-02,  2.0014e-02, -1.0735e-03, -1.9722e-03,\n",
       "                       1.8232e-02,  1.8780e-02, -1.0201e-02,  1.1867e-02,  3.6141e-02,\n",
       "                       5.7772e-04, -1.6748e-02,  4.7222e-03, -3.3139e-03,  4.9580e-03,\n",
       "                       1.9842e-03,  2.2583e-02,  1.4404e-02,  9.5415e-03, -2.3915e-03,\n",
       "                      -4.5225e-03,  1.6063e-03, -1.1109e-02, -2.3300e-03, -2.2078e-02,\n",
       "                       1.4199e-02, -5.5653e-03,  1.2853e-02,  5.6623e-03, -1.1559e-02,\n",
       "                       3.7886e-02, -1.0532e-02,  8.4667e-03, -1.5146e-02, -3.6366e-03,\n",
       "                       2.8519e-02, -1.0182e-03,  3.6739e-02,  9.8817e-03,  6.0466e-03,\n",
       "                      -9.6975e-03,  1.9751e-02, -1.8848e-02, -6.9404e-03,  6.2258e-03,\n",
       "                       2.1997e-02, -6.7857e-03, -3.7669e-03,  1.2382e-02,  9.5004e-03,\n",
       "                      -1.9088e-02,  4.1212e-03, -7.1269e-03,  2.4118e-02,  3.8047e-03,\n",
       "                      -5.0362e-03, -1.1293e-02,  2.3049e-02,  2.2958e-03, -9.6636e-03,\n",
       "                       1.6277e-02,  1.2218e-02,  3.4651e-03,  1.1848e-03,  2.1173e-02,\n",
       "                      -7.8486e-03,  7.1414e-03, -1.6071e-02,  4.0825e-02,  3.8314e-03,\n",
       "                      -4.7240e-03, -1.4257e-02,  5.6761e-05,  3.6000e-03,  2.3351e-02,\n",
       "                       1.0775e-03,  1.0955e-02, -8.4777e-03, -6.8288e-03,  7.4970e-03,\n",
       "                      -6.9391e-03, -2.8761e-03,  2.2137e-02,  1.0996e-02,  1.3523e-03,\n",
       "                      -6.0561e-03,  1.5105e-02,  3.7707e-03,  6.5373e-04, -9.4932e-03,\n",
       "                       1.6147e-02,  1.5559e-02,  1.2724e-02, -6.4037e-03,  5.2738e-03,\n",
       "                      -6.5507e-03,  1.5815e-02,  1.5831e-02, -2.1506e-02,  8.9347e-03,\n",
       "                      -1.9448e-02,  8.3050e-03, -7.7984e-03, -1.6915e-02,  8.3474e-03,\n",
       "                       1.9788e-02,  1.9575e-02,  1.7140e-02,  4.1456e-03,  3.9849e-02,\n",
       "                       1.8532e-02, -3.7475e-03, -6.4171e-04, -9.7313e-04,  1.0785e-02,\n",
       "                      -1.3645e-02,  3.9976e-02,  2.0064e-02, -6.6552e-04,  2.1579e-02,\n",
       "                      -1.3641e-02, -9.4121e-03,  7.7841e-03,  2.1873e-02,  1.0824e-02,\n",
       "                       5.4526e-03,  1.3100e-02,  4.7156e-03,  5.2285e-03, -1.0202e-02,\n",
       "                       8.6104e-03, -1.9890e-02,  1.6143e-02,  2.1335e-02,  3.4871e-02,\n",
       "                       3.4401e-02,  5.6305e-03,  2.5416e-02,  1.5382e-02,  1.2082e-02,\n",
       "                       6.3802e-03,  5.8248e-03,  7.2526e-03,  1.3092e-02,  3.1827e-03,\n",
       "                       2.5325e-02, -9.6771e-03,  1.8791e-02,  1.5581e-02,  3.4279e-02,\n",
       "                       3.7993e-02,  3.1179e-03, -3.8271e-03,  1.2354e-02, -2.9887e-02,\n",
       "                       1.3829e-02,  5.3278e-03,  2.2974e-03, -1.6842e-02,  9.9356e-03,\n",
       "                       1.0988e-02,  1.6827e-02, -8.8208e-03,  3.2043e-03,  2.0990e-02,\n",
       "                      -4.9782e-03, -1.6266e-02, -2.4447e-03,  8.6046e-03,  7.4645e-03,\n",
       "                      -7.6250e-03, -6.4591e-03,  2.2971e-02, -2.0349e-02, -7.9736e-03,\n",
       "                       2.1666e-02, -6.2828e-03,  1.3893e-02, -4.7515e-03,  1.3377e-03,\n",
       "                       4.3654e-03,  2.2743e-03,  7.4808e-03,  2.3192e-03, -1.0558e-02,\n",
       "                       2.1544e-02, -3.4616e-03,  3.4009e-03,  1.8247e-02,  2.0225e-02,\n",
       "                       1.1625e-02, -4.7732e-03,  9.0139e-03, -1.1355e-02, -7.1083e-03,\n",
       "                       7.9576e-03,  1.8426e-02,  1.0176e-02, -1.6573e-02,  1.4236e-02,\n",
       "                       9.5729e-03,  4.6540e-03, -1.9550e-03,  3.1653e-02, -1.3638e-02,\n",
       "                      -2.1022e-02,  7.7136e-04,  2.3706e-02,  2.6324e-02, -2.8976e-03,\n",
       "                      -8.4220e-03,  1.8299e-02,  1.9660e-03,  4.0402e-03,  2.9366e-02,\n",
       "                       8.4486e-03,  1.3624e-02, -1.3401e-02,  2.0594e-02,  9.9334e-03,\n",
       "                      -3.3441e-03,  5.0730e-03, -2.0963e-02,  7.2705e-03,  9.7438e-03,\n",
       "                       1.1558e-02,  2.7270e-02,  2.8745e-02,  5.1925e-03, -1.0196e-04,\n",
       "                       1.5687e-02,  1.1526e-02,  2.3031e-02, -3.4701e-03, -2.7489e-03])),\n",
       "             ('BN1.running_mean',\n",
       "              tensor([ 1.5979e-02, -8.3921e-03, -1.0570e-02,  4.0603e-03,  7.6917e-03,\n",
       "                      -1.3223e-03,  7.6865e-03, -2.1929e-03,  3.0552e-02, -2.2326e-03,\n",
       "                      -1.8037e-02, -1.5104e-02,  2.6218e-02,  1.6198e-02, -9.5951e-03,\n",
       "                      -1.1806e-02, -1.1475e-02, -7.8272e-03, -1.9174e-02,  7.9840e-03,\n",
       "                       1.5020e-02,  1.9196e-02,  3.8705e-04,  2.4415e-02,  2.3742e-02,\n",
       "                      -1.0464e-02,  3.4166e-02,  5.3846e-03,  1.9710e-02, -2.1641e-02,\n",
       "                       1.1133e-02,  7.1861e-04, -8.3134e-03,  6.4029e-03, -2.2833e-02,\n",
       "                       4.1798e-03,  1.4791e-03, -1.4559e-04,  8.9453e-03,  4.0715e-03,\n",
       "                       1.7401e-03,  3.0946e-03, -8.2649e-03,  2.9093e-02, -1.0784e-02,\n",
       "                       1.2257e-02, -1.9875e-02, -7.0603e-03,  7.3590e-03,  2.4524e-03,\n",
       "                       1.1820e-02,  1.7047e-02, -2.1916e-02,  1.0798e-02, -2.5885e-02,\n",
       "                       2.6640e-02,  1.7735e-02,  3.0615e-02, -9.1064e-03,  1.5902e-02,\n",
       "                       1.3432e-02,  2.9217e-02,  1.6626e-03, -5.0156e-03, -1.3659e-05,\n",
       "                      -3.5127e-03,  3.0451e-03, -9.3170e-03, -1.4241e-02, -3.8974e-03,\n",
       "                      -5.1268e-03,  1.7301e-02, -1.2891e-02,  8.0782e-03, -1.2238e-02,\n",
       "                      -3.0615e-03,  3.1065e-03, -1.5571e-02,  8.5697e-03, -1.3480e-02,\n",
       "                      -2.8215e-02, -2.9257e-02,  1.0588e-02, -1.0223e-02,  1.8739e-03,\n",
       "                       1.6971e-02,  1.1407e-02, -1.1256e-03,  3.1786e-03, -2.5187e-02,\n",
       "                       5.9451e-03, -7.0733e-03,  1.4198e-02, -7.8893e-03, -6.4281e-05,\n",
       "                       2.4456e-03,  3.1304e-02, -9.7330e-03, -3.0617e-04, -1.1751e-02,\n",
       "                      -1.0995e-02,  1.7575e-02,  8.3965e-03, -1.1288e-02, -3.8552e-02,\n",
       "                       8.7222e-03, -2.9954e-02, -9.2863e-03,  4.7868e-03,  1.9729e-02,\n",
       "                       5.6916e-03, -1.3435e-02,  1.8927e-02, -2.6998e-03,  8.7866e-03,\n",
       "                       2.2133e-02, -8.2846e-03,  3.6864e-04,  1.0822e-02,  2.9963e-02,\n",
       "                       6.2799e-03, -3.3495e-02,  1.7397e-02,  9.7815e-03,  1.6192e-02,\n",
       "                      -1.7175e-02,  1.9633e-02,  1.9112e-02, -3.9036e-03, -4.0968e-03,\n",
       "                      -1.1523e-02, -1.3823e-02,  1.2323e-02, -8.8635e-03, -1.7637e-02,\n",
       "                      -1.6256e-02, -1.9889e-02, -7.4178e-03,  4.8783e-03,  8.2551e-03,\n",
       "                       1.8650e-02,  1.1981e-03,  1.4369e-02,  3.6087e-03,  1.5963e-02,\n",
       "                      -2.0408e-03, -4.0704e-03, -2.0994e-02,  2.5096e-02, -3.7925e-02,\n",
       "                       2.1448e-02, -2.1493e-03, -2.9207e-02,  2.6516e-02, -1.2743e-03,\n",
       "                       1.2750e-02,  1.8615e-03,  1.7486e-02, -1.9875e-02,  6.9443e-03,\n",
       "                      -1.4316e-02,  2.2423e-02,  7.4770e-03,  1.9163e-02, -1.6027e-02,\n",
       "                       1.2113e-02,  2.0418e-02, -4.5793e-03, -2.2119e-03, -1.4532e-02,\n",
       "                       2.5737e-02, -3.8573e-02, -2.3969e-02,  2.5108e-02, -2.1397e-03,\n",
       "                       2.7853e-02, -1.5970e-02,  1.9676e-02, -1.0831e-02,  2.0650e-02,\n",
       "                       7.3339e-04,  4.3993e-04,  1.0129e-02,  3.1758e-02,  1.5695e-02,\n",
       "                      -3.0071e-03,  1.6274e-04,  1.6107e-02, -1.6139e-03, -2.6205e-02,\n",
       "                      -1.1258e-02, -5.6013e-03,  1.7295e-02, -1.5252e-03, -2.2107e-02,\n",
       "                      -1.0394e-02, -1.2754e-02,  2.3707e-02,  1.4186e-02,  1.6495e-02,\n",
       "                      -2.4400e-02, -2.6388e-02,  2.9075e-02,  2.9732e-02, -6.5790e-03,\n",
       "                       6.7083e-03,  4.3911e-03,  2.4123e-04, -1.1693e-02, -8.0739e-03,\n",
       "                      -4.1285e-03,  2.1755e-02, -5.5141e-03, -2.8190e-02,  8.3398e-03,\n",
       "                       1.0107e-02,  6.5287e-03, -8.4246e-03, -8.8514e-03,  2.3668e-02,\n",
       "                      -3.1109e-02,  1.4129e-02, -1.3499e-02,  2.6792e-02,  2.7313e-02,\n",
       "                       2.3250e-02, -6.2473e-03,  3.5316e-03,  2.3865e-02,  9.6786e-03,\n",
       "                      -5.5764e-03,  1.5669e-02,  5.8355e-03,  9.5154e-03, -1.7027e-02,\n",
       "                       2.4604e-02, -1.8587e-02,  2.2818e-02, -7.8201e-03,  1.8925e-02,\n",
       "                       1.6014e-03, -1.3751e-02, -7.7790e-03,  2.5924e-02, -9.2362e-03,\n",
       "                      -1.2949e-02, -6.5568e-03,  2.1232e-02,  1.3955e-02, -8.1523e-03,\n",
       "                       1.9961e-02,  1.7587e-02,  3.1429e-02, -2.8383e-02, -1.3924e-02,\n",
       "                       2.2387e-02,  2.2877e-02,  6.6053e-03, -4.4747e-03,  2.8911e-02,\n",
       "                       1.3421e-03, -2.4966e-02,  4.4511e-04,  1.8239e-02,  3.4779e-02,\n",
       "                       5.2353e-03, -1.8487e-02, -3.1336e-02,  8.8013e-03,  9.5783e-03,\n",
       "                      -1.7671e-02, -2.1818e-03,  4.9741e-04, -2.0543e-02,  3.2832e-02,\n",
       "                       9.6946e-03,  1.0512e-02, -5.6243e-03, -5.1487e-03, -3.6166e-02,\n",
       "                       9.6397e-03,  2.3578e-02,  1.7070e-02, -2.9305e-02, -4.0643e-03,\n",
       "                      -1.4021e-03, -2.6135e-03,  1.1028e-02, -9.5124e-04, -8.6064e-03,\n",
       "                       8.2610e-03,  2.3070e-03, -2.7336e-04, -1.4567e-02,  7.5762e-03,\n",
       "                       1.7778e-02, -3.4891e-03,  5.8798e-03,  1.0951e-02,  3.3743e-03,\n",
       "                      -7.0044e-03,  3.7748e-02,  1.5292e-02,  4.6283e-03,  1.3632e-02,\n",
       "                      -4.9615e-03,  8.8014e-03,  2.8536e-02, -3.6722e-05, -1.2372e-02,\n",
       "                       2.3300e-02, -3.0166e-02,  1.8040e-02, -4.7776e-03,  1.1567e-02,\n",
       "                       1.1574e-02,  1.9532e-03, -3.3755e-03,  1.3214e-02,  2.2154e-02,\n",
       "                       2.4205e-02,  1.7880e-02,  3.0108e-02, -1.7319e-02,  1.5805e-02,\n",
       "                       4.0955e-03,  1.9427e-02, -8.1889e-03,  2.5755e-02,  3.0130e-02,\n",
       "                      -8.4576e-04, -1.1933e-03,  1.0176e-02, -1.2805e-02,  1.9871e-02,\n",
       "                       9.7017e-03,  1.5691e-02,  1.1340e-02, -1.6297e-03, -5.0702e-03,\n",
       "                      -8.6722e-03,  8.4614e-03, -6.1363e-03, -2.4104e-02,  1.4216e-02,\n",
       "                      -1.0788e-03, -9.5046e-03,  3.8040e-03, -1.6085e-02, -3.6233e-04,\n",
       "                       3.1757e-03,  2.7993e-02,  2.6565e-02,  8.4625e-03,  1.4356e-02,\n",
       "                      -1.7802e-02,  1.0898e-02,  3.0302e-02, -2.2269e-02,  1.0257e-02,\n",
       "                       1.6863e-03, -3.0976e-04, -1.3382e-03, -7.1644e-03, -1.7186e-02,\n",
       "                       6.1707e-03, -3.9458e-03, -5.2765e-03,  1.7545e-02,  5.3078e-03,\n",
       "                       2.5668e-02, -5.1643e-03, -2.4084e-02,  1.0142e-02, -5.1873e-03,\n",
       "                      -1.3872e-02,  2.5305e-03,  1.0475e-02, -3.4370e-02,  1.6721e-02,\n",
       "                       1.4349e-02,  1.6668e-02,  1.8346e-02,  8.2756e-03,  1.9958e-02,\n",
       "                      -1.2863e-02, -3.2438e-02, -1.0957e-02,  9.5021e-03, -2.2843e-02,\n",
       "                      -5.9363e-03, -5.6797e-03,  1.6000e-02, -2.3095e-02,  1.1913e-02,\n",
       "                      -2.3546e-02,  3.4436e-03, -1.5736e-02,  9.3157e-03, -2.1713e-03,\n",
       "                       1.4862e-02,  4.2027e-03,  9.0437e-03,  2.8478e-02, -1.7558e-03,\n",
       "                      -2.2546e-02, -2.3105e-02,  1.4240e-02,  3.5045e-02,  1.6070e-02,\n",
       "                      -6.9266e-03,  6.3811e-03,  1.2116e-02, -1.0122e-02, -3.4900e-02,\n",
       "                       2.3993e-03,  6.6541e-03,  1.9928e-02, -3.3418e-02, -2.3798e-03,\n",
       "                       1.8594e-03, -2.0612e-04,  1.8777e-02, -1.8105e-02, -1.2347e-04,\n",
       "                       1.4346e-02,  8.1085e-03, -1.2288e-02, -4.8253e-03, -3.0419e-02,\n",
       "                       1.1027e-02, -3.4959e-03, -1.2693e-02,  2.2644e-02,  7.3829e-03,\n",
       "                       2.9939e-02,  1.2471e-03, -3.2729e-03, -6.1538e-03,  9.5004e-03,\n",
       "                      -1.9808e-03, -8.0466e-03, -3.0950e-03, -3.0371e-02, -2.8467e-02,\n",
       "                       1.7550e-02, -1.9272e-03,  2.4924e-02,  2.2506e-02, -1.0687e-02,\n",
       "                      -2.1325e-02, -6.8485e-03, -1.6798e-02, -1.1240e-02,  3.0448e-02,\n",
       "                      -1.0492e-02, -6.8585e-03,  6.2780e-03, -2.3833e-03, -1.0727e-02,\n",
       "                       1.2339e-02,  1.2955e-02,  5.3793e-03, -2.1265e-02, -2.7198e-02,\n",
       "                       4.6935e-03,  3.2734e-03, -9.5361e-03,  2.2110e-02,  1.6801e-02,\n",
       "                       1.1266e-03, -1.9382e-02, -1.2232e-02,  1.6808e-02,  2.0899e-03,\n",
       "                       2.9127e-02, -6.2613e-03,  1.3826e-03, -9.0855e-03,  9.3541e-03,\n",
       "                      -9.5000e-03,  8.0587e-03, -3.5070e-03,  3.1898e-02, -3.9246e-03,\n",
       "                      -1.1069e-02, -4.8722e-03, -1.5860e-02,  6.0152e-03,  1.3474e-03,\n",
       "                       5.7025e-03,  2.6122e-02,  3.3829e-02,  2.2403e-02, -4.5319e-03,\n",
       "                      -5.0203e-03,  5.7392e-03, -1.5159e-03, -2.3906e-02, -8.9274e-03])),\n",
       "             ('BN1.running_var',\n",
       "              tensor([2.8941, 1.9068, 3.4819, 3.5290, 4.3340, 2.2926, 3.4542, 1.6300, 2.8531,\n",
       "                      3.0637, 3.5462, 4.7226, 1.7327, 4.2518, 4.2070, 3.2694, 2.3657, 1.7751,\n",
       "                      2.2548, 1.5983, 3.5765, 3.3817, 2.5984, 4.0082, 1.7722, 2.7432, 2.5186,\n",
       "                      1.8968, 4.7511, 2.1878, 7.0188, 3.2224, 1.6659, 4.7045, 1.7199, 2.2383,\n",
       "                      2.7480, 2.1177, 1.6131, 4.7541, 2.3345, 4.1006, 7.7057, 3.3359, 2.6827,\n",
       "                      3.1671, 1.6175, 3.9543, 3.2079, 2.0928, 2.0026, 3.5402, 3.7992, 6.2258,\n",
       "                      3.3788, 2.6364, 1.6374, 2.4946, 2.7198, 2.3150, 3.4705, 2.0523, 2.1243,\n",
       "                      1.9287, 2.9012, 4.9181, 2.4214, 4.2436, 2.1503, 4.6303, 2.4668, 2.9407,\n",
       "                      1.7141, 2.7614, 2.1133, 2.6732, 6.4687, 4.5644, 2.7364, 5.0823, 4.4631,\n",
       "                      5.2982, 2.6729, 2.6034, 2.7830, 1.9430, 2.3012, 3.1202, 4.6960, 4.9894,\n",
       "                      2.7968, 4.1193, 3.0509, 4.3307, 3.3764, 2.8712, 5.8568, 4.4695, 2.7539,\n",
       "                      4.7666, 5.5402, 1.8797, 2.6485, 2.0658, 5.8482, 2.5722, 2.5391, 5.7831,\n",
       "                      2.4875, 2.6607, 5.9136, 5.1065, 1.5863, 5.0843, 1.9993, 5.0906, 4.5806,\n",
       "                      1.7432, 3.9858, 3.3643, 3.5150, 2.2530, 4.3692, 1.7768, 2.1083, 2.8714,\n",
       "                      2.5807, 2.8425, 2.7677, 6.2828, 4.3805, 2.9065, 2.3097, 3.0692, 6.8929,\n",
       "                      2.3222, 2.2290, 3.0097, 3.6912, 2.8932, 4.1844, 3.3388, 2.2036, 2.8355,\n",
       "                      2.2398, 2.2524, 3.5567, 2.4894, 2.2061, 4.5380, 3.9899, 2.8281, 1.9391,\n",
       "                      4.5148, 3.1065, 2.9179, 3.6264, 2.9768, 4.8702, 2.5706, 4.9809, 2.1007,\n",
       "                      2.4589, 1.9848, 2.9937, 3.3382, 3.0972, 2.0501, 3.1635, 5.1814, 2.6225,\n",
       "                      7.5186, 2.3611, 1.8085, 4.8470, 2.4877, 2.7872, 4.2607, 2.8459, 1.5375,\n",
       "                      2.3058, 2.5757, 2.0172, 2.7011, 2.8402, 3.5332, 2.6607, 1.6511, 5.2564,\n",
       "                      6.2741, 3.3524, 2.2322, 4.6322, 4.1233, 1.8970, 3.2401, 2.2587, 4.2922,\n",
       "                      2.4265, 2.6999, 3.5420, 4.1724, 5.5321, 2.7394, 2.5991, 3.3001, 2.1837,\n",
       "                      3.0999, 1.5690, 2.6677, 2.7523, 3.0805, 3.2587, 6.5939, 1.4477, 6.6102,\n",
       "                      3.4234, 3.8153, 3.7185, 4.6998, 4.6001, 3.7584, 2.5822, 1.8124, 3.5706,\n",
       "                      4.4367, 2.3236, 2.3840, 2.4959, 6.0327, 3.7224, 4.3440, 4.8301, 2.7373,\n",
       "                      3.3722, 2.2831, 4.8100, 2.9544, 4.7646, 3.2487, 1.5587, 4.0930, 2.1963,\n",
       "                      3.8196, 5.2440, 2.3995, 2.6781, 1.7024, 1.9222, 1.9264, 2.4285, 1.9742,\n",
       "                      2.1185, 2.5399, 2.2305, 2.7337, 2.0493, 4.2806, 6.1530, 4.6459, 2.9633,\n",
       "                      1.8282, 5.5920, 4.0414, 2.2168, 1.8384, 3.3942, 3.1532, 2.1354, 2.8603,\n",
       "                      5.2917, 2.3400, 2.8393, 3.6341, 3.5692, 1.8213, 1.7032, 4.1204, 3.5662,\n",
       "                      4.2211, 3.0861, 1.8521, 2.0996, 3.4599, 2.1685, 3.0415, 5.5136, 1.3480,\n",
       "                      5.4432, 2.4173, 4.4400, 2.1693, 3.1940, 2.6946, 3.2384, 2.5382, 2.5047,\n",
       "                      4.8066, 4.2931, 5.4272, 2.1017, 2.4789, 3.1230, 1.7794, 3.4281, 1.2750,\n",
       "                      2.9698, 3.3182, 2.0575, 4.1577, 2.3837, 5.3048, 2.6842, 3.1309, 1.7110,\n",
       "                      3.5715, 5.9689, 1.5123, 3.8788, 1.6544, 1.5063, 1.7181, 4.0516, 4.9175,\n",
       "                      3.2169, 1.6706, 2.4087, 2.3911, 1.6308, 2.2883, 2.7958, 3.1844, 1.8010,\n",
       "                      2.0216, 3.4236, 2.7077, 3.4581, 3.5720, 2.3501, 4.0819, 1.7953, 3.2507,\n",
       "                      5.5835, 3.7649, 3.0155, 1.8723, 4.0515, 5.6112, 2.8717, 2.5204, 3.8784,\n",
       "                      2.2098, 3.6664, 3.2661, 4.2170, 2.0299, 2.2673, 2.9798, 3.5846, 2.3669,\n",
       "                      2.6270, 3.1332, 2.9438, 4.1908, 6.3036, 2.5231, 2.1486, 2.5514, 3.1487,\n",
       "                      3.3825, 8.4687, 3.1517, 2.4115, 2.4466, 1.8601, 4.4755, 4.9710, 2.2971,\n",
       "                      3.7118, 4.4898, 2.9930, 2.7102, 1.8463, 4.1804, 3.1020, 5.3740, 2.7746,\n",
       "                      2.5409, 2.0704, 2.3843, 2.1101, 3.7216, 3.1380, 3.8658, 3.3523, 2.6704,\n",
       "                      3.2951, 1.6729, 3.5265, 2.5864, 3.4161, 3.8731, 2.4506, 2.5091, 2.8200,\n",
       "                      4.0657, 2.6904, 2.6133, 1.6974, 3.2489, 1.6728, 2.7489, 2.1413, 2.5116,\n",
       "                      2.2012, 2.4262, 1.7894, 1.6383, 7.1259, 1.7209, 2.2711, 4.7792, 2.5776,\n",
       "                      2.2322, 2.8172, 3.3944, 6.3185, 2.6503, 2.6189, 3.0914, 4.1090, 2.5413,\n",
       "                      4.2766, 3.2433, 3.9392, 3.7564, 1.7574, 3.5499, 2.4637, 2.0566, 2.2190,\n",
       "                      2.9837, 2.2078, 4.3676, 2.1194, 2.3529, 5.3290, 1.9196, 2.0840, 4.7319,\n",
       "                      5.0004, 3.1619, 2.7696, 1.5720, 3.0908, 2.3589, 2.0054, 2.3343, 2.5027,\n",
       "                      3.5609, 2.5232, 2.7921, 4.8355, 3.0547, 4.3336, 2.7767, 4.2971, 2.3934,\n",
       "                      3.0510, 1.4266, 2.9293, 3.2458, 2.5163, 3.7493, 3.6349, 3.0664, 3.2030,\n",
       "                      2.9939, 2.3424, 1.8546, 3.9960, 3.2808, 4.3219, 2.9095, 2.9500, 3.9263,\n",
       "                      2.3846, 1.7513, 2.4633, 2.3296, 1.9910, 2.7101, 1.8136, 4.9166, 3.8912,\n",
       "                      2.3411, 4.2695, 3.0474, 4.4256, 3.9716])),\n",
       "             ('BN1.num_batches_tracked', tensor(600)),\n",
       "             ('enc_2.weight',\n",
       "              tensor([[-0.0227,  0.0041, -0.0105,  ...,  0.0067,  0.0122,  0.0127],\n",
       "                      [ 0.0381, -0.0178,  0.0249,  ...,  0.0007, -0.0408,  0.0228],\n",
       "                      [-0.0316, -0.0059, -0.0459,  ...,  0.0201,  0.0120, -0.0261],\n",
       "                      ...,\n",
       "                      [ 0.0531,  0.0116,  0.0257,  ..., -0.0174,  0.0047,  0.0259],\n",
       "                      [-0.0427,  0.0109, -0.0071,  ..., -0.0248, -0.0023, -0.0194],\n",
       "                      [-0.0095, -0.0080,  0.0216,  ..., -0.0132, -0.0327,  0.0402]])),\n",
       "             ('enc_2.bias',\n",
       "              tensor([ 0.0344,  0.0133, -0.0176,  0.0228,  0.0301,  0.0106,  0.0245,  0.0396,\n",
       "                       0.0003, -0.0256, -0.0331, -0.0218, -0.0355, -0.0208,  0.0337,  0.0442,\n",
       "                      -0.0184,  0.0064, -0.0286, -0.0399, -0.0368, -0.0185,  0.0034,  0.0284,\n",
       "                      -0.0297, -0.0012,  0.0160,  0.0188,  0.0355, -0.0220,  0.0003, -0.0121,\n",
       "                       0.0337, -0.0098,  0.0025, -0.0218,  0.0422,  0.0234,  0.0425, -0.0416,\n",
       "                      -0.0296,  0.0357, -0.0030,  0.0389,  0.0138, -0.0058, -0.0398, -0.0335,\n",
       "                       0.0366, -0.0137, -0.0371,  0.0280,  0.0063, -0.0173,  0.0037,  0.0332,\n",
       "                      -0.0162, -0.0055, -0.0227, -0.0349, -0.0033,  0.0078,  0.0087,  0.0074,\n",
       "                       0.0289,  0.0355, -0.0077,  0.0334, -0.0231,  0.0027, -0.0136, -0.0262,\n",
       "                      -0.0066,  0.0239, -0.0367,  0.0030, -0.0253, -0.0211,  0.0152,  0.0338,\n",
       "                       0.0333, -0.0086,  0.0151,  0.0404,  0.0072, -0.0098, -0.0163, -0.0133,\n",
       "                      -0.0156,  0.0109, -0.0330, -0.0049,  0.0399,  0.0039, -0.0025,  0.0411,\n",
       "                       0.0181, -0.0304,  0.0167,  0.0053, -0.0284,  0.0399, -0.0177, -0.0427,\n",
       "                       0.0244, -0.0379, -0.0045, -0.0147,  0.0100,  0.0185,  0.0206, -0.0228,\n",
       "                       0.0028, -0.0307, -0.0022,  0.0349, -0.0195,  0.0334,  0.0201,  0.0034,\n",
       "                       0.0325,  0.0244, -0.0022,  0.0426,  0.0064, -0.0188, -0.0036, -0.0331,\n",
       "                       0.0350, -0.0035, -0.0036,  0.0038,  0.0394, -0.0049,  0.0172,  0.0217,\n",
       "                       0.0076, -0.0280, -0.0311,  0.0363, -0.0231,  0.0385, -0.0236, -0.0380,\n",
       "                      -0.0264,  0.0006,  0.0073,  0.0003, -0.0236, -0.0327, -0.0047, -0.0338,\n",
       "                      -0.0185,  0.0139,  0.0249,  0.0107,  0.0101,  0.0368, -0.0157,  0.0319,\n",
       "                      -0.0268, -0.0442,  0.0278, -0.0245, -0.0038, -0.0415, -0.0379, -0.0372,\n",
       "                       0.0098, -0.0142, -0.0209,  0.0408, -0.0180, -0.0233,  0.0046,  0.0009,\n",
       "                       0.0085, -0.0272,  0.0134,  0.0235,  0.0378,  0.0175, -0.0050,  0.0004,\n",
       "                       0.0437,  0.0279,  0.0246, -0.0037,  0.0378,  0.0073,  0.0054,  0.0130,\n",
       "                       0.0440, -0.0338,  0.0175, -0.0375, -0.0290,  0.0196,  0.0418, -0.0180,\n",
       "                       0.0339, -0.0447,  0.0131,  0.0433, -0.0424, -0.0227,  0.0035,  0.0165,\n",
       "                      -0.0028, -0.0091,  0.0262,  0.0419,  0.0043,  0.0114, -0.0365, -0.0087,\n",
       "                      -0.0099, -0.0324, -0.0291, -0.0195, -0.0314,  0.0447,  0.0220, -0.0370,\n",
       "                      -0.0113,  0.0094, -0.0308,  0.0160, -0.0419, -0.0190, -0.0443, -0.0033,\n",
       "                       0.0081, -0.0309, -0.0046,  0.0135, -0.0253, -0.0175, -0.0072, -0.0354,\n",
       "                      -0.0306,  0.0029,  0.0376, -0.0435,  0.0097,  0.0388, -0.0169, -0.0360,\n",
       "                       0.0056,  0.0135, -0.0426, -0.0089, -0.0380, -0.0239, -0.0134, -0.0440,\n",
       "                      -0.0124, -0.0151,  0.0428, -0.0238, -0.0317, -0.0265,  0.0392,  0.0030,\n",
       "                      -0.0146,  0.0416,  0.0301,  0.0232,  0.0226, -0.0175,  0.0399,  0.0146,\n",
       "                       0.0298, -0.0187, -0.0341,  0.0287,  0.0053,  0.0094,  0.0403, -0.0061,\n",
       "                       0.0051,  0.0045,  0.0191,  0.0188, -0.0182, -0.0128, -0.0386,  0.0094,\n",
       "                       0.0244,  0.0436,  0.0259,  0.0153,  0.0259, -0.0356, -0.0196, -0.0103,\n",
       "                      -0.0396, -0.0425, -0.0114,  0.0308, -0.0031, -0.0005, -0.0062, -0.0411,\n",
       "                      -0.0346,  0.0201, -0.0307,  0.0251, -0.0044, -0.0376, -0.0036,  0.0423,\n",
       "                      -0.0294,  0.0009,  0.0076,  0.0299, -0.0444,  0.0366, -0.0072,  0.0068,\n",
       "                      -0.0120, -0.0155,  0.0087, -0.0407,  0.0114,  0.0328, -0.0356,  0.0155,\n",
       "                       0.0180, -0.0119,  0.0113, -0.0228,  0.0023,  0.0393,  0.0257,  0.0332,\n",
       "                       0.0161,  0.0078, -0.0344, -0.0237, -0.0374, -0.0093,  0.0147,  0.0149,\n",
       "                       0.0075, -0.0156,  0.0288,  0.0231, -0.0060, -0.0233,  0.0423, -0.0297,\n",
       "                       0.0126,  0.0111,  0.0110, -0.0111,  0.0261,  0.0004,  0.0254, -0.0062,\n",
       "                      -0.0428, -0.0200,  0.0436,  0.0090,  0.0149,  0.0418, -0.0254,  0.0426,\n",
       "                       0.0380, -0.0006,  0.0422, -0.0121,  0.0430, -0.0288,  0.0043,  0.0381,\n",
       "                      -0.0349, -0.0423, -0.0252,  0.0296, -0.0376,  0.0176, -0.0226,  0.0142,\n",
       "                       0.0137,  0.0103,  0.0029,  0.0355,  0.0026,  0.0259,  0.0427, -0.0073,\n",
       "                       0.0306, -0.0330, -0.0152,  0.0397,  0.0237, -0.0310, -0.0043,  0.0183,\n",
       "                       0.0167, -0.0318, -0.0333,  0.0172,  0.0210, -0.0274,  0.0445,  0.0168,\n",
       "                       0.0364,  0.0373,  0.0178, -0.0299,  0.0200,  0.0027, -0.0214, -0.0343,\n",
       "                      -0.0281, -0.0266, -0.0362, -0.0019,  0.0221,  0.0009, -0.0188, -0.0415,\n",
       "                      -0.0382,  0.0232,  0.0181, -0.0037, -0.0290, -0.0152,  0.0123,  0.0414,\n",
       "                       0.0053, -0.0423, -0.0297,  0.0055, -0.0086,  0.0355, -0.0179,  0.0351,\n",
       "                      -0.0091, -0.0277,  0.0350, -0.0381,  0.0401, -0.0041,  0.0111,  0.0446,\n",
       "                       0.0182, -0.0414,  0.0312, -0.0142, -0.0128, -0.0445,  0.0368, -0.0065,\n",
       "                       0.0002,  0.0400,  0.0346,  0.0152,  0.0403,  0.0010, -0.0359, -0.0002,\n",
       "                      -0.0343, -0.0249,  0.0242, -0.0008, -0.0248, -0.0164, -0.0035,  0.0032,\n",
       "                       0.0024,  0.0374,  0.0245, -0.0393, -0.0339,  0.0341,  0.0136,  0.0140,\n",
       "                      -0.0271, -0.0257,  0.0001,  0.0312,  0.0085, -0.0054,  0.0012,  0.0398,\n",
       "                       0.0081, -0.0046,  0.0318,  0.0405, -0.0252, -0.0240,  0.0167,  0.0232,\n",
       "                      -0.0022, -0.0015, -0.0132, -0.0310])),\n",
       "             ('BN2.weight',\n",
       "              tensor([1.0013, 0.9950, 1.0101, 1.0028, 0.9986, 1.0080, 1.0192, 0.9972, 0.9796,\n",
       "                      0.9794, 0.9795, 1.0020, 1.0200, 1.0117, 0.9870, 1.0014, 0.9962, 0.9946,\n",
       "                      0.9995, 0.9937, 1.0404, 0.9930, 0.9845, 0.9888, 0.9997, 0.9896, 0.9910,\n",
       "                      1.0127, 0.9975, 0.9922, 1.0134, 1.0107, 1.0027, 1.0252, 0.9946, 0.9858,\n",
       "                      0.9952, 1.0035, 1.0009, 1.0016, 1.0143, 0.9884, 1.0026, 0.9874, 1.0288,\n",
       "                      0.9895, 0.9972, 0.9883, 1.0018, 0.9904, 0.9918, 0.9956, 0.9886, 0.9955,\n",
       "                      0.9875, 0.9960, 1.0206, 1.0049, 0.9771, 1.0173, 1.0119, 1.0005, 1.0134,\n",
       "                      1.0041, 1.0050, 0.9943, 0.9969, 1.0376, 0.9876, 0.9902, 0.9844, 1.0026,\n",
       "                      0.9842, 1.0028, 0.9852, 0.9893, 1.0101, 0.9897, 0.9987, 0.9814, 1.0116,\n",
       "                      0.9812, 0.9824, 0.9992, 1.0742, 0.9951, 0.9908, 0.9980, 1.0139, 1.0020,\n",
       "                      1.0162, 1.0308, 0.9793, 0.9833, 1.0056, 0.9891, 0.9964, 0.9961, 1.0110,\n",
       "                      0.9881, 0.9966, 0.9967, 0.9750, 1.0178, 0.9934, 0.9874, 0.9944, 1.0029,\n",
       "                      1.0129, 1.0047, 0.9846, 1.0035, 1.0143, 0.9729, 0.9796, 0.9869, 1.0020,\n",
       "                      0.9994, 0.9961, 0.9978, 1.0065, 0.9891, 1.0029, 0.9765, 0.9813, 0.9953,\n",
       "                      1.0193, 0.9718, 1.0251, 1.0030, 0.9948, 1.0098, 0.9954, 0.9937, 1.0154,\n",
       "                      1.0012, 1.0175, 0.9983, 0.9926, 1.0160, 1.0025, 0.9981, 1.0176, 0.9916,\n",
       "                      1.0237, 1.0159, 0.9958, 0.9994, 0.9922, 0.9938, 1.0302, 0.9977, 1.0109,\n",
       "                      0.9997, 1.0007, 1.0113, 1.0027, 0.9845, 0.9875, 0.9892, 1.0006, 1.0192,\n",
       "                      1.0039, 0.9886, 0.9973, 0.9925, 0.9825, 0.9843, 1.0127, 1.0074, 1.0035,\n",
       "                      0.9944, 0.9901, 1.0066, 1.0079, 0.9754, 0.9812, 0.9786, 0.9995, 0.9779,\n",
       "                      1.0347, 1.0485, 0.9915, 0.9898, 1.0041, 1.0022, 0.9930, 0.9882, 1.0354,\n",
       "                      0.9889, 0.9992, 0.9862, 1.0033, 0.9951, 0.9759, 1.0124, 0.9850, 1.0074,\n",
       "                      1.0065, 0.9939, 1.0576, 1.0146, 1.0194, 1.0006, 1.0062, 0.9972, 0.9891,\n",
       "                      0.9975, 0.9964, 1.0020, 0.9931, 0.9909, 0.9962, 0.9964, 0.9971, 1.0027,\n",
       "                      1.0126, 1.0077, 1.0069, 0.9926, 0.9993, 1.0135, 1.0012, 0.9950, 1.0189,\n",
       "                      0.9977, 1.0057, 0.9969, 1.0183, 0.9883, 1.0074, 0.9833, 1.0000, 1.0314,\n",
       "                      0.9808, 1.0056, 1.0219, 1.0041, 0.9994, 0.9907, 0.9831, 0.9802, 0.9828,\n",
       "                      1.0043, 1.0043, 0.9863, 0.9951, 0.9876, 1.0010, 0.9832, 1.0009, 0.9921,\n",
       "                      1.0012, 1.0188, 0.9852, 0.9910, 1.0135, 0.9904, 0.9838, 1.0132, 0.9913,\n",
       "                      0.9885, 1.0228, 0.9906, 1.0118, 0.9962, 1.0028, 0.9902, 0.9836, 1.0197,\n",
       "                      1.0108, 0.9934, 1.0043, 0.9953, 1.0062, 1.0034, 1.0081, 1.0057, 0.9951,\n",
       "                      0.9943, 1.0181, 0.9849, 1.0019, 1.0255, 0.9757, 0.9786, 1.0249, 0.9872,\n",
       "                      0.9872, 0.9995, 1.0165, 0.9998, 1.0276, 1.0067, 0.9854, 0.9620, 0.9943,\n",
       "                      0.9888, 0.9941, 1.0041, 1.0443, 0.9916, 0.9942, 0.9899, 1.0427, 0.9953,\n",
       "                      1.0081, 0.9887, 0.9870, 1.0027, 0.9768, 0.9972, 0.9956, 0.9896, 0.9864,\n",
       "                      1.0081, 1.0042, 1.0071, 0.9956, 0.9921, 1.0234, 1.0114, 1.0124, 1.0159,\n",
       "                      1.0004, 1.0078, 1.0238, 0.9835, 0.9915, 1.0226, 0.9946, 0.9884, 0.9856,\n",
       "                      0.9858, 1.0109, 1.0040, 1.0182, 1.0042, 1.0261, 1.0078, 0.9887, 0.9815,\n",
       "                      1.0054, 1.0087, 0.9879, 0.9893, 1.0027, 0.9950, 1.0060, 0.9911, 0.9930,\n",
       "                      0.9854, 1.0288, 1.0033, 0.9973, 0.9832, 0.9861, 1.0117, 1.0037, 0.9965,\n",
       "                      0.9654, 1.0189, 1.0228, 1.0082, 0.9939, 0.9872, 0.9913, 1.0190, 0.9895,\n",
       "                      1.0122, 1.0008, 1.0025, 0.9885, 0.9919, 1.0003, 0.9930, 1.0250, 0.9870,\n",
       "                      0.9854, 0.9996, 0.9942, 1.0028, 1.0018, 1.0065, 0.9848, 1.0028, 1.0108,\n",
       "                      0.9953, 0.9975, 0.9878, 1.0187, 0.9971, 0.9954, 1.0247, 1.0070, 1.0062,\n",
       "                      1.0045, 1.0011, 1.0188, 0.9952, 0.9863, 0.9827, 1.0086, 1.0323, 0.9820,\n",
       "                      1.0011, 0.9950, 0.9840, 0.9871, 0.9931, 0.9894, 1.0124, 1.0123, 0.9895,\n",
       "                      1.0131, 0.9891, 1.0228, 1.0031, 0.9872, 0.9939, 1.0137, 0.9874, 0.9802,\n",
       "                      0.9869, 0.9921, 1.0292, 0.9953, 1.0052, 1.0013, 1.0041, 0.9877, 1.0116,\n",
       "                      0.9917, 0.9928, 0.9928, 0.9812, 1.0204, 1.0201, 0.9980, 1.0067, 1.0556,\n",
       "                      0.9984, 0.9920, 0.9880, 1.0009, 1.0058, 0.9978, 1.0000, 1.0124, 1.0058,\n",
       "                      0.9859, 0.9765, 0.9856, 1.0011, 1.0030, 0.9964, 0.9913, 0.9977, 0.9840,\n",
       "                      1.0087, 1.0250, 0.9932, 0.9941, 1.0013, 0.9950, 0.9908, 0.9918, 1.0127,\n",
       "                      0.9853, 1.0197, 0.9956, 0.9897, 1.0121, 1.0033, 0.9948, 0.9925, 0.9962,\n",
       "                      0.9998, 0.9894, 1.0084, 1.0063, 0.9964, 1.0041, 1.0070, 0.9954, 0.9889,\n",
       "                      0.9870, 1.0037, 0.9724, 0.9992, 0.9786, 1.0173, 0.9945, 0.9677, 1.0167,\n",
       "                      0.9983, 0.9957, 0.9843, 1.0226, 0.9965])),\n",
       "             ('BN2.bias',\n",
       "              tensor([-4.6869e-03,  1.6387e-02,  2.7147e-02,  3.8755e-03,  2.5444e-02,\n",
       "                       3.4194e-03,  1.4747e-02,  2.1245e-02, -8.6996e-03,  2.1578e-02,\n",
       "                      -8.6176e-03, -3.2715e-03,  4.4149e-02,  7.0816e-05, -5.9537e-03,\n",
       "                       1.4214e-02, -3.0675e-03, -1.9608e-03,  1.2144e-02,  2.5745e-03,\n",
       "                       1.9449e-02,  4.8963e-03,  1.0409e-03, -1.5788e-02,  3.1069e-03,\n",
       "                      -4.1055e-02,  7.9536e-04,  3.0533e-02,  8.0223e-03,  2.6762e-02,\n",
       "                       1.9006e-02,  1.2336e-02, -1.2772e-02, -3.0368e-03,  1.4998e-02,\n",
       "                       4.8526e-03, -1.3128e-02,  9.2876e-03,  1.5390e-02, -9.9189e-05,\n",
       "                       1.1440e-02, -1.6333e-02,  1.3865e-02,  6.5012e-03,  3.4430e-02,\n",
       "                       1.2553e-03,  2.6615e-03, -9.8621e-03,  6.8307e-03, -8.8725e-03,\n",
       "                       4.9849e-03,  1.6601e-02, -6.5004e-03, -8.7065e-03,  5.4223e-03,\n",
       "                       1.1161e-02,  1.2212e-03,  1.4000e-02, -7.7093e-03,  1.3016e-02,\n",
       "                      -5.7647e-03, -4.9661e-04,  2.3866e-02,  2.4304e-02, -3.5137e-03,\n",
       "                       3.3071e-03, -3.4236e-03, -1.4061e-03,  7.1392e-03, -2.6276e-03,\n",
       "                       8.1840e-03,  8.3199e-03,  4.4674e-03,  1.2488e-02, -1.5244e-02,\n",
       "                      -2.8672e-04,  1.4748e-02,  8.8583e-04, -8.0386e-03, -7.6481e-03,\n",
       "                       2.2569e-02, -2.0405e-02, -1.7418e-02, -7.4379e-03,  6.3716e-02,\n",
       "                       2.4024e-02,  1.8843e-02, -3.3838e-03,  2.3251e-02,  1.0524e-02,\n",
       "                       1.4239e-02,  3.8002e-02, -3.9439e-03, -4.3061e-04,  2.8939e-03,\n",
       "                       1.0266e-02,  1.2504e-03,  1.6745e-02,  5.8526e-03, -1.0370e-02,\n",
       "                       3.8902e-03,  1.5704e-02, -3.8826e-04,  1.5908e-02,  1.2394e-02,\n",
       "                      -1.6747e-02, -5.0636e-03,  1.1070e-02,  3.2883e-02,  1.0896e-02,\n",
       "                      -8.4166e-03,  1.5315e-02,  2.8659e-02,  2.6823e-04, -1.5952e-02,\n",
       "                      -1.6894e-02,  2.0758e-02,  1.2165e-02,  1.2016e-02, -4.8987e-03,\n",
       "                       6.3309e-03, -1.0783e-02, -1.5080e-02, -2.6252e-02,  4.8027e-03,\n",
       "                       9.8124e-03,  2.7325e-02, -2.9839e-02,  2.4237e-02,  9.9551e-03,\n",
       "                       5.4086e-03,  1.1038e-02, -3.1008e-03,  4.6110e-03,  1.1563e-02,\n",
       "                       1.2964e-02,  8.5649e-03,  1.4747e-02,  2.8877e-03,  1.8344e-02,\n",
       "                       2.9509e-02, -9.9239e-04,  2.0003e-02,  1.3543e-02,  1.8432e-02,\n",
       "                       4.7985e-02, -5.5182e-03, -1.3400e-02,  3.6649e-03, -1.2824e-03,\n",
       "                       3.1483e-02,  1.5053e-03, -2.4631e-03,  1.6466e-02, -2.7890e-03,\n",
       "                       1.6561e-02,  1.8370e-02,  5.9596e-04, -3.6906e-03,  4.5305e-03,\n",
       "                       1.4679e-02, -9.8856e-03,  1.5164e-02,  1.9102e-03,  5.2134e-03,\n",
       "                       4.9245e-03, -1.2011e-02, -1.6168e-02,  1.2705e-02, -1.3461e-02,\n",
       "                      -3.0605e-02,  9.0189e-03,  1.9274e-02,  1.9835e-02,  3.0962e-02,\n",
       "                      -3.4871e-02, -6.3113e-04,  2.1483e-02,  2.0362e-02, -6.9088e-03,\n",
       "                       2.3023e-02,  9.8734e-03, -1.0382e-02, -8.9159e-03,  2.0112e-02,\n",
       "                       1.1469e-02,  5.5352e-03, -1.2538e-02,  1.8645e-02,  9.0145e-03,\n",
       "                       1.1889e-03,  7.6775e-04,  3.6376e-03,  1.7117e-02, -7.5003e-03,\n",
       "                       1.1500e-02, -5.1530e-03,  3.2857e-03,  1.6297e-02, -2.3464e-03,\n",
       "                       1.7833e-02,  9.8178e-03,  1.4056e-02,  5.0707e-03, -7.8808e-03,\n",
       "                       1.0473e-02, -3.4150e-03, -1.9066e-02,  1.1441e-02,  1.5016e-02,\n",
       "                       1.6017e-06, -9.9846e-03, -1.3085e-02,  4.3553e-03,  4.3892e-03,\n",
       "                       1.8568e-02,  1.6693e-02,  1.0025e-02,  3.4743e-02,  1.4309e-02,\n",
       "                       3.7301e-03,  1.0196e-02,  1.5456e-02,  3.7869e-03, -1.0549e-02,\n",
       "                      -7.4230e-03,  1.9254e-02, -6.4110e-03,  2.6950e-02,  5.5554e-03,\n",
       "                       2.9376e-02,  5.2847e-03,  1.8857e-02,  2.2441e-02,  8.1212e-03,\n",
       "                      -1.2889e-03,  2.4695e-02,  2.0250e-02,  6.6023e-03, -6.3361e-03,\n",
       "                      -1.8023e-02,  2.3940e-02, -6.5932e-03,  3.3774e-02,  6.4443e-03,\n",
       "                      -2.9312e-03, -2.3411e-03,  1.1355e-02,  2.5879e-02, -1.7316e-02,\n",
       "                      -4.6797e-03, -1.0197e-03,  1.3809e-02, -2.4221e-03,  1.3314e-03,\n",
       "                       2.5025e-03,  1.7651e-02, -5.3287e-03, -3.4649e-02,  3.4192e-03,\n",
       "                       1.2955e-02, -1.2175e-02,  2.1402e-02,  5.8312e-03,  2.5065e-03,\n",
       "                      -1.9198e-03,  1.5349e-02, -2.8263e-03,  6.9931e-04,  1.7941e-02,\n",
       "                       2.2841e-02,  2.1120e-02,  7.3394e-03, -8.2747e-03,  8.2445e-03,\n",
       "                      -8.0430e-03,  4.9034e-03,  1.0024e-02,  4.0333e-03,  8.1323e-03,\n",
       "                       2.1113e-02, -8.3769e-03,  2.1959e-02,  2.4557e-02,  3.9239e-03,\n",
       "                      -2.7375e-03,  9.5467e-03,  7.4468e-03, -6.6343e-03, -5.0616e-04,\n",
       "                       5.3836e-03,  6.7154e-03,  3.1376e-02, -5.1694e-03, -4.2785e-03,\n",
       "                      -1.4452e-02, -1.8126e-03,  6.2496e-03,  7.7364e-03,  1.8901e-02,\n",
       "                       1.3293e-02, -5.8808e-03,  1.0373e-02,  2.0854e-02,  4.2493e-02,\n",
       "                       6.9105e-03,  3.4340e-02,  9.1222e-03, -7.1752e-03,  1.8269e-02,\n",
       "                      -2.2042e-02,  2.3488e-02,  1.0408e-02,  1.7794e-02,  2.0906e-02,\n",
       "                       1.0294e-02, -7.7015e-03,  3.8754e-03,  2.4155e-02,  9.3284e-04,\n",
       "                       3.9125e-02,  1.6487e-03, -3.9999e-03,  1.7961e-02, -1.5431e-02,\n",
       "                       3.7454e-03,  1.1636e-02, -6.8984e-03, -8.5923e-03,  2.0622e-02,\n",
       "                      -1.2746e-02,  1.1609e-02, -3.3649e-03,  1.7076e-02,  1.7873e-02,\n",
       "                       2.5706e-02,  3.5641e-02, -3.3887e-04,  8.9503e-03,  1.1618e-02,\n",
       "                       1.5805e-02, -1.1093e-02,  5.8647e-03,  1.7308e-02, -1.8507e-02,\n",
       "                      -2.0266e-03,  6.9226e-03,  3.8557e-03,  2.0976e-02, -5.0398e-03,\n",
       "                      -5.7981e-03, -2.8131e-02,  3.7883e-02,  1.8510e-05,  1.1768e-02,\n",
       "                      -1.2127e-02,  5.0610e-03,  2.3672e-03,  1.6090e-02, -1.9480e-03,\n",
       "                      -7.3607e-03,  7.6238e-03,  9.4106e-03,  3.1921e-02,  3.3786e-02,\n",
       "                      -2.4689e-03,  9.6351e-04,  3.1538e-02, -6.3467e-03,  3.0153e-02,\n",
       "                       1.0669e-02, -1.4021e-03, -1.2334e-02,  5.0440e-03,  4.2579e-03,\n",
       "                      -7.8932e-03,  2.2067e-02, -6.3621e-03,  4.6546e-03,  1.1333e-02,\n",
       "                       2.4610e-02, -1.3515e-03,  1.0750e-03,  1.4044e-02, -1.6299e-04,\n",
       "                       9.2135e-03,  1.1269e-02,  6.8318e-03,  1.8581e-02,  8.4264e-03,\n",
       "                       1.8822e-02,  1.6297e-02, -3.9255e-03,  3.0869e-02,  8.6747e-03,\n",
       "                       3.5805e-03,  1.8233e-02,  1.2398e-03,  7.5279e-03, -1.7671e-03,\n",
       "                      -1.4778e-02, -5.2465e-03,  2.4182e-02, -9.1301e-03, -2.6750e-02,\n",
       "                      -3.1107e-03,  9.2699e-03, -9.6100e-03, -9.9833e-03, -4.3542e-04,\n",
       "                      -2.1663e-03, -5.2562e-03,  3.9433e-02, -2.0297e-02,  2.9258e-02,\n",
       "                      -8.6528e-03,  1.1002e-02,  8.2035e-03, -9.6744e-03, -1.2854e-02,\n",
       "                       3.1954e-02,  2.5892e-04,  9.6971e-04, -2.1141e-02,  1.0300e-02,\n",
       "                       9.3426e-03, -3.4883e-03,  1.9797e-02, -9.0858e-03,  1.7971e-02,\n",
       "                       1.7720e-03,  8.7681e-03,  1.5165e-02, -1.6850e-02, -5.6009e-04,\n",
       "                      -1.2900e-02,  2.5024e-02,  3.0290e-02,  9.1523e-03,  8.8762e-03,\n",
       "                       5.3552e-02,  1.3290e-02, -4.9743e-03,  9.9539e-04,  1.2226e-02,\n",
       "                       9.6692e-03, -1.8214e-02,  7.2955e-03,  2.3287e-02,  1.7303e-02,\n",
       "                       1.4674e-03,  5.9454e-03, -9.5181e-03,  4.8258e-04,  1.9365e-02,\n",
       "                      -6.1726e-04, -1.0052e-02,  5.1840e-03, -1.2583e-02,  2.5895e-02,\n",
       "                       2.9040e-02, -1.4795e-02,  8.7122e-03,  1.0868e-02,  7.0823e-03,\n",
       "                       3.9281e-03, -2.6711e-03,  1.3905e-02, -5.6929e-03,  3.1323e-02,\n",
       "                       1.3117e-02, -3.1375e-03,  1.0820e-02,  1.4021e-02, -4.2830e-03,\n",
       "                      -7.0739e-03,  5.5637e-03,  1.6384e-02,  3.8190e-03,  2.1239e-02,\n",
       "                       2.0155e-02,  1.7338e-02,  1.2910e-02,  3.3409e-02,  1.8198e-03,\n",
       "                       4.7400e-03,  1.2933e-02,  7.2471e-03, -2.2414e-02, -1.6123e-03,\n",
       "                      -2.7553e-03,  1.0431e-02,  1.1353e-02, -1.1073e-02,  1.0086e-03,\n",
       "                      -2.6494e-03,  7.8642e-05, -2.5805e-02,  2.1948e-02, -1.3671e-02])),\n",
       "             ('BN2.running_mean',\n",
       "              tensor([ 8.2936e-01, -2.4575e-01,  8.3979e-02, -3.6119e-01, -9.8521e-01,\n",
       "                       8.9245e-01,  2.5150e-01, -5.5794e-01, -3.3091e-02, -6.2701e-01,\n",
       "                       4.9078e-02,  2.6288e-01, -1.6064e-01,  6.8394e-01,  1.7166e-01,\n",
       "                      -3.0563e-01, -8.3936e-02,  1.7390e-01,  1.9082e-01, -5.2983e-02,\n",
       "                      -1.8148e-02, -3.3233e-02, -4.6230e-01,  6.0888e-01, -3.4968e-01,\n",
       "                       9.6900e-01,  2.5368e-01, -1.0383e+00, -3.4952e-01, -2.9888e-01,\n",
       "                      -7.9942e-02,  1.7064e-01,  9.5566e-02,  8.5075e-01, -5.0623e-01,\n",
       "                      -3.8989e-01,  2.2417e-01,  3.5806e-01, -2.7881e-01,  4.6509e-01,\n",
       "                      -4.6443e-01,  3.4801e-01,  5.0169e-02,  1.6194e-01,  4.8149e-01,\n",
       "                      -4.9533e-01, -1.2626e-01,  4.5503e-03, -2.9459e-01, -5.8939e-03,\n",
       "                      -3.8373e-01, -5.6037e-01,  3.4866e-02,  3.1893e-01, -2.0931e-01,\n",
       "                      -2.0145e-01,  1.0911e-01, -5.0676e-01, -2.3407e-01, -3.5233e-01,\n",
       "                       5.8368e-01, -9.6106e-02,  2.7722e-01,  3.1235e-01,  3.2995e-01,\n",
       "                      -8.7232e-01, -2.0826e-01,  9.7385e-01, -7.5372e-01,  1.7812e-01,\n",
       "                      -2.1819e-02,  2.2496e-01,  1.8242e-01, -7.1892e-01,  1.9084e-01,\n",
       "                      -1.2084e-01, -7.2754e-02, -4.3803e-01,  4.9714e-01,  4.4742e-02,\n",
       "                      -1.0326e-01,  2.1981e-01, -2.8776e-01,  4.7783e-01,  5.5958e-01,\n",
       "                      -1.4620e-01, -4.4376e-01, -1.2376e-01, -6.0745e-01,  3.0903e-01,\n",
       "                       3.0248e-01,  2.4880e-01,  7.7310e-02, -6.1010e-01,  4.9492e-01,\n",
       "                      -6.7272e-01,  2.1055e-02, -5.4117e-01, -2.7435e-01, -5.5878e-01,\n",
       "                       1.7410e-01, -9.9489e-01, -6.2579e-01,  4.1247e-01, -4.0167e-01,\n",
       "                      -5.3055e-01, -1.1576e-01,  4.0465e-01, -1.2104e+00,  7.7487e-01,\n",
       "                      -3.9591e-02,  5.1680e-02, -2.9713e-01,  1.4462e-01, -6.8375e-01,\n",
       "                      -1.1743e+00, -3.1629e-01, -9.1460e-02, -4.8765e-01,  2.9600e-02,\n",
       "                       2.2804e-01,  2.4009e-01,  2.1814e-01,  5.1391e-01, -1.2525e-01,\n",
       "                      -6.2995e-01,  4.2124e-01, -3.8586e-01,  4.9657e-01, -9.9526e-02,\n",
       "                      -4.5572e-01,  5.3212e-01,  1.8741e-01, -9.2406e-01,  6.5539e-01,\n",
       "                      -6.1138e-01,  5.0606e-01, -3.5116e-01,  2.7359e-01,  1.9763e-01,\n",
       "                      -7.8109e-01,  3.6819e-01, -1.2123e-01, -3.1045e-01,  2.2313e-01,\n",
       "                       4.0973e-02, -7.8646e-01,  1.0321e-01, -5.2278e-02,  3.5071e-01,\n",
       "                       1.5777e-01, -1.0944e+00,  7.9036e-01, -1.8253e-01, -2.8900e-01,\n",
       "                      -5.4339e-01, -2.0581e-01, -1.5371e-01, -2.9635e-01, -2.5579e-01,\n",
       "                      -2.1449e-01, -8.5544e-01, -1.1334e+00, -1.9659e-01, -3.1044e-01,\n",
       "                       2.0580e-01,  1.8268e-01,  6.6631e-02,  8.6860e-03,  9.5135e-01,\n",
       "                       7.2710e-01,  1.0589e-01, -6.6440e-02, -5.9910e-01, -1.9033e-01,\n",
       "                      -1.6018e-01, -4.8588e-01, -5.6403e-01, -2.4462e-01,  6.2520e-02,\n",
       "                      -7.5092e-02,  3.7008e-01,  3.7553e-01, -2.7125e-01, -3.3088e-02,\n",
       "                       4.6630e-02, -2.9288e-01,  4.4317e-01,  7.1446e-01,  3.5312e-02,\n",
       "                      -8.3721e-01,  5.3701e-01,  4.5248e-01, -7.1803e-01, -4.0240e-02,\n",
       "                       4.2080e-02, -1.6142e-02, -2.0847e-01,  3.6205e-02,  2.6513e-01,\n",
       "                       4.2098e-01, -1.7840e-01,  2.4755e-01,  6.1053e-01,  3.5275e-01,\n",
       "                       7.6969e-02, -7.3894e-01,  9.2809e-01, -1.7809e-01, -6.3399e-02,\n",
       "                       2.3813e-01,  3.3022e-01,  2.9696e-01, -3.3634e-01,  2.5587e-02,\n",
       "                      -3.7233e-01,  2.4642e-01,  2.9304e-01, -8.1295e-01,  9.6509e-02,\n",
       "                      -3.5536e-01, -2.1709e-01, -4.4076e-01, -3.9596e-01,  6.7524e-01,\n",
       "                      -5.2979e-01, -1.4058e+00,  4.2783e-01, -5.0562e-01, -5.6858e-01,\n",
       "                      -1.4697e-01,  3.8473e-01, -3.5195e-01,  5.4855e-01, -4.8147e-01,\n",
       "                       4.1686e-01,  5.5155e-01, -4.6697e-01, -1.2005e-01, -3.3290e-01,\n",
       "                      -3.2794e-01, -9.1197e-01, -5.8200e-02, -3.5870e-02, -4.5142e-02,\n",
       "                       2.7408e-01,  3.6101e-01,  4.6135e-01, -9.3148e-01, -1.2927e+00,\n",
       "                       2.6283e-01,  4.1932e-01, -2.5961e-01,  3.3856e-01,  3.9603e-01,\n",
       "                      -3.6384e-01,  4.6128e-01,  1.1765e-01, -7.6395e-01,  2.0759e-01,\n",
       "                       7.4159e-02, -5.4254e-01,  7.4855e-01, -4.2601e-01, -2.3427e-01,\n",
       "                       1.2819e-01,  4.2116e-01, -1.1371e+00, -4.1060e-01,  6.3936e-02,\n",
       "                       1.5847e-02, -1.0540e+00,  2.4246e-01, -2.6102e-01,  2.7147e-01,\n",
       "                       4.3185e-01,  6.1327e-01, -1.7582e-01, -9.4870e-02, -3.2369e-01,\n",
       "                       9.2605e-02, -5.4794e-01, -8.8334e-02,  7.8345e-02,  5.8442e-01,\n",
       "                       2.3870e-01, -3.4796e-01, -2.9277e-01, -3.5739e-01, -2.6493e-01,\n",
       "                       6.2923e-01, -6.9116e-02, -1.7207e-01, -8.3748e-02,  6.8497e-01,\n",
       "                      -3.1103e-01, -5.1670e-01, -6.4706e-01, -2.2070e-02, -2.2490e-01,\n",
       "                       8.0621e-01, -1.1913e-01,  9.9285e-02, -1.1686e-01,  3.3381e-01,\n",
       "                       5.0453e-01, -1.1132e+00,  6.1783e-02, -3.4046e-02, -2.2318e-01,\n",
       "                      -6.5623e-03, -3.0802e-01,  2.4815e-01, -1.0751e+00, -1.8312e-02,\n",
       "                      -3.8394e-01,  2.0147e-03,  9.8752e-02,  4.9422e-03,  2.9298e-01,\n",
       "                      -3.7525e-01,  3.0721e-01,  9.3278e-01,  3.2888e-01,  2.6613e-01,\n",
       "                       5.2356e-01,  3.1963e-01, -8.2171e-02, -2.4300e-01,  6.6327e-01,\n",
       "                      -1.4171e-02, -1.4543e-01,  7.9138e-01, -2.8457e-02, -1.4003e-01,\n",
       "                       3.0016e-02,  2.1099e-01, -3.1618e-01, -1.4536e-01,  6.8848e-02,\n",
       "                      -4.2679e-01, -8.7838e-01,  4.6130e-01, -2.3502e-01, -2.0483e-01,\n",
       "                      -2.5064e-01,  2.1026e-01, -1.5688e-01, -2.1569e-01, -3.1510e-01,\n",
       "                      -1.9186e-01,  5.6672e-01, -9.2514e-01, -5.3810e-01, -2.9389e-01,\n",
       "                       5.8550e-01,  3.8671e-01,  5.6804e-01,  3.6001e-02, -7.0191e-01,\n",
       "                       3.1716e-01,  5.5879e-01,  4.4546e-01, -1.2560e-01, -7.1420e-01,\n",
       "                      -7.3950e-01, -1.4285e-01,  1.1062e-01, -4.4822e-01, -8.0527e-01,\n",
       "                      -7.4891e-01,  5.8373e-02,  1.3535e-03, -2.8939e-01, -4.1997e-01,\n",
       "                       1.3887e-02, -2.8490e-01, -6.9018e-02,  1.4066e-01, -2.9810e-01,\n",
       "                      -3.6381e-01,  6.0695e-01,  6.4131e-01,  2.0128e-01,  2.7019e-02,\n",
       "                       3.0388e-01, -7.8964e-02, -5.8191e-01,  5.8745e-01,  6.9656e-01,\n",
       "                      -3.6201e-01,  4.2278e-02,  2.4278e-01, -7.9537e-02, -2.0016e-01,\n",
       "                       2.3212e-01,  4.6752e-01, -5.4904e-01,  8.9767e-02, -1.3908e-01,\n",
       "                      -7.3152e-02, -2.2394e-01, -5.9719e-01,  6.9107e-01,  8.7744e-02,\n",
       "                       1.5825e-01,  2.6350e-02,  3.5300e-01,  8.0580e-01,  6.7704e-02,\n",
       "                      -2.0898e-01,  1.0677e+00,  9.4470e-02,  1.0416e+00, -2.4624e-01,\n",
       "                       3.2781e-02, -2.0826e-01,  7.6352e-02,  6.4773e-01,  2.6066e-01,\n",
       "                      -8.9541e-01, -5.5474e-01, -4.8781e-01, -1.5715e-01, -8.7882e-01,\n",
       "                       1.3601e+00,  8.3260e-01, -3.1099e-01,  1.3716e-01,  8.6172e-02,\n",
       "                      -4.2042e-01,  8.4603e-01, -7.1450e-01, -5.0484e-01,  1.5661e-02,\n",
       "                       7.1470e-01,  7.6360e-02, -4.1062e-01,  1.0169e-01,  1.1870e-01,\n",
       "                       2.6568e-01,  2.0118e-01,  2.8871e-01,  2.0489e-01,  1.7190e-01,\n",
       "                       2.4620e-01, -6.2057e-01,  1.5176e-01, -4.5230e-01, -4.7096e-02,\n",
       "                      -1.1155e+00, -3.4777e-01,  1.8300e-01,  1.2895e-01,  1.2346e-01,\n",
       "                       4.3713e-02,  4.2699e-01,  3.2231e-02, -2.3741e-01, -2.0974e-01,\n",
       "                      -3.6299e-01, -5.9696e-01, -3.9551e-02, -4.3826e-01, -1.1011e+00,\n",
       "                      -4.9233e-01, -2.3281e-01, -2.5283e-01, -2.1074e-01, -6.6959e-01,\n",
       "                      -1.5231e-01, -1.6944e-01,  1.5992e-01,  1.4464e-01, -3.4366e-02,\n",
       "                      -3.4929e-01, -5.0557e-01, -1.7722e-01, -3.2099e-01, -1.5076e+00,\n",
       "                      -6.9292e-01, -1.3089e-01, -1.6393e-01, -8.8927e-01, -1.8381e-01,\n",
       "                       1.0946e-01,  9.3802e-02, -1.6203e-01, -3.2120e-01, -2.4528e-01,\n",
       "                      -5.6969e-01,  1.5061e-02, -1.6162e-01,  6.6561e-01,  4.4418e-01,\n",
       "                       3.5949e-02, -4.4436e-01, -6.9318e-01,  3.8601e-01,  1.2487e-01])),\n",
       "             ('BN2.running_var',\n",
       "              tensor([0.5621, 0.6354, 0.5883, 0.8985, 1.1337, 0.5753, 0.6050, 0.6102, 0.6108,\n",
       "                      0.4212, 0.8107, 0.4403, 0.5789, 0.5209, 0.7781, 1.0798, 0.7913, 0.9077,\n",
       "                      0.8270, 0.6112, 0.4623, 0.5291, 0.7217, 0.7175, 0.3682, 0.3175, 0.6965,\n",
       "                      0.5996, 0.8138, 0.4641, 0.6533, 0.5804, 0.3077, 0.3932, 0.8381, 0.7076,\n",
       "                      0.5363, 0.5214, 0.9366, 0.5345, 0.4937, 0.4571, 1.2804, 0.4698, 0.4114,\n",
       "                      0.4215, 0.6641, 1.0834, 1.0481, 0.4812, 0.7660, 0.6175, 0.3862, 0.4903,\n",
       "                      0.5681, 0.5875, 0.4812, 0.3049, 0.7157, 0.4781, 0.5636, 0.8249, 0.4085,\n",
       "                      0.7227, 0.5065, 0.7433, 0.4294, 0.3891, 1.4375, 0.5634, 1.1692, 0.4786,\n",
       "                      0.5267, 0.3947, 0.3364, 0.3599, 0.4721, 1.4110, 0.4112, 0.9512, 0.4611,\n",
       "                      0.8681, 0.5743, 0.6873, 0.5116, 0.4553, 0.6772, 0.4875, 0.3341, 0.7648,\n",
       "                      0.5330, 0.5021, 0.2793, 0.4533, 0.7906, 0.3997, 0.5822, 0.9520, 0.3153,\n",
       "                      0.5993, 0.6242, 0.6934, 0.7468, 0.4274, 0.4346, 0.2975, 0.5660, 0.5739,\n",
       "                      0.8528, 0.5179, 0.5258, 1.2915, 0.4995, 0.7620, 0.2308, 0.4348, 0.6825,\n",
       "                      1.0646, 0.4959, 0.5283, 0.3819, 0.7085, 0.2938, 0.3328, 0.6621, 0.6972,\n",
       "                      0.5308, 0.5449, 0.4185, 0.5441, 0.7435, 0.8402, 0.5198, 0.7727, 0.4889,\n",
       "                      1.0961, 0.4345, 1.9618, 0.6087, 0.7091, 0.7113, 0.6525, 0.4684, 0.6221,\n",
       "                      0.3739, 0.4513, 0.9787, 0.4043, 0.4434, 0.5521, 0.4042, 0.5501, 0.5206,\n",
       "                      0.6025, 0.8799, 0.8357, 0.6041, 0.5959, 0.4345, 1.2507, 0.7548, 0.2762,\n",
       "                      0.8201, 0.9344, 0.7377, 0.4058, 0.4990, 0.5826, 0.4966, 0.5119, 0.5499,\n",
       "                      0.6675, 0.4696, 0.9716, 0.8173, 0.4487, 0.6796, 0.5434, 1.2126, 0.6357,\n",
       "                      0.3137, 0.3892, 0.6576, 0.4632, 1.1386, 0.3937, 0.7928, 0.8422, 0.4008,\n",
       "                      0.8587, 1.3486, 0.3751, 0.4396, 0.4195, 0.4263, 0.5441, 0.6418, 0.8179,\n",
       "                      0.4585, 0.4251, 0.4502, 0.6313, 0.4316, 0.9405, 0.5632, 0.7831, 0.2557,\n",
       "                      0.2607, 0.9222, 0.6449, 0.3804, 1.2509, 0.2653, 0.5101, 0.5051, 0.9073,\n",
       "                      0.3992, 0.7867, 0.5231, 1.3069, 0.5353, 0.5378, 0.4046, 0.8107, 0.3430,\n",
       "                      0.5495, 0.7815, 0.5365, 0.5952, 0.6891, 0.8377, 1.4301, 1.1988, 0.4571,\n",
       "                      0.7478, 1.0419, 0.5066, 0.6304, 0.3623, 0.4591, 0.5592, 0.7741, 0.8362,\n",
       "                      0.5127, 0.3628, 0.5445, 0.8244, 0.6394, 1.0416, 0.6128, 0.6169, 0.7159,\n",
       "                      0.4939, 0.3227, 0.9467, 1.1187, 0.4458, 0.5350, 0.2011, 0.4598, 0.7192,\n",
       "                      0.3576, 0.4020, 0.5525, 0.3452, 0.4265, 0.5068, 0.4062, 0.7591, 0.2538,\n",
       "                      0.6292, 0.7647, 0.6133, 0.5319, 0.5249, 0.5231, 0.4798, 0.5354, 0.3200,\n",
       "                      0.7665, 1.0510, 0.7331, 0.7660, 0.5739, 0.6657, 1.1425, 0.3816, 0.4877,\n",
       "                      0.5773, 0.4451, 0.5697, 0.5327, 0.6293, 0.3194, 0.4023, 0.3397, 0.7183,\n",
       "                      0.7671, 0.9239, 1.3490, 0.3850, 0.8680, 0.8268, 0.4623, 0.3724, 0.5527,\n",
       "                      0.5655, 0.8607, 0.9114, 0.5449, 0.3320, 0.6647, 0.8333, 0.8106, 0.5114,\n",
       "                      0.7867, 0.2943, 0.4767, 0.4497, 0.9936, 0.4936, 0.3230, 0.6445, 0.8339,\n",
       "                      0.4957, 0.7674, 0.3757, 0.7766, 0.9442, 0.5256, 0.2427, 0.3324, 0.6926,\n",
       "                      0.6602, 0.7983, 0.3516, 0.4962, 0.3642, 0.3462, 0.4515, 0.9272, 0.4319,\n",
       "                      0.5123, 0.4206, 0.4661, 0.9919, 0.6821, 0.8429, 0.8050, 0.9855, 0.6364,\n",
       "                      0.3364, 0.3164, 0.7933, 1.0911, 0.6132, 0.8320, 0.4880, 0.6339, 0.7540,\n",
       "                      0.6212, 0.4639, 0.5112, 0.4130, 0.7651, 0.9201, 0.3341, 0.4112, 0.7404,\n",
       "                      0.4946, 1.0325, 0.4959, 0.3554, 0.6227, 0.4262, 0.6254, 0.3981, 0.4185,\n",
       "                      0.5499, 1.1422, 0.5814, 0.3901, 0.3842, 0.4514, 0.6867, 0.7404, 0.3370,\n",
       "                      0.5494, 0.8981, 0.5980, 0.8069, 1.1154, 0.7214, 0.5017, 0.5637, 0.4712,\n",
       "                      1.2094, 0.3601, 0.2973, 0.5142, 0.4222, 0.6531, 0.6529, 0.3504, 0.2852,\n",
       "                      0.8332, 0.3940, 0.8131, 0.6248, 0.7682, 0.5640, 0.3402, 0.3853, 0.4694,\n",
       "                      0.5357, 0.4681, 0.4016, 0.4801, 0.6177, 1.0408, 0.9914, 0.4074, 0.6121,\n",
       "                      0.6233, 0.4682, 0.5117, 0.4792, 0.6356, 0.5501, 0.8097, 0.8167, 0.6099,\n",
       "                      0.9405, 0.3770, 0.4801, 0.7167, 0.5517, 1.1219, 0.4289, 0.3320, 0.4212,\n",
       "                      0.6019, 0.4870, 0.6194, 0.4931, 0.8136, 0.5585, 1.0421, 0.4134, 0.6908,\n",
       "                      0.8907, 0.5239, 0.5109, 0.4383, 0.5855, 0.8081, 1.0060, 0.6599, 0.6210,\n",
       "                      0.7131, 0.4445, 0.5524, 0.6525, 0.6467, 0.6915, 0.3758, 0.3185, 0.3776,\n",
       "                      0.8970, 0.4525, 0.9162, 0.6905, 0.3636, 0.5137, 0.5186, 0.3143, 0.6464,\n",
       "                      0.6669, 0.6910, 1.3759, 0.6723, 0.6736, 0.7785, 0.8191, 0.7998, 0.7532,\n",
       "                      0.5405, 0.4668, 0.6070, 0.9366, 0.8055, 0.5069, 0.4550, 0.3395, 0.4795,\n",
       "                      0.4343, 1.1288, 0.3650, 0.7455, 0.5487])),\n",
       "             ('BN2.num_batches_tracked', tensor(600)),\n",
       "             ('enc_3.weight',\n",
       "              tensor([[ 0.0127,  0.0021, -0.0187,  ..., -0.0009, -0.0012,  0.0364],\n",
       "                      [-0.0399,  0.0377,  0.0293,  ..., -0.0023, -0.0092, -0.0218],\n",
       "                      [-0.0079, -0.0282, -0.0313,  ..., -0.0380, -0.0485,  0.0085],\n",
       "                      ...,\n",
       "                      [-0.0313,  0.0274, -0.0051,  ..., -0.0168,  0.0332,  0.0425],\n",
       "                      [-0.0329, -0.0314,  0.0463,  ...,  0.0284, -0.0046,  0.0282],\n",
       "                      [ 0.0287, -0.0363, -0.0436,  ...,  0.0076,  0.0181, -0.0307]])),\n",
       "             ('enc_3.bias',\n",
       "              tensor([ 0.0005, -0.0396,  0.0288,  ...,  0.0076, -0.0001, -0.0354])),\n",
       "             ('BN3.weight',\n",
       "              tensor([0.9840, 0.9986, 0.9851,  ..., 1.0061, 0.9961, 0.9973])),\n",
       "             ('BN3.bias',\n",
       "              tensor([-0.0102,  0.0044, -0.0115,  ...,  0.0057, -0.0084, -0.0038])),\n",
       "             ('BN3.running_mean',\n",
       "              tensor([-0.6040,  0.3834, -0.5650,  ...,  0.2059, -0.0859, -0.4377])),\n",
       "             ('BN3.running_var',\n",
       "              tensor([0.7953, 0.8767, 0.3583,  ..., 0.6933, 0.4207, 0.7497])),\n",
       "             ('BN3.num_batches_tracked', tensor(600)),\n",
       "             ('z_layer.weight',\n",
       "              tensor([[-0.0044,  0.0322,  0.0047,  ..., -0.0088,  0.0175, -0.0202],\n",
       "                      [ 0.0162,  0.0179, -0.0067,  ...,  0.0195, -0.0101, -0.0050],\n",
       "                      [ 0.0236,  0.0135,  0.0095,  ...,  0.0326,  0.0192,  0.0006],\n",
       "                      ...,\n",
       "                      [ 0.0069, -0.0119, -0.0144,  ...,  0.0036,  0.0188,  0.0055],\n",
       "                      [-0.0333,  0.0155, -0.0093,  ...,  0.0100, -0.0069,  0.0092],\n",
       "                      [ 0.0047,  0.0162,  0.0084,  ...,  0.0234,  0.0196, -0.0080]])),\n",
       "             ('z_layer.bias',\n",
       "              tensor([-0.0094,  0.0002, -0.0118,  0.0156, -0.0110, -0.0219,  0.0172,  0.0207,\n",
       "                       0.0031, -0.0045])),\n",
       "             ('dec_1.weight',\n",
       "              tensor([[ 0.1053, -0.2423, -0.1065,  ..., -0.1069, -0.2501,  0.2563],\n",
       "                      [ 0.1724, -0.2222, -0.1494,  ...,  0.1244, -0.1466, -0.2140],\n",
       "                      [ 0.2371, -0.1786, -0.1218,  ..., -0.2054, -0.2599,  0.1926],\n",
       "                      ...,\n",
       "                      [ 0.0367, -0.1337, -0.1592,  ..., -0.2151, -0.2091, -0.0316],\n",
       "                      [ 0.2377,  0.2649, -0.2146,  ...,  0.2099,  0.2302,  0.0137],\n",
       "                      [ 0.2878,  0.1693, -0.1764,  ...,  0.1405, -0.2371,  0.2101]])),\n",
       "             ('dec_1.bias',\n",
       "              tensor([ 0.0328, -0.0696,  0.3011,  ...,  0.2720,  0.0892, -0.0563])),\n",
       "             ('BN4.weight',\n",
       "              tensor([0.9684, 0.9795, 0.9791,  ..., 1.0127, 0.9853, 1.0043])),\n",
       "             ('BN4.bias',\n",
       "              tensor([-0.0605, -0.0645, -0.0749,  ..., -0.0663, -0.0896, -0.0697])),\n",
       "             ('BN4.running_mean',\n",
       "              tensor([-0.0989,  0.1314,  0.8788,  ..., -0.0100,  0.4759,  0.9736])),\n",
       "             ('BN4.running_var',\n",
       "              tensor([11.1815,  7.3309,  8.3973,  ...,  8.1779, 10.3991, 11.0808])),\n",
       "             ('BN4.num_batches_tracked', tensor(600)),\n",
       "             ('dec_2.weight',\n",
       "              tensor([[-0.0120, -0.0302,  0.0144,  ..., -0.0175, -0.0040, -0.0254],\n",
       "                      [-0.0067,  0.0015,  0.0068,  ..., -0.0073,  0.0090, -0.0015],\n",
       "                      [-0.0531,  0.0121, -0.0173,  ...,  0.0172, -0.0211, -0.0408],\n",
       "                      ...,\n",
       "                      [-0.0058, -0.0050, -0.0151,  ..., -0.0344,  0.0134, -0.0170],\n",
       "                      [ 0.0226, -0.0153,  0.0323,  ...,  0.0185,  0.0012,  0.0206],\n",
       "                      [ 0.0048, -0.0111, -0.0335,  ...,  0.0027, -0.0175, -0.0058]])),\n",
       "             ('dec_2.bias',\n",
       "              tensor([-9.6845e-03, -1.5158e-02, -5.3824e-04, -1.8768e-02,  6.9687e-03,\n",
       "                      -1.1741e-02,  1.7722e-02,  1.0426e-02,  2.2252e-04,  1.5181e-02,\n",
       "                       1.1857e-02,  6.6602e-03,  1.2410e-02, -2.1145e-02,  2.0431e-02,\n",
       "                       1.2348e-02,  1.9788e-02, -7.3204e-03, -6.8917e-03,  1.9975e-02,\n",
       "                      -1.9559e-02, -8.4177e-03,  2.3727e-03, -2.7399e-04, -8.1903e-03,\n",
       "                       1.7291e-02, -1.3442e-02, -8.2331e-03,  1.8122e-02,  8.6519e-03,\n",
       "                       5.7191e-03, -2.6283e-03, -1.2905e-02, -1.7556e-02,  1.1145e-03,\n",
       "                      -3.2342e-03, -1.8520e-02, -1.0331e-03, -1.6379e-02, -2.0270e-02,\n",
       "                       1.0860e-02, -1.8684e-02, -7.0546e-04, -2.0507e-02,  9.0161e-03,\n",
       "                      -2.0626e-02,  1.6128e-02,  4.0949e-03, -2.9520e-03, -1.6652e-02,\n",
       "                       7.9224e-03,  1.6869e-02, -1.5382e-02, -1.5374e-02, -1.9691e-02,\n",
       "                       2.0154e-03,  1.8050e-02, -2.2908e-03, -1.7659e-02,  1.5979e-02,\n",
       "                       1.5579e-02,  4.6681e-03,  8.6001e-03, -2.1686e-02,  2.2057e-02,\n",
       "                       1.9381e-02, -8.3368e-03, -4.5785e-03,  2.1098e-02, -2.2210e-02,\n",
       "                      -1.7371e-02, -9.4964e-03,  6.8287e-03, -2.0501e-02, -5.3085e-03,\n",
       "                      -9.8032e-03,  7.7360e-03, -3.8407e-03, -6.3863e-04,  8.2846e-03,\n",
       "                       1.9196e-02,  2.6222e-03,  6.5127e-03,  7.6634e-03, -3.4427e-03,\n",
       "                      -1.2192e-02, -1.6242e-02,  1.5633e-02,  3.1186e-03,  5.7309e-03,\n",
       "                       2.0556e-02,  1.6757e-02, -1.8253e-02,  1.7013e-02, -8.5821e-03,\n",
       "                      -4.7980e-03,  7.8402e-03, -6.5923e-03, -4.7510e-04, -8.1346e-03,\n",
       "                       2.0794e-02, -1.5429e-02, -5.1817e-03, -1.4543e-02, -2.1583e-02,\n",
       "                      -1.2299e-03, -4.9890e-03, -1.4345e-02,  1.1669e-02,  1.2845e-02,\n",
       "                      -7.4331e-03, -1.7375e-02,  1.6993e-02, -5.3980e-03,  1.1117e-02,\n",
       "                      -1.6572e-02, -2.1436e-02, -2.1110e-02, -2.1854e-02,  1.1253e-02,\n",
       "                      -2.0475e-02, -9.7781e-03,  2.7674e-03,  3.9880e-04, -9.2610e-03,\n",
       "                      -1.9862e-02, -2.0415e-02,  7.0864e-03,  2.1539e-02,  1.0007e-02,\n",
       "                      -1.0374e-02, -7.2572e-03,  2.0899e-02,  1.3628e-02,  9.6518e-03,\n",
       "                       1.7069e-02, -8.0069e-03, -1.5220e-02,  1.2830e-02,  1.4082e-02,\n",
       "                       4.2852e-03,  1.2970e-02,  1.5179e-02, -1.1524e-02, -1.8431e-02,\n",
       "                       1.8315e-02,  1.6371e-02,  1.2274e-03,  8.0524e-03, -4.3087e-03,\n",
       "                      -6.9320e-03, -4.0972e-03, -2.0174e-02, -2.1892e-02, -2.3949e-03,\n",
       "                      -1.6521e-02, -7.8786e-03, -2.1361e-02, -1.6815e-02,  1.1454e-02,\n",
       "                      -9.4907e-03,  2.0602e-02,  6.5912e-03,  1.3069e-02, -1.3551e-02,\n",
       "                       1.0886e-03,  1.5519e-02, -2.0987e-02, -2.3228e-03,  8.3364e-03,\n",
       "                       2.8071e-03,  7.3603e-03,  1.5336e-03, -3.5553e-04,  2.1129e-02,\n",
       "                      -1.3357e-02, -1.5585e-02,  1.4355e-02,  7.2974e-03, -9.3723e-03,\n",
       "                      -5.0954e-03,  1.2452e-02, -1.3510e-02,  3.1131e-03, -8.5242e-03,\n",
       "                      -1.6162e-04,  8.1044e-03,  3.6802e-03, -1.7446e-02,  2.8010e-03,\n",
       "                      -3.7269e-03, -3.7851e-03, -1.2151e-02,  3.1426e-03,  1.8572e-02,\n",
       "                       2.8211e-03,  6.1786e-03, -2.0314e-02,  5.6284e-03,  7.4339e-03,\n",
       "                      -2.0712e-02,  6.4341e-03,  7.2349e-03, -4.3799e-03, -9.8449e-03,\n",
       "                       4.1061e-03,  1.4284e-02,  1.6771e-03,  5.6823e-03, -1.0917e-02,\n",
       "                      -5.1879e-03,  1.3426e-02, -2.0850e-03,  1.8336e-02, -7.0267e-03,\n",
       "                       7.6849e-03,  4.7710e-03,  2.5556e-04, -1.0388e-02, -8.9363e-03,\n",
       "                       1.8858e-02, -3.7631e-03,  7.7994e-03,  5.2097e-03,  1.4912e-02,\n",
       "                       7.5326e-03,  1.9054e-02, -7.5646e-03, -1.0388e-02,  2.1880e-02,\n",
       "                       2.0646e-04, -1.5577e-02,  3.8607e-04, -1.0269e-03, -2.0993e-02,\n",
       "                      -2.6735e-03, -6.0918e-04, -9.5403e-03,  7.4941e-03, -1.1558e-04,\n",
       "                      -7.0771e-03, -8.7518e-03,  6.4392e-03, -1.0234e-02, -2.2033e-02,\n",
       "                       1.5859e-02, -1.4240e-02, -7.0648e-03,  1.7735e-02,  7.7536e-03,\n",
       "                       2.1151e-02, -4.0468e-03,  8.6660e-03, -1.9883e-02, -5.9851e-03,\n",
       "                       7.6571e-03,  1.2387e-03,  1.5972e-02, -1.9947e-02, -9.3802e-03,\n",
       "                      -2.3395e-04, -1.4386e-02, -1.2522e-02, -7.8776e-04, -5.5171e-03,\n",
       "                      -1.3034e-02,  1.8948e-02,  7.3915e-03, -1.2470e-02, -1.2410e-02,\n",
       "                       1.2023e-04, -1.1695e-02,  1.8937e-03,  1.0188e-03, -1.2319e-02,\n",
       "                       1.7232e-02, -6.9586e-03,  1.8725e-02,  1.4088e-02, -3.5323e-04,\n",
       "                      -1.0899e-02,  4.9869e-03,  2.1561e-02, -4.1196e-03,  1.7406e-02,\n",
       "                      -2.4006e-03, -1.5086e-02,  2.0115e-02,  8.4789e-03, -4.7090e-03,\n",
       "                       1.1811e-02, -1.6752e-02,  5.8356e-03,  2.2300e-02, -2.1399e-02,\n",
       "                       2.0618e-02, -4.7576e-03,  1.7382e-02,  1.8987e-02, -1.0490e-02,\n",
       "                      -6.3912e-03, -1.4603e-02,  9.3864e-03, -7.2226e-03,  1.0582e-02,\n",
       "                      -1.0974e-02, -5.2878e-03,  1.1068e-03, -1.3024e-02, -1.2834e-02,\n",
       "                       4.0631e-04, -6.8979e-03, -1.9290e-02,  2.1184e-02,  7.1974e-03,\n",
       "                       5.0271e-03,  1.1900e-02, -6.3544e-03,  6.4941e-04,  3.6633e-03,\n",
       "                       1.1591e-03, -7.8707e-03, -1.6641e-02, -8.8909e-03, -1.0490e-02,\n",
       "                      -5.7213e-03, -1.0628e-03, -1.8320e-02, -4.2803e-03, -1.4856e-02,\n",
       "                      -2.2561e-03, -6.5415e-04,  1.0016e-02, -5.2167e-03, -1.6099e-02,\n",
       "                      -6.9396e-03,  8.3455e-03, -1.3925e-02, -8.5486e-03,  1.4164e-02,\n",
       "                      -1.9186e-02,  3.4030e-03, -3.2693e-03,  9.5961e-03,  3.5814e-03,\n",
       "                      -1.8319e-02, -2.0100e-02, -1.2937e-02,  2.1142e-02, -9.0240e-03,\n",
       "                       1.5020e-02, -7.4085e-04,  1.0928e-02, -7.5496e-03,  8.3806e-03,\n",
       "                      -1.0160e-02,  1.7069e-03,  2.1829e-02,  1.2482e-02, -1.0824e-02,\n",
       "                       6.4037e-03,  9.6882e-03, -1.2041e-02, -5.3880e-03,  8.3127e-03,\n",
       "                       2.0732e-02,  1.1299e-02,  1.9823e-02,  1.2451e-02, -1.5554e-02,\n",
       "                       1.8453e-02, -1.3825e-02,  2.2167e-02, -1.3521e-02,  4.8511e-03,\n",
       "                      -1.3182e-02,  1.4662e-02, -1.9230e-02, -1.1482e-03, -9.4180e-03,\n",
       "                      -3.5491e-03,  1.3450e-02, -1.8597e-02, -1.0412e-04,  1.6777e-02,\n",
       "                       1.5383e-02, -9.2302e-03,  1.6583e-03,  1.0660e-02,  1.0885e-02,\n",
       "                       2.4495e-03,  1.1095e-02,  1.2791e-02, -1.0500e-02,  7.5549e-05,\n",
       "                      -7.8828e-03,  1.3749e-02, -1.0501e-02, -1.9018e-02, -1.9434e-02,\n",
       "                      -2.1204e-02,  1.4736e-02, -1.7880e-02,  1.7298e-02, -1.6782e-02,\n",
       "                       6.6304e-03,  7.3204e-03, -4.2529e-03,  5.7571e-03,  4.9612e-03,\n",
       "                       1.9269e-02, -1.9740e-02, -1.5436e-02,  7.6991e-03,  1.1200e-02,\n",
       "                       1.6840e-02, -1.3710e-02, -1.4294e-02, -2.1056e-02, -6.3091e-03,\n",
       "                       1.6369e-02, -1.6559e-02,  2.1970e-02, -4.1214e-03,  1.1632e-02,\n",
       "                      -1.0198e-02, -2.1269e-02,  5.9778e-03, -1.9436e-02,  1.7140e-02,\n",
       "                       1.0994e-02, -9.3608e-04,  1.8819e-02,  2.0764e-02, -4.3208e-03,\n",
       "                       1.9155e-02, -1.8077e-02, -5.7437e-03,  1.5834e-02, -2.0205e-02,\n",
       "                      -6.9626e-04, -1.9559e-03, -1.6524e-02,  4.9452e-03,  2.2282e-02,\n",
       "                      -1.0986e-02, -3.0114e-03, -1.5504e-02,  1.8100e-02, -1.3015e-02,\n",
       "                       4.4961e-03,  1.3931e-02,  1.6400e-02,  4.3524e-03, -1.8228e-02,\n",
       "                       7.0304e-03, -2.9578e-03, -2.1233e-02, -1.2710e-02,  4.0179e-03,\n",
       "                      -1.9871e-02, -1.4592e-02,  1.6581e-02, -1.0613e-02,  1.6855e-02,\n",
       "                      -7.5689e-03, -7.6008e-03, -8.8312e-03, -2.2086e-02,  1.1102e-02,\n",
       "                       2.1572e-02,  1.7378e-02,  1.4326e-03,  1.1439e-02,  5.6980e-03,\n",
       "                      -1.2369e-02, -6.9833e-03,  2.0169e-02, -1.1446e-02, -1.9079e-02,\n",
       "                      -6.6864e-03, -9.2722e-03,  1.9348e-02, -2.0026e-02, -1.5717e-02,\n",
       "                       1.0839e-02,  2.0644e-02,  7.2971e-03, -1.1483e-02,  5.7715e-03,\n",
       "                       1.0534e-02, -1.6105e-02,  2.2193e-02, -1.9310e-02,  8.9682e-03,\n",
       "                       1.8010e-02, -1.7917e-02,  3.6511e-03, -1.3888e-02,  1.1182e-02])),\n",
       "             ('BN5.weight',\n",
       "              tensor([1.0231, 0.9983, 0.9849, 1.0454, 0.9968, 1.0437, 0.9688, 0.9741, 0.9874,\n",
       "                      1.0066, 1.0213, 0.9850, 1.0356, 0.9840, 1.0032, 1.0282, 1.0252, 0.9694,\n",
       "                      0.9971, 1.0267, 0.9774, 0.9867, 1.0179, 1.0061, 0.9989, 0.9942, 1.0085,\n",
       "                      0.9910, 1.0136, 1.0624, 1.0143, 1.0059, 1.0035, 0.9861, 1.0351, 1.0085,\n",
       "                      1.0111, 0.9909, 1.0617, 1.0124, 0.9849, 0.9786, 1.0529, 0.9972, 0.9835,\n",
       "                      0.9836, 1.0011, 0.9801, 1.0092, 1.0000, 1.0094, 1.0296, 0.9863, 0.9723,\n",
       "                      0.9583, 0.9863, 0.9955, 1.0053, 1.0137, 1.0552, 0.9525, 0.9862, 0.9843,\n",
       "                      0.9921, 0.9931, 0.9929, 1.0061, 1.0136, 1.0061, 1.0115, 0.9768, 1.0107,\n",
       "                      1.0007, 0.9899, 0.9931, 1.0203, 0.9983, 0.9839, 0.9804, 0.9970, 0.9972,\n",
       "                      1.0032, 0.9978, 1.0326, 0.9603, 1.0114, 0.9965, 0.9957, 0.9753, 0.9765,\n",
       "                      1.0110, 0.9812, 1.0255, 1.0045, 1.0031, 1.0029, 0.9767, 0.9909, 1.0060,\n",
       "                      0.9710, 1.0037, 0.9925, 1.0221, 0.9942, 0.9830, 0.9804, 1.0357, 1.0102,\n",
       "                      1.0440, 0.9949, 0.9870, 1.0012, 0.9602, 1.0202, 1.0221, 0.9978, 0.9894,\n",
       "                      1.0058, 1.0463, 0.9758, 0.9835, 0.9905, 1.0367, 1.0005, 0.9984, 1.0118,\n",
       "                      0.9768, 1.0409, 0.9975, 1.0175, 0.9951, 0.9992, 1.0041, 1.0145, 1.0080,\n",
       "                      0.9957, 0.9881, 1.0217, 0.9920, 1.0234, 0.9704, 0.9809, 0.9888, 0.9787,\n",
       "                      0.9857, 0.9978, 0.9803, 0.9840, 0.9838, 1.0077, 1.0046, 1.0194, 1.0295,\n",
       "                      0.9905, 0.9954, 1.0057, 1.0114, 0.9942, 0.9963, 1.0115, 1.0258, 1.0264,\n",
       "                      1.0186, 1.0141, 0.9793, 1.0249, 0.9708, 1.0163, 0.9794, 1.0338, 0.9929,\n",
       "                      1.0194, 0.9582, 1.0384, 1.0065, 1.0208, 0.9941, 0.9936, 0.9802, 1.0026,\n",
       "                      1.0249, 1.0235, 0.9744, 1.0186, 1.0061, 1.0144, 1.0164, 1.0120, 0.9978,\n",
       "                      1.0007, 0.9829, 1.0010, 1.0178, 1.0153, 0.9980, 1.0271, 0.9833, 0.9927,\n",
       "                      0.9880, 1.0196, 0.9782, 0.9974, 0.9994, 0.9970, 1.0103, 1.0095, 0.9877,\n",
       "                      0.9923, 1.0140, 1.0580, 0.9937, 1.0442, 0.9891, 1.0397, 0.9730, 1.0280,\n",
       "                      1.0267, 0.9817, 1.0120, 1.0012, 0.9961, 1.0019, 1.0432, 0.9823, 0.9941,\n",
       "                      1.0168, 1.0133, 1.0132, 1.0086, 1.0013, 1.0023, 0.9933, 0.9974, 1.0196,\n",
       "                      1.0061, 1.0250, 0.9655, 0.9845, 1.0215, 0.9882, 0.9927, 0.9900, 0.9579,\n",
       "                      1.0024, 0.9981, 1.0379, 0.9767, 0.9874, 1.0318, 0.9893, 1.0132, 0.9981,\n",
       "                      0.9917, 0.9940, 0.9916, 1.0025, 0.9915, 0.9553, 1.0295, 0.9981, 0.9829,\n",
       "                      0.9865, 1.0178, 0.9751, 0.9977, 0.9992, 0.9824, 0.9617, 0.9654, 1.0194,\n",
       "                      1.0068, 1.0206, 0.9646, 0.9983, 1.0606, 0.9669, 0.9865, 1.0297, 1.0085,\n",
       "                      0.9879, 1.0158, 0.9850, 0.9825, 1.0188, 1.0009, 0.9764, 0.9936, 1.0348,\n",
       "                      0.9788, 0.9777, 1.0365, 0.9989, 0.9933, 0.9617, 1.0062, 0.9563, 1.0470,\n",
       "                      1.0010, 1.0077, 0.9875, 1.0144, 0.9947, 1.0206, 0.9888, 1.0144, 0.9932,\n",
       "                      1.0089, 1.0183, 1.0081, 1.0291, 1.0082, 1.0035, 1.0185, 1.0028, 0.9954,\n",
       "                      0.9936, 0.9948, 0.9858, 1.0093, 0.9996, 1.0128, 0.9886, 1.0642, 1.0002,\n",
       "                      0.9625, 0.9877, 1.0243, 0.9657, 1.0430, 0.9868, 0.9613, 1.0051, 0.9678,\n",
       "                      0.9739, 0.9723, 0.9814, 1.0162, 0.9987, 1.0375, 0.9988, 0.9722, 1.0055,\n",
       "                      1.0217, 0.9745, 0.9654, 0.9664, 1.0085, 1.0055, 1.0136, 0.9911, 1.0024,\n",
       "                      0.9971, 0.9960, 0.9695, 1.0040, 0.9945, 0.9888, 0.9970, 0.9532, 1.0130,\n",
       "                      1.0046, 0.9967, 1.0080, 0.9955, 1.0272, 1.0050, 1.0530, 0.9983, 1.0192,\n",
       "                      0.9847, 1.0278, 1.0064, 0.9808, 1.0226, 0.9968, 1.0056, 1.0129, 1.0118,\n",
       "                      1.0563, 1.0008, 0.9949, 1.0426, 1.0028, 1.0018, 0.9968, 1.0186, 1.0027,\n",
       "                      1.0006, 0.9728, 1.0225, 1.0306, 1.0059, 1.0251, 0.9775, 0.9867, 1.0407,\n",
       "                      1.0241, 1.0038, 0.9972, 1.0087, 1.0573, 1.0160, 1.0145, 1.0370, 0.9561,\n",
       "                      0.9840, 0.9897, 1.0414, 0.9801, 1.0712, 1.0436, 0.9845, 1.0200, 0.9846,\n",
       "                      1.0172, 1.0266, 1.0216, 0.9955, 0.9861, 0.9595, 1.0047, 1.0059, 0.9784,\n",
       "                      0.9964, 0.9857, 1.0303, 0.9829, 0.9965, 0.9943, 0.9900, 1.0009, 1.0481,\n",
       "                      1.0196, 0.9492, 1.0210, 1.0431, 1.0062, 1.0049, 1.0056, 0.9904, 0.9582,\n",
       "                      0.9813, 1.0004, 0.9953, 1.0021, 0.9817, 1.0439, 0.9958, 1.0347, 0.9912,\n",
       "                      1.0137, 1.0082, 0.9542, 0.9621, 0.9546, 1.0272, 1.0576, 0.9817, 1.0319,\n",
       "                      0.9633, 1.0126, 1.0013, 1.0014, 0.9999, 1.0562, 1.0409, 1.0288, 0.9958,\n",
       "                      0.9821, 1.0109, 0.9841, 1.0408, 0.9780, 1.0216, 1.0244, 1.0038, 1.0102,\n",
       "                      1.0448, 1.0421, 1.0352, 0.9926, 1.0225, 0.9908, 0.9715, 1.0010, 0.9870,\n",
       "                      1.0212, 0.9623, 0.9924, 1.0542, 1.0020, 1.0248, 1.0208, 1.0392, 1.0134,\n",
       "                      1.0008, 0.9794, 1.0453, 1.0144, 0.9961])),\n",
       "             ('BN5.bias',\n",
       "              tensor([ 0.0197, -0.0691, -0.0506,  0.0156, -0.0112,  0.0110, -0.0843, -0.0959,\n",
       "                      -0.1275,  0.0108,  0.0126, -0.0610, -0.0359, -0.0842, -0.0719, -0.0479,\n",
       "                       0.0385, -0.1679, -0.0742, -0.0756, -0.0688, -0.0539, -0.0340, -0.0163,\n",
       "                      -0.0593, -0.0762, -0.0590, -0.0689, -0.0685, -0.0153, -0.0295, -0.0525,\n",
       "                      -0.0636, -0.0696, -0.0328, -0.0411,  0.0060, -0.0660,  0.0638, -0.0501,\n",
       "                      -0.1178, -0.1645, -0.0322, -0.0844, -0.1565, -0.0330, -0.0572, -0.0709,\n",
       "                       0.0137, -0.0369, -0.0836,  0.0609, -0.0574, -0.1195, -0.1189, -0.0448,\n",
       "                      -0.0640, -0.0642, -0.0303,  0.0112, -0.1461, -0.0267, -0.0839, -0.0175,\n",
       "                      -0.0532, -0.0490, -0.0149, -0.0167, -0.0574, -0.0020, -0.0909, -0.0451,\n",
       "                      -0.0243, -0.0860, -0.1108, -0.0062, -0.0427, -0.1710, -0.0705, -0.0658,\n",
       "                      -0.0541, -0.0681, -0.0549, -0.0230, -0.1553, -0.0059, -0.0683, -0.0041,\n",
       "                      -0.0704, -0.1238, -0.0211, -0.1320, -0.0290, -0.0452, -0.0011, -0.0284,\n",
       "                      -0.0996, -0.0988, -0.0335, -0.0559, -0.0619, -0.1276,  0.0341, -0.0443,\n",
       "                      -0.0393, -0.0451,  0.0684, -0.0555,  0.0118, -0.0676, -0.0580, -0.0652,\n",
       "                      -0.1635, -0.0558, -0.0038, -0.0845, -0.0438, -0.0887,  0.0242, -0.0994,\n",
       "                      -0.0497, -0.0437, -0.0517, -0.0018, -0.0781, -0.0857, -0.0647, -0.0254,\n",
       "                      -0.0452, -0.0480, -0.0441, -0.0391, -0.0364, -0.0183, -0.0585, -0.0689,\n",
       "                      -0.0389, -0.0650, -0.0202,  0.0252, -0.1097, -0.0353, -0.0290, -0.1275,\n",
       "                      -0.0437, -0.0049, -0.1131, -0.0793, -0.1288, -0.0817, -0.0160, -0.0060,\n",
       "                      -0.0420, -0.0984, -0.0563, -0.0106, -0.0519, -0.0737, -0.0729, -0.0244,\n",
       "                      -0.0515, -0.0039,  0.0440,  0.0134, -0.0766, -0.0512, -0.1560,  0.0160,\n",
       "                      -0.0543,  0.0199, -0.1032, -0.0042, -0.1067, -0.0541, -0.0519, -0.0034,\n",
       "                      -0.1297, -0.0805, -0.0738, -0.0547,  0.0097,  0.0484, -0.0975, -0.0201,\n",
       "                      -0.0632, -0.0211, -0.0311, -0.0044, -0.0271, -0.0326, -0.1082, -0.0322,\n",
       "                      -0.0044, -0.0095, -0.0490, -0.0252, -0.0482, -0.0525, -0.0422, -0.0585,\n",
       "                      -0.1021, -0.0069,  0.0063, -0.0551, -0.0374, -0.0133, -0.0603, -0.0853,\n",
       "                      -0.0189, -0.0522, -0.0586,  0.0271, -0.0852, -0.0297, -0.1732, -0.0068,\n",
       "                       0.0333, -0.0525, -0.0242, -0.0207, -0.0756, -0.0256, -0.0062, -0.0763,\n",
       "                      -0.0706, -0.0094, -0.0770, -0.0087, -0.0030, -0.0455, -0.0598, -0.0263,\n",
       "                      -0.1078, -0.0141, -0.0696,  0.0058, -0.0461, -0.0509, -0.1004, -0.0989,\n",
       "                      -0.0754, -0.1048, -0.1214, -0.0713, -0.0287, -0.0145, -0.0214, -0.0931,\n",
       "                      -0.0251, -0.0633, -0.0183, -0.0672, -0.0995, -0.0648, -0.0266, -0.0623,\n",
       "                      -0.1159, -0.1102, -0.0704, -0.1270, -0.0641, -0.0183,  0.0316, -0.1060,\n",
       "                      -0.1042, -0.0955, -0.0305, -0.0577, -0.1064, -0.0451, -0.0243, -0.0437,\n",
       "                      -0.0774, -0.0547,  0.0090, -0.0745, -0.0450, -0.0353, -0.0902, -0.0436,\n",
       "                      -0.0513, -0.1109, -0.1550, -0.0512, -0.0866, -0.0471, -0.0639,  0.0033,\n",
       "                      -0.1045, -0.0368, -0.0263, -0.0455, -0.0607, -0.1815, -0.0264, -0.0913,\n",
       "                      -0.0652, -0.1101, -0.1246, -0.0519, -0.0016, -0.0855, -0.0494, -0.0552,\n",
       "                      -0.0767, -0.0234, -0.0153, -0.0398, -0.0171, -0.0190, -0.1401, -0.0425,\n",
       "                      -0.0601, -0.0913, -0.1059, -0.0648, -0.0540, -0.0710, -0.0243, -0.0490,\n",
       "                      -0.0010, -0.0677,  0.0142, -0.0267, -0.1101, -0.1075, -0.0083, -0.1161,\n",
       "                       0.0126, -0.0621, -0.1013, -0.0290, -0.1273, -0.0789, -0.1359, -0.0353,\n",
       "                       0.0231, -0.0155, -0.0583, -0.0663, -0.1057, -0.0356, -0.0315, -0.1066,\n",
       "                      -0.1080, -0.1362,  0.0010, -0.0376, -0.0343, -0.0394, -0.0759, -0.1074,\n",
       "                      -0.0712, -0.1077, -0.0798, -0.1111, -0.1110, -0.0380, -0.1080, -0.0582,\n",
       "                      -0.0348,  0.0221, -0.0895, -0.1090, -0.0424, -0.0625,  0.0640, -0.0901,\n",
       "                      -0.0693, -0.0834,  0.0263, -0.0522, -0.0873, -0.0207, -0.0878, -0.0655,\n",
       "                      -0.0574, -0.0662,  0.0417, -0.0430, -0.1240,  0.0163, -0.0748, -0.1083,\n",
       "                      -0.0720,  0.0252, -0.0023, -0.0416, -0.0766, -0.0398, -0.0085, -0.0272,\n",
       "                       0.0029, -0.0571, -0.0443, -0.0357, -0.0350, -0.0508, -0.0505, -0.0737,\n",
       "                      -0.0462, -0.0449, -0.0464,  0.0199, -0.1215, -0.0720, -0.0411, -0.0129,\n",
       "                      -0.0532, -0.0084, -0.0803, -0.0899, -0.0347, -0.0847, -0.0315, -0.0276,\n",
       "                      -0.0388, -0.0582, -0.0459, -0.0995, -0.0536, -0.0207, -0.0910, -0.0489,\n",
       "                       0.0095, -0.0456, -0.1039, -0.0707, -0.0647, -0.0339, -0.1332, -0.0302,\n",
       "                      -0.0650, -0.1142, -0.0373, -0.0210, -0.0135, -0.0056, -0.1045, -0.0662,\n",
       "                      -0.0917, -0.0514, -0.0740, -0.0774, -0.0478, -0.0919,  0.0679, -0.0500,\n",
       "                      -0.0621, -0.0267, -0.0641, -0.0216, -0.1643, -0.1115, -0.0629, -0.0448,\n",
       "                      -0.0306, -0.1088,  0.0031, -0.1160, -0.0372, -0.0497, -0.0708, -0.0255,\n",
       "                      -0.0292, -0.0729,  0.0134, -0.0370, -0.0802, -0.0460, -0.0840,  0.0082,\n",
       "                      -0.1193, -0.0061, -0.0186, -0.0754, -0.0606,  0.0163, -0.0303,  0.0015,\n",
       "                      -0.1402, -0.0151, -0.1395, -0.0828, -0.0505, -0.1074, -0.0133, -0.0961,\n",
       "                       0.0038, -0.0256, -0.0472, -0.0767, -0.0361,  0.0870, -0.0417, -0.0587,\n",
       "                      -0.0782, -0.0618, -0.0701, -0.0422])),\n",
       "             ('BN5.running_mean',\n",
       "              tensor([-1.1854e+00, -1.3689e+00, -1.8814e+00, -1.2821e+00, -1.1347e+00,\n",
       "                      -1.0212e+00,  2.1067e+00,  2.4664e+00,  1.4129e+00, -2.8923e+00,\n",
       "                      -1.1286e+00,  1.0441e+00, -6.2920e-01, -9.5274e-01,  6.7381e-01,\n",
       "                      -1.2713e+00, -2.6338e+00,  2.1820e+00, -8.6521e-01, -1.2749e+00,\n",
       "                       2.7942e+00,  4.6171e-01, -3.1299e-01, -2.7428e+00, -8.0271e-02,\n",
       "                      -1.2518e+00, -9.8479e-01,  1.2004e+00, -2.5460e-01, -2.2010e+00,\n",
       "                      -6.8651e-01, -1.6976e+00,  1.1316e+00, -3.5927e-02,  2.6148e-01,\n",
       "                      -1.5669e+00, -2.6740e+00, -2.1586e+00, -1.8494e+00,  3.5507e-01,\n",
       "                       1.1050e+00,  1.3019e+00, -1.9551e+00,  6.9393e-01,  2.4156e+00,\n",
       "                      -1.1527e+00,  1.0882e+00, -1.7893e-01, -2.1445e+00, -7.8725e-01,\n",
       "                      -4.2611e-01, -3.2703e+00, -1.0110e+00,  1.9791e+00,  1.0332e+00,\n",
       "                       3.3848e-01,  3.0303e-03,  3.2552e-01, -1.9672e+00, -3.1996e+00,\n",
       "                       2.8209e+00, -1.9227e+00,  3.8524e-01, -1.1026e+00, -8.1736e-02,\n",
       "                      -8.8420e-01, -2.4245e+00, -1.3816e+00, -1.2257e+00, -1.9084e+00,\n",
       "                       1.3022e-01, -6.9112e-01,  8.4426e-01,  6.0350e-01, -6.6208e-02,\n",
       "                      -1.1506e+00, -1.8293e-01,  2.5205e+00,  1.0602e+00, -9.6464e-02,\n",
       "                      -1.0328e-01, -4.6164e-01, -1.2712e-01, -1.3114e+00,  2.1700e+00,\n",
       "                      -3.7127e-01, -6.8846e-01, -7.7911e-01, -6.5954e-01,  8.5348e-01,\n",
       "                       1.0528e+00,  1.5228e+00, -3.7483e-01,  9.0096e-01, -2.8202e+00,\n",
       "                       1.3953e-01,  4.2201e-01,  1.0182e+00, -1.2932e+00,  9.4702e-01,\n",
       "                       8.9516e-01,  1.6987e+00, -2.1235e+00, -1.5119e+00, -1.5135e+00,\n",
       "                      -2.2741e+00, -2.3708e+00,  1.8208e+00, -2.7922e+00, -3.7196e-01,\n",
       "                      -2.0830e-01, -2.7148e-01,  1.0722e+00, -1.4246e+00, -1.9532e+00,\n",
       "                       8.2539e-01, -1.7928e+00,  4.4377e-01, -2.9426e+00,  2.6766e+00,\n",
       "                       1.0291e+00,  9.1953e-01, -4.9215e-01, -1.6062e+00,  1.6816e-01,\n",
       "                      -7.1963e-01, -3.9747e-01, -8.4374e-01, -1.6148e+00,  3.9337e-01,\n",
       "                      -1.2179e-01, -1.4880e+00, -8.3151e-01, -5.4599e-01,  6.7103e-01,\n",
       "                      -8.2213e-01,  8.2347e-01,  1.2038e+00,  8.8622e-02, -1.6120e+00,\n",
       "                       1.4051e+00, -1.8953e+00, -2.0740e+00,  1.4318e+00, -7.2416e-01,\n",
       "                      -2.4771e+00,  2.5809e+00,  1.0108e+00,  1.5981e+00, -8.2689e-01,\n",
       "                      -2.5042e+00, -1.1895e+00, -1.0548e+00,  2.7818e-01,  5.4580e-01,\n",
       "                      -3.0894e+00,  2.6501e-01, -1.5136e-02, -1.3326e+00, -2.3887e+00,\n",
       "                      -1.0542e+00, -2.0601e+00, -2.6105e+00, -2.9770e+00,  9.3934e-01,\n",
       "                       6.7495e-01,  2.0371e+00, -2.4098e+00, -3.5848e-02, -9.5201e-01,\n",
       "                       1.5293e+00, -2.7762e+00,  1.5549e+00, -1.3174e+00, -1.5058e+00,\n",
       "                      -2.8404e+00,  1.4486e+00,  7.1712e-01,  3.0698e-01,  1.5279e-01,\n",
       "                      -3.1217e+00, -2.3522e+00,  1.7176e+00, -1.0792e+00, -2.4675e+00,\n",
       "                      -1.1031e+00, -4.0528e-01, -1.0373e+00,  8.2152e-01, -9.0759e-01,\n",
       "                       1.1656e+00, -1.0622e+00, -1.2619e+00, -1.4782e+00, -1.7190e+00,\n",
       "                      -2.6662e+00, -4.0443e-01, -4.6446e-01, -1.5819e+00, -2.0061e+00,\n",
       "                      -7.4697e-02, -2.1811e+00, -2.7390e+00, -2.4510e+00, -8.9270e-01,\n",
       "                       4.7987e-01,  9.3708e-01, -5.5641e-02, -1.7661e+00, -2.8070e+00,\n",
       "                      -8.3162e-01,  3.0754e-01,  8.1897e-01, -1.7018e+00,  2.4763e+00,\n",
       "                      -1.8815e+00, -1.5619e+00, -8.1327e-01, -2.8848e-01, -1.1394e+00,\n",
       "                       1.5016e-01, -2.2739e+00, -6.3962e-01, -5.7954e-01,  1.3309e+00,\n",
       "                      -1.4609e+00, -1.8205e-01, -1.2765e+00, -7.3388e-01, -1.5737e-01,\n",
       "                       5.3461e-01, -1.5260e+00,  2.0765e-01, -1.6979e+00,  1.4827e-01,\n",
       "                      -1.9259e+00,  7.3506e-01, -4.7212e-01,  1.3810e+00, -2.1657e-01,\n",
       "                       1.0349e+00, -5.3797e-01,  2.5778e+00,  1.3490e+00, -2.5502e+00,\n",
       "                      -2.6611e+00, -2.3786e+00,  1.6245e+00, -1.1143e+00, -4.3932e-01,\n",
       "                      -3.6890e-01, -1.2221e+00,  1.1654e+00, -1.8187e+00, -7.2061e-01,\n",
       "                      -1.2529e+00,  1.6543e+00,  1.3109e+00, -1.2264e-01, -1.2078e+00,\n",
       "                      -7.7157e-01, -6.9116e-01, -2.5979e+00,  1.0091e+00,  1.3684e+00,\n",
       "                       4.6783e-01, -1.0179e+00,  3.7738e-01,  1.7462e+00, -1.3345e+00,\n",
       "                       5.5208e-01, -2.3647e+00,  2.0464e+00, -3.1052e-03, -1.9125e+00,\n",
       "                      -8.4357e-02,  1.4159e-01, -1.7759e+00,  7.0709e-01, -2.3585e+00,\n",
       "                      -1.8362e+00, -2.3588e-01,  2.0721e+00, -1.0142e+00, -1.0930e+00,\n",
       "                      -4.4622e-01,  1.3683e+00, -1.6562e+00, -1.4709e+00, -6.9848e-01,\n",
       "                      -1.5521e+00, -1.2797e+00, -2.2174e-01,  1.6689e+00, -3.9306e-01,\n",
       "                       2.0460e+00, -2.2412e+00, -4.6462e-01, -1.3554e+00,  1.7827e-01,\n",
       "                      -1.9216e+00,  1.1002e+00, -5.0336e-01, -4.2647e-01, -5.4645e-02,\n",
       "                      -6.8213e-01, -1.3325e+00, -1.4037e+00, -1.3026e+00, -8.9380e-01,\n",
       "                       1.5658e+00,  8.9405e-01, -1.1506e+00, -1.3514e+00,  1.4120e+00,\n",
       "                       1.7530e+00, -1.6135e+00,  1.3423e+00, -1.4175e+00, -1.5082e+00,\n",
       "                      -1.9973e+00,  9.4815e-01, -2.3161e+00, -2.0020e+00,  1.9741e+00,\n",
       "                      -2.6476e-02, -2.6338e+00,  2.5664e+00, -2.1864e+00, -6.4343e-02,\n",
       "                       3.0562e+00, -2.6519e+00,  2.6856e+00, -1.8503e+00,  8.3049e-01,\n",
       "                      -1.8913e+00, -1.3919e+00, -9.5597e-01, -1.0861e+00,  1.6468e+00,\n",
       "                      -4.4500e-01,  5.1833e-01, -2.6019e-01,  1.5362e-02,  2.2750e+00,\n",
       "                       2.0329e+00, -2.7609e+00,  7.3622e-01, -1.9254e+00, -1.0168e+00,\n",
       "                      -4.5717e-01,  6.4396e-01, -6.1726e-01,  2.2784e-01,  7.5096e-01,\n",
       "                       1.4760e+00,  7.5984e-01, -2.3657e+00,  1.5296e+00, -1.3705e+00,\n",
       "                      -1.1550e+00, -3.3058e+00, -1.3278e+00, -9.9978e-01,  2.4584e-01,\n",
       "                      -3.2178e-01, -3.0680e+00,  1.8837e+00, -1.0348e+00, -1.4632e-01,\n",
       "                      -2.0772e+00,  6.8505e-01,  2.4802e+00,  5.5190e-01,  1.3314e+00,\n",
       "                       9.5098e-01, -1.3469e+00, -1.9644e-01, -2.3286e+00, -2.7517e+00,\n",
       "                       1.0733e+00, -3.0281e+00,  1.9742e-01,  1.2992e+00, -8.6841e-01,\n",
       "                      -1.0932e+00, -1.4171e+00, -4.3374e-01,  2.4938e+00, -1.6531e-01,\n",
       "                      -1.0102e+00, -1.6155e-01, -1.7066e+00, -9.2946e-01, -1.3104e+00,\n",
       "                      -2.1886e+00, -7.3395e-01, -2.1078e+00,  2.7069e-01,  6.1395e-01,\n",
       "                      -2.4353e+00, -3.3925e-01,  7.7277e-01, -1.1030e+00,  3.0073e+00,\n",
       "                       5.7332e-01,  1.2471e-01, -2.6653e+00, -3.3405e-01, -1.9416e+00,\n",
       "                      -9.8251e-01, -1.4400e-01, -7.6615e-01,  1.3895e+00, -3.6381e-01,\n",
       "                      -1.0988e-01, -1.3344e+00, -1.1286e+00, -1.4051e-01,  2.0241e+00,\n",
       "                      -1.6322e+00, -1.8819e+00,  6.6007e-01, -9.1080e-01, -2.0393e+00,\n",
       "                      -2.3560e+00,  1.5605e+00,  1.5978e+00, -4.4296e-01, -2.3877e+00,\n",
       "                       1.4288e-01, -1.7127e+00, -1.9753e+00,  1.6819e+00, -7.3747e-01,\n",
       "                      -1.6036e+00, -1.5507e+00, -1.6493e+00,  1.3278e+00, -3.3603e-01,\n",
       "                       1.7694e+00,  8.8999e-01,  2.3538e-01,  2.3540e+00,  4.6995e-01,\n",
       "                       4.6189e-01, -2.4401e+00, -1.7384e+00, -3.7678e-01,  1.1035e+00,\n",
       "                      -1.0264e+00, -4.0166e-01,  2.8406e+00,  3.5485e+00, -3.3992e-02,\n",
       "                      -2.1527e+00, -8.3336e-01,  1.7279e+00, -9.2105e-01,  2.0085e+00,\n",
       "                      -2.2912e+00, -1.1395e+00,  6.5023e-01, -3.0461e+00, -2.2727e+00,\n",
       "                      -2.3254e+00, -8.3096e-01, -2.3795e+00,  4.9914e-01, -1.0351e+00,\n",
       "                       1.5567e+00, -9.5121e-01,  8.1107e-01, -1.7927e+00, -3.2083e-01,\n",
       "                       7.1301e-01, -1.4118e+00, -2.6463e+00, -4.9084e-01, -1.7937e+00,\n",
       "                       1.1131e+00, -8.8050e-01,  1.2273e+00,  2.4044e+00, -1.3395e+00,\n",
       "                       1.8348e+00, -3.0024e+00,  2.3013e+00, -1.7026e+00, -1.4522e+00,\n",
       "                      -1.4588e+00,  1.1535e+00, -1.1762e+00, -3.5553e+00, -7.4391e-01,\n",
       "                      -1.9570e+00,  4.6275e-01, -2.3829e+00, -1.1144e+00, -3.2779e-01])),\n",
       "             ('BN5.running_var',\n",
       "              tensor([4.1191, 2.2475, 2.6795, 3.5989, 3.2271, 3.0435, 6.0542, 2.5262, 2.9408,\n",
       "                      3.4045, 2.2313, 3.6147, 3.9561, 3.2701, 2.9876, 2.9259, 3.7554, 2.9237,\n",
       "                      4.9030, 2.5927, 2.5782, 3.6988, 2.9853, 1.7817, 3.4602, 3.6246, 2.3823,\n",
       "                      3.3787, 3.3037, 3.8924, 2.5285, 3.7552, 3.5940, 4.3954, 2.7252, 5.6159,\n",
       "                      4.5296, 4.5593, 3.2486, 3.8905, 2.9607, 2.3030, 2.1583, 2.8084, 2.0521,\n",
       "                      2.2097, 3.2317, 3.7551, 1.9141, 4.3341, 2.4230, 2.4481, 4.9714, 2.9657,\n",
       "                      1.9963, 2.9744, 2.5896, 2.0010, 4.0019, 4.1172, 1.9110, 2.5158, 2.0520,\n",
       "                      5.1362, 4.3471, 3.7675, 3.9770, 3.3402, 3.2679, 3.2161, 1.9006, 4.5800,\n",
       "                      3.5518, 2.7142, 2.8809, 2.4534, 2.6521, 1.7652, 3.2154, 3.3180, 4.4449,\n",
       "                      2.3004, 2.9331, 3.6594, 2.5727, 3.6198, 2.1040, 4.0267, 3.0777, 1.9928,\n",
       "                      4.5508, 2.0563, 2.8963, 3.2158, 2.9070, 4.1926, 2.9779, 3.7072, 1.9408,\n",
       "                      5.2179, 3.3344, 2.2186, 2.6529, 3.4494, 4.4227, 3.2666, 2.0716, 2.7418,\n",
       "                      3.3626, 3.7296, 2.5016, 3.0075, 1.7248, 2.5101, 4.1822, 2.5525, 4.7145,\n",
       "                      2.7074, 2.2006, 3.1486, 4.4625, 4.6598, 2.6606, 2.4731, 3.0520, 4.0841,\n",
       "                      3.1002, 4.6670, 2.1297, 6.9362, 3.5229, 2.4958, 4.1508, 3.1603, 4.8110,\n",
       "                      3.1531, 4.4813, 3.3951, 4.2837, 2.2442, 5.2753, 2.2142, 2.5424, 4.1513,\n",
       "                      3.8576, 2.3493, 2.1598, 3.6165, 2.1233, 3.1214, 2.9442, 4.2004, 3.6555,\n",
       "                      2.6938, 4.5421, 4.3619, 3.3654, 2.6258, 4.0241, 2.9341, 2.8981, 2.7108,\n",
       "                      6.1671, 2.2356, 2.7794, 3.0327, 2.1757, 5.2914, 3.5342, 3.6376, 2.1686,\n",
       "                      2.7149, 2.4827, 2.2872, 3.8268, 3.0676, 2.6775, 3.0535, 2.9306, 2.8513,\n",
       "                      2.5736, 3.8959, 2.3070, 2.6343, 3.7555, 3.6883, 4.4299, 3.9030, 3.8568,\n",
       "                      4.0897, 2.3190, 2.0684, 3.5798, 3.1835, 3.8476, 4.6091, 6.7683, 2.2968,\n",
       "                      2.9403, 3.6900, 5.0188, 4.6455, 3.1668, 3.2390, 2.2371, 5.0000, 2.9455,\n",
       "                      2.6271, 2.3601, 2.2460, 2.8479, 3.8130, 2.6017, 3.8642, 2.5426, 3.2471,\n",
       "                      3.6035, 4.1165, 3.1390, 4.8132, 3.9433, 3.4161, 4.1208, 3.6647, 3.9563,\n",
       "                      4.9316, 2.2676, 3.9000, 4.2006, 3.0432, 3.2189, 2.5088, 2.9931, 5.6126,\n",
       "                      3.3621, 4.3369, 4.0726, 3.3848, 2.7432, 2.6161, 3.1017, 4.2202, 2.1597,\n",
       "                      2.5701, 3.5187, 3.8013, 2.6781, 3.2532, 3.8483, 4.0609, 2.5036, 2.7113,\n",
       "                      2.1814, 1.8373, 3.4279, 3.4291, 3.6328, 3.7529, 2.2493, 1.9785, 4.3307,\n",
       "                      3.6592, 3.3145, 3.0104, 4.3222, 5.9996, 3.0840, 3.7332, 3.5248, 2.0885,\n",
       "                      4.4420, 2.8998, 5.3029, 3.0053, 3.1446, 4.1921, 4.4639, 4.1122, 2.6273,\n",
       "                      2.9387, 2.5586, 2.7677, 1.8482, 2.5393, 2.4136, 4.5703, 3.7180, 2.8302,\n",
       "                      3.1198, 3.4501, 3.6043, 3.5403, 2.3989, 3.4557, 2.7942, 2.5981, 3.5390,\n",
       "                      1.8278, 2.2693, 6.1960, 4.5262, 3.0693, 3.6247, 3.2903, 3.3562, 4.3439,\n",
       "                      4.1429, 3.5403, 2.9319, 4.5949, 1.9140, 4.0554, 2.3546, 2.3719, 3.3786,\n",
       "                      2.0858, 4.1266, 3.4314, 5.5366, 2.8536, 2.5484, 4.5734, 3.4146, 2.2246,\n",
       "                      3.3318, 3.1528, 3.5948, 2.3184, 4.5665, 3.7547, 2.1294, 2.6895, 2.2059,\n",
       "                      2.4838, 2.9673, 3.5820, 3.7003, 4.9192, 3.2151, 3.1914, 2.7328, 2.9600,\n",
       "                      3.8124, 2.6970, 3.4545, 1.4444, 3.3509, 3.0469, 4.4232, 3.6567, 3.0557,\n",
       "                      2.3226, 3.3241, 3.5061, 3.1176, 2.6149, 4.4418, 2.5330, 2.9122, 2.5588,\n",
       "                      2.9754, 2.7147, 2.9697, 1.9547, 2.3067, 2.8726, 2.9199, 4.2155, 2.9177,\n",
       "                      4.0585, 3.9151, 3.5323, 2.6899, 4.0177, 2.2345, 4.1141, 3.9294, 2.0168,\n",
       "                      3.7972, 2.5717, 2.3577, 3.0774, 3.6790, 2.4194, 3.1848, 3.8548, 3.0002,\n",
       "                      3.5364, 1.8405, 4.2634, 3.1262, 5.4929, 4.2800, 4.4684, 3.8691, 3.3320,\n",
       "                      3.7114, 3.1345, 2.6550, 3.2548, 3.1488, 3.6500, 3.4364, 2.8909, 2.7436,\n",
       "                      4.2582, 5.7949, 2.9472, 5.2348, 3.3165, 3.4802, 3.1317, 3.9713, 3.2574,\n",
       "                      4.2230, 4.8558, 3.2776, 3.5402, 3.0870, 2.1738, 2.7488, 2.9882, 3.0951,\n",
       "                      4.6547, 2.9041, 1.8891, 1.9171, 2.5806, 2.9087, 2.9746, 2.9405, 2.8874,\n",
       "                      3.0524, 2.8477, 3.1896, 3.2078, 3.5409, 3.7794, 2.0127, 4.9669, 4.0474,\n",
       "                      3.8785, 3.5526, 2.8430, 3.4596, 2.5832, 4.0444, 3.1604, 3.7227, 2.4611,\n",
       "                      2.3853, 3.1001, 2.6839, 2.9624, 2.9251, 3.8280, 2.4839, 3.2614, 2.5506,\n",
       "                      3.2371, 3.0821, 4.5413, 2.6382, 2.5735, 1.5878, 1.9210, 4.0161, 2.2161,\n",
       "                      2.1267, 1.9432, 3.6379, 3.7768, 2.3981, 3.5651, 3.5712, 2.3649, 3.6408,\n",
       "                      4.9473, 4.2959, 2.4143, 2.8831, 3.0554, 3.5749, 2.5094, 4.9538, 2.5654,\n",
       "                      3.6124, 1.8031, 5.4322, 3.1586, 2.5774, 3.1001, 3.5178, 2.6768, 2.9274,\n",
       "                      2.7448, 2.7979, 1.7125, 2.5569, 3.5182])),\n",
       "             ('BN5.num_batches_tracked', tensor(600)),\n",
       "             ('dec_3.weight',\n",
       "              tensor([[-0.0544, -0.0149, -0.0390,  ..., -0.0546,  0.0246,  0.0227],\n",
       "                      [ 0.0152,  0.0279, -0.0043,  ..., -0.0010, -0.0075, -0.0129],\n",
       "                      [ 0.0151,  0.0310, -0.0038,  ..., -0.0461, -0.0156,  0.0419],\n",
       "                      ...,\n",
       "                      [-0.0032,  0.0048, -0.0574,  ..., -0.0385, -0.0147, -0.0041],\n",
       "                      [ 0.0223, -0.0112,  0.0052,  ..., -0.0008,  0.0255, -0.0015],\n",
       "                      [ 0.0636,  0.0473, -0.0172,  ..., -0.0252,  0.0220, -0.0154]])),\n",
       "             ('dec_3.bias',\n",
       "              tensor([-0.0119,  0.0230, -0.0272,  0.0274, -0.0061,  0.0095,  0.0313,  0.0023,\n",
       "                      -0.0200, -0.0378, -0.0336, -0.0300,  0.0333, -0.0033,  0.0075,  0.0338,\n",
       "                      -0.0368, -0.0155,  0.0423, -0.0245,  0.0027,  0.0178, -0.0428,  0.0063,\n",
       "                       0.0053,  0.0086, -0.0159,  0.0447, -0.0392, -0.0313,  0.0164, -0.0247,\n",
       "                       0.0094, -0.0088,  0.0259, -0.0376, -0.0199,  0.0295, -0.0166, -0.0205,\n",
       "                       0.0017,  0.0097,  0.0057,  0.0075, -0.0280, -0.0167, -0.0369,  0.0323,\n",
       "                      -0.0287, -0.0107, -0.0002,  0.0126, -0.0322, -0.0445,  0.0425,  0.0087,\n",
       "                      -0.0258, -0.0164,  0.0287, -0.0377, -0.0412, -0.0036,  0.0221,  0.0360,\n",
       "                      -0.0003, -0.0027,  0.0294,  0.0013, -0.0217, -0.0109,  0.0370,  0.0127,\n",
       "                       0.0036,  0.0103,  0.0224, -0.0044, -0.0076, -0.0022,  0.0439, -0.0443,\n",
       "                      -0.0087, -0.0428,  0.0256, -0.0412, -0.0070, -0.0441, -0.0350, -0.0310,\n",
       "                      -0.0399, -0.0102, -0.0103, -0.0382,  0.0292, -0.0174, -0.0277, -0.0299,\n",
       "                       0.0422, -0.0287,  0.0290, -0.0269, -0.0230, -0.0141, -0.0143, -0.0271,\n",
       "                       0.0370,  0.0382,  0.0342, -0.0131,  0.0439,  0.0063,  0.0269, -0.0367,\n",
       "                      -0.0293,  0.0176,  0.0034, -0.0212, -0.0348, -0.0425, -0.0401, -0.0328,\n",
       "                      -0.0423,  0.0395, -0.0388,  0.0056,  0.0170,  0.0202, -0.0276,  0.0440,\n",
       "                      -0.0163,  0.0366, -0.0152, -0.0423,  0.0012, -0.0428, -0.0360, -0.0235,\n",
       "                       0.0006, -0.0276,  0.0318, -0.0365, -0.0357, -0.0047,  0.0014,  0.0395,\n",
       "                      -0.0027, -0.0209,  0.0116,  0.0006,  0.0216, -0.0303,  0.0126,  0.0340,\n",
       "                      -0.0317, -0.0239, -0.0381,  0.0365,  0.0318, -0.0197, -0.0437, -0.0410,\n",
       "                       0.0386,  0.0329,  0.0169, -0.0410,  0.0002, -0.0065,  0.0155, -0.0363,\n",
       "                       0.0368,  0.0231, -0.0059, -0.0164,  0.0369,  0.0010, -0.0202,  0.0231,\n",
       "                       0.0287, -0.0327, -0.0038,  0.0358,  0.0146, -0.0420, -0.0046,  0.0243,\n",
       "                      -0.0250,  0.0098, -0.0212, -0.0141,  0.0003,  0.0200,  0.0179, -0.0159,\n",
       "                      -0.0216,  0.0147, -0.0017, -0.0196,  0.0042, -0.0165, -0.0083,  0.0287,\n",
       "                      -0.0301,  0.0320, -0.0092, -0.0244, -0.0270,  0.0228,  0.0148,  0.0135,\n",
       "                      -0.0125, -0.0384, -0.0265,  0.0163,  0.0292, -0.0301, -0.0161, -0.0350,\n",
       "                      -0.0426, -0.0253, -0.0171, -0.0162, -0.0151, -0.0435, -0.0417,  0.0243,\n",
       "                       0.0317, -0.0400, -0.0368, -0.0299, -0.0230, -0.0237,  0.0035, -0.0403,\n",
       "                       0.0392, -0.0414,  0.0016, -0.0172,  0.0349,  0.0009, -0.0341,  0.0386,\n",
       "                       0.0203, -0.0412,  0.0215, -0.0167,  0.0230, -0.0395, -0.0104,  0.0239,\n",
       "                      -0.0344, -0.0072, -0.0405, -0.0047,  0.0235,  0.0313,  0.0408, -0.0274,\n",
       "                      -0.0260, -0.0306, -0.0133,  0.0220, -0.0092, -0.0441, -0.0350,  0.0037,\n",
       "                      -0.0293, -0.0397, -0.0167,  0.0334, -0.0427, -0.0111, -0.0094, -0.0218,\n",
       "                      -0.0044, -0.0312,  0.0227, -0.0037, -0.0048, -0.0447, -0.0126,  0.0017,\n",
       "                      -0.0261,  0.0400, -0.0179, -0.0193,  0.0262,  0.0312,  0.0180, -0.0179,\n",
       "                       0.0363, -0.0368, -0.0241, -0.0236, -0.0319, -0.0218,  0.0250,  0.0061,\n",
       "                       0.0335,  0.0136, -0.0438,  0.0418, -0.0369, -0.0257, -0.0211,  0.0133,\n",
       "                      -0.0131,  0.0199,  0.0314, -0.0408,  0.0103, -0.0362, -0.0182, -0.0065,\n",
       "                       0.0163,  0.0317,  0.0064,  0.0377, -0.0057,  0.0389,  0.0309, -0.0188,\n",
       "                       0.0322, -0.0350, -0.0212, -0.0224,  0.0061, -0.0143, -0.0260,  0.0424,\n",
       "                       0.0347, -0.0021, -0.0416, -0.0213,  0.0230,  0.0210,  0.0202, -0.0313,\n",
       "                      -0.0139,  0.0209,  0.0386, -0.0280, -0.0232,  0.0206,  0.0284, -0.0331,\n",
       "                      -0.0041,  0.0056,  0.0276,  0.0322, -0.0285, -0.0267,  0.0078,  0.0209,\n",
       "                       0.0383,  0.0142, -0.0438,  0.0171,  0.0378, -0.0351,  0.0400, -0.0039,\n",
       "                       0.0084,  0.0056,  0.0022, -0.0092, -0.0332,  0.0438, -0.0029,  0.0087,\n",
       "                      -0.0386,  0.0313, -0.0096,  0.0031, -0.0284, -0.0163, -0.0099,  0.0025,\n",
       "                       0.0324, -0.0185,  0.0206, -0.0160,  0.0208, -0.0071, -0.0031, -0.0187,\n",
       "                       0.0230, -0.0329,  0.0019, -0.0016,  0.0120,  0.0172,  0.0215, -0.0007,\n",
       "                      -0.0311, -0.0035, -0.0199,  0.0019,  0.0355, -0.0191, -0.0161, -0.0430,\n",
       "                       0.0301, -0.0060,  0.0097,  0.0275,  0.0287,  0.0427,  0.0238,  0.0226,\n",
       "                      -0.0060,  0.0292,  0.0130,  0.0202, -0.0253, -0.0220, -0.0197, -0.0156,\n",
       "                       0.0234, -0.0203,  0.0118, -0.0295, -0.0003, -0.0005, -0.0257, -0.0163,\n",
       "                      -0.0418, -0.0205,  0.0423,  0.0277, -0.0371,  0.0239,  0.0337, -0.0213,\n",
       "                       0.0154,  0.0123, -0.0145,  0.0358, -0.0342,  0.0050, -0.0344,  0.0343,\n",
       "                       0.0018, -0.0258,  0.0343, -0.0132, -0.0433,  0.0218,  0.0431, -0.0352,\n",
       "                       0.0438, -0.0188,  0.0063, -0.0106, -0.0087, -0.0329, -0.0324, -0.0253,\n",
       "                       0.0150, -0.0200, -0.0134, -0.0380,  0.0422, -0.0285, -0.0012, -0.0342,\n",
       "                      -0.0115, -0.0367,  0.0008,  0.0254,  0.0292, -0.0413,  0.0015,  0.0191,\n",
       "                       0.0389,  0.0187,  0.0358,  0.0162,  0.0339, -0.0319,  0.0072, -0.0044,\n",
       "                      -0.0428,  0.0130,  0.0157, -0.0288, -0.0158, -0.0119,  0.0159,  0.0101,\n",
       "                      -0.0165,  0.0092,  0.0010, -0.0279, -0.0103, -0.0208,  0.0359,  0.0075,\n",
       "                      -0.0407,  0.0444, -0.0021,  0.0061])),\n",
       "             ('BN6.weight',\n",
       "              tensor([1.1261, 1.1363, 1.2009, 1.1971, 1.1262, 1.1533, 1.1210, 1.1854, 1.1549,\n",
       "                      1.1190, 1.1601, 1.1599, 1.1932, 1.1937, 1.0990, 1.1869, 1.1522, 1.1973,\n",
       "                      1.1734, 1.1585, 1.1129, 1.1877, 1.2002, 1.1605, 1.2224, 1.1984, 1.2201,\n",
       "                      1.1687, 1.1710, 1.2085, 1.1378, 1.1599, 1.1024, 1.2148, 1.1698, 1.2432,\n",
       "                      1.1679, 1.1197, 1.1306, 1.1925, 1.2144, 1.1908, 1.1838, 1.1108, 1.1845,\n",
       "                      1.1171, 1.1954, 1.1362, 1.2136, 1.0756, 1.1980, 1.1780, 1.0647, 1.1506,\n",
       "                      1.1655, 1.1885, 1.1436, 1.1585, 1.1087, 1.1998, 1.1543, 1.2245, 1.1430,\n",
       "                      1.2008, 1.2070, 1.1935, 1.1362, 1.1611, 1.2066, 1.1843, 1.0782, 1.1058,\n",
       "                      1.1549, 1.2007, 1.2037, 1.1770, 1.1116, 1.1652, 1.1787, 1.1058, 1.1793,\n",
       "                      1.0837, 1.2014, 1.1771, 1.1904, 1.2186, 1.1940, 1.0680, 1.1881, 1.1535,\n",
       "                      1.2024, 1.1807, 1.1440, 1.2016, 1.1895, 1.1870, 1.0842, 1.2058, 1.2082,\n",
       "                      1.1661, 1.1943, 1.2121, 1.1571, 1.0871, 1.1425, 1.0863, 1.1681, 1.1929,\n",
       "                      1.1620, 1.1061, 1.1762, 1.2217, 1.2008, 1.0941, 1.2006, 1.1739, 1.1742,\n",
       "                      1.0821, 1.1863, 1.1939, 1.1527, 1.0817, 1.1304, 1.1829, 1.2166, 1.2009,\n",
       "                      1.1089, 1.1505, 1.2220, 1.1723, 1.1918, 1.2006, 1.2006, 1.1743, 1.1019,\n",
       "                      1.2218, 1.1111, 1.1788, 1.1882, 1.2225, 1.1816, 1.2161, 1.1847, 1.1509,\n",
       "                      1.1973, 1.1910, 1.1857, 1.1881, 1.1792, 1.1595, 1.1387, 1.1434, 1.1684,\n",
       "                      1.2204, 1.1899, 1.2063, 1.1944, 1.1203, 1.1774, 1.2055, 1.1784, 1.2043,\n",
       "                      1.2014, 1.1920, 1.1782, 1.1391, 1.1174, 1.1448, 1.1489, 1.1491, 1.1601,\n",
       "                      1.1994, 1.1889, 1.1490, 1.2075, 1.1545, 1.1543, 1.1757, 1.2074, 1.2070,\n",
       "                      1.1407, 1.1530, 1.1717, 1.1905, 1.1650, 1.0864, 1.1457, 1.2164, 1.2176,\n",
       "                      1.2112, 1.2057, 1.1689, 1.2168, 1.1850, 1.1592, 1.1631, 1.1716, 1.2361,\n",
       "                      1.1612, 1.2054, 1.0831, 1.1853, 1.1306, 1.1498, 1.1751, 1.0490, 1.2141,\n",
       "                      1.2105, 1.2177, 1.1816, 1.1078, 1.2098, 1.1901, 1.1860, 1.1051, 1.1409,\n",
       "                      1.2172, 1.0534, 1.1627, 1.1885, 1.1755, 1.1590, 1.1815, 1.1683, 1.0966,\n",
       "                      1.1832, 1.1298, 1.1006, 1.1046, 1.1326, 1.1978, 1.1868, 1.2095, 1.1729,\n",
       "                      1.1953, 1.1387, 1.1914, 1.1363, 1.1620, 1.1937, 1.1944, 1.1952, 1.0939,\n",
       "                      1.1416, 1.1814, 1.1887, 1.1803, 1.1888, 1.1351, 1.2113, 1.0852, 1.0891,\n",
       "                      1.1811, 1.1607, 1.1218, 1.2100, 1.1491, 1.0866, 1.1691, 1.2201, 1.1863,\n",
       "                      1.2178, 1.1802, 1.2123, 1.1085, 1.2134, 1.1816, 1.1724, 1.1712, 1.1919,\n",
       "                      1.1166, 1.1835, 1.1864, 1.1773, 1.1042, 1.1863, 1.1248, 1.1564, 1.2084,\n",
       "                      1.1934, 1.1948, 1.1758, 1.1619, 1.0789, 1.1833, 1.1408, 1.0720, 1.1847,\n",
       "                      1.1777, 1.1279, 1.1800, 1.1954, 1.1594, 1.2013, 1.1583, 1.1387, 1.2038,\n",
       "                      1.2081, 1.0839, 1.1784, 1.1386, 1.1843, 1.2109, 1.1755, 1.2027, 1.2023,\n",
       "                      1.1665, 1.1331, 1.1950, 1.1872, 1.1640, 1.1874, 1.1598, 1.2095, 1.1618,\n",
       "                      1.2107, 1.2087, 1.1470, 1.2135, 1.2274, 1.1250, 1.1877, 1.1987, 1.1775,\n",
       "                      1.1727, 1.1796, 1.1380, 1.1716, 1.0746, 1.1412, 1.1140, 1.1078, 1.1538,\n",
       "                      1.1686, 1.0715, 1.2044, 1.1081, 1.1732, 1.1854, 1.1802, 1.1764, 1.1501,\n",
       "                      1.1613, 1.1545, 1.2336, 1.2034, 1.1785, 1.1979, 1.1884, 1.1493, 1.1036,\n",
       "                      1.1706, 1.1726, 1.2082, 1.1958, 1.1965, 1.2380, 1.1636, 1.2124, 1.1370,\n",
       "                      1.1925, 1.2411, 1.2130, 1.0552, 1.0943, 1.2213, 1.0932, 1.1056, 1.2044,\n",
       "                      1.1590, 1.1839, 1.1775, 1.0800, 1.0733, 1.1826, 1.1974, 1.1157, 1.1759,\n",
       "                      1.2120, 1.1864, 1.2070, 1.2133, 1.1778, 1.2042, 1.2000, 1.1242, 1.2418,\n",
       "                      1.1590, 1.1624, 1.1941, 1.1326, 1.1877, 1.1594, 1.1115, 1.1602, 1.1723,\n",
       "                      1.1567, 1.2060, 1.1573, 1.1466, 1.2169, 1.1486, 1.1981, 1.2174, 1.2075,\n",
       "                      1.1793, 1.1692, 1.2128, 1.1762, 1.1870, 1.2039, 1.0924, 1.2206, 1.2215,\n",
       "                      1.1702, 1.1539, 1.1841, 1.1621, 1.1755, 1.1231, 1.1763, 1.1648, 1.0769,\n",
       "                      1.1950, 1.1496, 1.1866, 1.0920, 1.1985, 1.1282, 1.0744, 1.1945, 1.2025,\n",
       "                      1.1669, 1.2025, 1.1651, 1.2157, 1.2060, 1.1573, 1.1496, 1.2021, 1.1067,\n",
       "                      1.1575, 1.2145, 1.1513, 1.0868, 1.0720, 1.1735, 1.1711, 1.2066, 1.1867,\n",
       "                      1.1884, 1.1794, 1.1782, 1.1790, 1.1867, 1.1428, 1.1674, 1.1808, 1.2059,\n",
       "                      1.1496, 1.1128, 1.1883, 1.0798, 1.1576, 1.1181, 1.1914, 1.1987, 1.2154,\n",
       "                      1.1254, 1.0739, 1.1728, 1.1590, 1.1823, 1.1815, 1.1672, 1.1474, 1.1695,\n",
       "                      1.1940, 1.2122, 1.1534, 1.1267, 1.1520, 1.1851, 1.1639, 1.2024, 1.0793,\n",
       "                      1.1364, 1.1418, 1.2047, 1.1788, 1.2063, 1.1964, 1.2176, 1.1868, 1.2064,\n",
       "                      1.2249, 1.1200, 1.1846, 1.2025, 1.1842])),\n",
       "             ('BN6.bias',\n",
       "              tensor([ 2.1498e-02,  3.4492e-02, -3.7186e-02,  4.7686e-02,  2.0023e-02,\n",
       "                      -6.8304e-03, -9.8981e-04,  4.1065e-02,  1.0035e-03,  3.1556e-02,\n",
       "                       1.1875e-02,  2.1709e-02,  2.2610e-04,  2.0607e-02,  6.3510e-03,\n",
       "                       4.7861e-02,  5.4786e-02,  4.4960e-02,  3.1021e-02,  2.9651e-02,\n",
       "                       6.0530e-02,  5.1077e-03,  3.2283e-02,  3.8597e-02,  3.9220e-02,\n",
       "                      -5.1933e-03,  3.9415e-02,  2.8125e-02,  1.3982e-02,  3.0478e-02,\n",
       "                      -1.0966e-02,  8.9174e-03, -2.4142e-02,  1.8818e-02,  3.6034e-02,\n",
       "                       6.8066e-02,  2.7598e-02,  1.7620e-02,  3.2675e-02,  5.2588e-02,\n",
       "                       4.0933e-02,  7.7634e-02, -2.2961e-02,  7.2113e-03,  4.8266e-02,\n",
       "                       2.1616e-02,  6.1191e-02,  1.2107e-02,  3.5636e-02,  7.8264e-03,\n",
       "                       3.1165e-02,  3.3628e-02, -1.4661e-02, -1.3149e-02,  3.3406e-02,\n",
       "                       2.5571e-02,  1.7599e-02,  8.3933e-03,  3.2543e-02,  7.7277e-03,\n",
       "                       1.5473e-03,  6.0244e-02,  3.7956e-02,  6.8038e-02,  5.0497e-02,\n",
       "                       6.7078e-04,  3.0853e-02,  4.5655e-02,  4.6782e-02,  6.3443e-02,\n",
       "                      -7.9339e-03,  2.6023e-02,  3.5587e-02,  2.0250e-02,  4.3287e-02,\n",
       "                       1.4217e-02, -1.7496e-02,  6.7768e-03,  2.2606e-02, -3.6095e-02,\n",
       "                       4.9868e-02, -1.3653e-03,  2.4785e-02,  6.6444e-02,  4.1028e-02,\n",
       "                       4.8469e-02,  4.1975e-02,  3.7100e-03,  5.1278e-02,  9.7601e-03,\n",
       "                       3.5298e-02,  5.2382e-02,  2.4824e-02,  1.9481e-02,  1.7454e-02,\n",
       "                       2.8179e-02,  3.1104e-03, -1.5095e-02,  3.1032e-02,  9.5813e-03,\n",
       "                       3.1729e-02,  4.2438e-02,  1.8788e-02,  3.9503e-02,  4.0195e-03,\n",
       "                       2.8271e-02,  4.7316e-02,  1.6820e-03,  4.1249e-02, -2.2193e-02,\n",
       "                       1.1568e-02,  4.9667e-02,  2.7228e-02,  1.9313e-02,  1.6998e-02,\n",
       "                       3.2708e-02,  2.5486e-02,  3.4715e-02,  2.9379e-02,  5.8416e-02,\n",
       "                       2.3103e-02, -1.8286e-02,  3.9896e-02,  2.9487e-02,  2.8511e-02,\n",
       "                       1.7110e-02,  1.2611e-02,  1.7751e-02,  5.7094e-02, -1.3620e-02,\n",
       "                       8.4821e-03,  6.7099e-02,  4.4909e-02,  1.6967e-02, -2.7291e-02,\n",
       "                       4.4520e-02,  2.6627e-02,  3.8432e-02,  1.6890e-02,  9.1230e-03,\n",
       "                       3.4096e-02,  2.0121e-02,  4.1049e-02,  2.5765e-02,  5.6771e-02,\n",
       "                       5.1383e-02,  1.4129e-02,  6.1833e-03,  2.2415e-02,  5.4668e-02,\n",
       "                       1.9035e-02,  7.9680e-03,  1.1072e-02,  5.0142e-02,  1.9153e-02,\n",
       "                       4.8354e-02,  1.5859e-02, -8.7232e-03,  1.7190e-02,  2.5370e-02,\n",
       "                       7.7615e-03,  3.8977e-02,  5.6493e-02,  5.1543e-02,  2.5356e-02,\n",
       "                       3.1224e-02,  3.4237e-02,  4.5697e-02,  2.4613e-02,  4.0614e-02,\n",
       "                       5.0879e-02,  2.8794e-02,  5.1402e-02,  2.5178e-02,  2.6733e-02,\n",
       "                       4.8236e-02,  3.2510e-02,  4.3845e-02,  5.5521e-02,  3.2931e-02,\n",
       "                       4.5760e-02,  9.1276e-03,  3.0318e-02,  5.0114e-02,  2.3577e-02,\n",
       "                       2.3724e-02,  1.7852e-03,  1.4842e-02,  3.5681e-02,  3.0564e-02,\n",
       "                       2.3913e-02,  3.9200e-02,  4.2632e-02,  6.6916e-04,  2.7333e-02,\n",
       "                       2.2255e-02,  9.0254e-03,  7.0287e-02,  3.7371e-02,  4.0604e-02,\n",
       "                      -2.5695e-02,  4.8617e-02, -1.7344e-02,  2.5494e-02,  5.4498e-02,\n",
       "                       4.7822e-03, -9.9636e-03,  5.3657e-02,  3.9493e-02,  4.3786e-02,\n",
       "                       1.9709e-02,  3.2658e-02,  5.3309e-02,  1.9677e-02,  1.1007e-03,\n",
       "                       3.5170e-02,  3.2507e-02, -3.4449e-03,  2.8106e-02,  6.5590e-02,\n",
       "                       3.4009e-02, -5.3935e-03,  3.2339e-02,  3.8414e-02, -1.7867e-03,\n",
       "                       2.9594e-02,  9.5393e-03,  2.4571e-02,  5.2036e-02, -4.8831e-03,\n",
       "                       2.9555e-02,  1.0194e-02,  2.8089e-02,  3.0778e-02,  8.6182e-03,\n",
       "                       1.0119e-03,  4.7589e-02,  1.6264e-02,  1.6352e-02,  4.5196e-02,\n",
       "                       8.4168e-02, -3.7851e-03, -1.2976e-02,  7.2444e-03,  2.8049e-02,\n",
       "                       9.6932e-03,  5.7701e-02,  2.0068e-02,  3.7356e-02,  3.1914e-02,\n",
       "                      -1.2711e-03,  1.2886e-02,  4.9901e-02, -1.3328e-03,  6.4969e-03,\n",
       "                       3.7305e-02,  4.2999e-02,  1.7922e-03,  5.3758e-02,  3.2320e-02,\n",
       "                       9.5797e-03,  5.9657e-03,  4.4523e-02, -4.2926e-03,  4.1319e-02,\n",
       "                       7.5523e-02,  2.4618e-02, -1.1162e-02,  6.0312e-03,  1.0349e-02,\n",
       "                       7.7204e-03,  2.8660e-02,  2.0899e-02,  2.5647e-02,  3.0036e-02,\n",
       "                       6.3423e-02, -1.4352e-02,  2.6715e-02, -1.0484e-02,  3.2319e-02,\n",
       "                       2.8525e-02,  2.9304e-02,  2.5906e-02,  2.5043e-02,  1.3422e-02,\n",
       "                       2.8753e-02,  1.7694e-02,  3.7595e-02, -5.1409e-03, -9.9895e-03,\n",
       "                       9.7199e-03,  2.6161e-02,  1.6097e-02,  3.0616e-02, -1.3003e-02,\n",
       "                       5.8487e-03,  3.6416e-03,  4.4357e-02,  2.6637e-02,  1.2527e-02,\n",
       "                      -3.4878e-03,  1.6423e-02,  3.8934e-02,  4.8140e-02,  3.6908e-02,\n",
       "                       2.9333e-02,  1.1579e-02,  3.5732e-02,  3.0364e-02,  8.0856e-03,\n",
       "                      -3.5626e-03,  6.6544e-02,  2.9382e-02,  5.0346e-02,  2.6776e-02,\n",
       "                       3.6849e-02,  2.8332e-02,  3.8342e-02,  4.2511e-02,  2.8775e-02,\n",
       "                       2.6541e-02,  4.3285e-02,  2.2123e-02,  5.8552e-02,  6.4221e-02,\n",
       "                       4.7335e-02, -5.3694e-03, -3.5181e-02, -4.3137e-03, -4.2574e-03,\n",
       "                       9.3804e-03, -1.1301e-02,  9.0998e-03,  2.3190e-02,  3.6814e-02,\n",
       "                       4.1323e-02, -2.1849e-02,  6.4098e-02,  1.0504e-02, -4.9423e-03,\n",
       "                       2.7991e-02,  3.4152e-03,  5.4476e-03,  2.9621e-02,  6.7924e-02,\n",
       "                       4.8405e-02,  3.3940e-02,  2.1575e-02,  3.7896e-02,  5.0535e-02,\n",
       "                       3.7218e-02,  3.7534e-02,  2.4905e-02,  3.2363e-02,  2.3345e-02,\n",
       "                       3.1587e-02,  5.7294e-02,  5.5834e-02,  3.6731e-02,  2.0732e-02,\n",
       "                      -1.1654e-02,  3.3540e-02,  6.0175e-02,  7.3463e-03,  7.3766e-04,\n",
       "                       5.1029e-02,  8.6633e-03,  2.0754e-03,  2.8940e-02,  3.3320e-02,\n",
       "                       4.4858e-02,  6.1060e-02,  2.4705e-03, -1.7750e-03,  2.4854e-02,\n",
       "                       4.0509e-02,  4.1789e-02,  3.2359e-02,  4.5281e-02,  4.4112e-02,\n",
       "                       4.5729e-02,  1.9999e-02,  1.2616e-02,  5.5902e-02,  3.4207e-02,\n",
       "                       9.6234e-03,  2.3908e-02,  3.6309e-02,  5.6239e-02,  2.1070e-02,\n",
       "                       1.7757e-02,  4.5554e-02,  4.2060e-02,  1.1693e-02,  3.0509e-03,\n",
       "                       4.3966e-02,  3.9172e-02,  3.4787e-02,  6.1120e-03,  2.1768e-02,\n",
       "                       4.9629e-02,  3.4264e-02,  1.3397e-02,  3.8009e-04,  4.2688e-02,\n",
       "                       3.3333e-03,  4.9431e-02,  1.8443e-02,  4.4969e-03, -5.0730e-03,\n",
       "                       4.4719e-02,  3.5732e-02,  3.1902e-02,  5.4736e-02,  5.1393e-02,\n",
       "                       2.8093e-02,  4.8067e-02,  4.0736e-02,  3.9853e-02,  1.8166e-02,\n",
       "                       5.1761e-02,  2.9286e-02,  3.2985e-03,  2.6488e-02, -3.7939e-03,\n",
       "                       3.2200e-02,  1.2804e-02,  1.4495e-02,  2.4679e-02, -1.8690e-03,\n",
       "                       6.1159e-02,  3.3625e-02,  5.3525e-03,  7.5152e-02,  4.0953e-02,\n",
       "                       2.7557e-02,  6.3404e-02,  2.2629e-02,  4.8290e-02,  9.9287e-05,\n",
       "                       3.4535e-02,  2.9598e-02,  3.5048e-02,  3.1286e-02,  2.3271e-02,\n",
       "                      -4.1440e-03,  2.0389e-02, -6.5882e-03,  1.9119e-02,  7.3615e-02,\n",
       "                       3.0996e-02,  4.0169e-02,  3.1966e-02,  1.2729e-02,  1.2774e-02,\n",
       "                      -1.4688e-02,  8.9386e-03, -6.8943e-03,  1.7511e-03,  4.1322e-02,\n",
       "                       4.0377e-02,  4.1088e-02, -9.1835e-03,  9.8500e-03,  8.4397e-03,\n",
       "                       1.2372e-02,  2.9122e-02,  3.6938e-02, -2.2686e-02, -9.3310e-04,\n",
       "                       3.8303e-02,  3.4585e-02,  4.0597e-02,  2.3937e-02, -8.6354e-03,\n",
       "                       1.4991e-02,  1.2924e-02,  3.5687e-02,  6.1598e-02, -2.0430e-03,\n",
       "                       1.5014e-02,  5.1376e-02,  2.9320e-02,  3.5489e-03,  1.1733e-02,\n",
       "                       2.1099e-02,  1.5453e-02,  1.7241e-02,  4.0798e-02,  4.8758e-02,\n",
       "                       4.8190e-02,  6.6914e-02,  5.5379e-02,  2.8363e-02,  8.3145e-02,\n",
       "                       1.9113e-02,  8.4467e-03,  6.0915e-03, -3.3784e-03, -1.1319e-02])),\n",
       "             ('BN6.running_mean',\n",
       "              tensor([ 0.3955, -0.2124, -0.0363, -0.2433, -0.5074, -0.1436, -0.2513, -0.6148,\n",
       "                       0.2781,  0.0977, -0.2481,  0.0764, -0.4417, -0.4493, -0.3077,  0.2303,\n",
       "                      -0.0410, -0.3619,  0.1106, -0.2096, -0.5106,  0.0699,  0.0343, -0.4876,\n",
       "                      -0.1460, -0.2567, -0.1397,  0.0276, -0.0431, -0.1077,  0.2739, -0.1831,\n",
       "                       0.0294, -0.4278,  0.0429, -0.3185, -0.0682, -0.0607, -0.1170, -0.4976,\n",
       "                      -0.3323,  0.0055,  0.1297, -0.0286, -0.2776, -0.1986, -0.3566, -0.5523,\n",
       "                      -0.3663, -0.2063, -0.5501, -0.1705, -0.0335, -0.0424,  0.4587, -0.0793,\n",
       "                      -0.1648, -0.3603, -0.1030, -0.3264,  0.0052, -0.3710, -0.4196, -0.0389,\n",
       "                      -0.2514, -0.4276, -0.1223,  0.0182,  0.0376,  0.2371, -0.0276,  0.1229,\n",
       "                      -0.4258,  0.1806, -0.1699, -0.3768,  0.1649, -0.1293,  0.5634,  0.0029,\n",
       "                       0.1129, -0.1868,  0.2822, -0.3671,  0.0683, -0.2376, -0.0863,  0.1806,\n",
       "                      -0.0560,  0.1080, -0.3005, -0.1390,  0.4069, -0.1784,  0.2814,  0.2703,\n",
       "                      -0.4117, -0.2785, -0.0910,  0.2623, -0.3030, -0.1414, -0.0435, -0.1231,\n",
       "                      -0.0350, -0.2067, -0.4138,  0.0096,  0.0489, -0.1388, -0.0321, -0.2473,\n",
       "                      -0.3022, -0.1401, -0.3702, -0.1536, -0.3314,  0.0620,  0.0770, -0.1589,\n",
       "                      -0.2807,  0.3510,  0.1419, -0.2484, -0.3941, -0.1576, -0.1347, -0.0451,\n",
       "                       0.0096, -0.2361,  0.0845, -0.1122, -0.2426, -0.1234, -0.0624,  0.1248,\n",
       "                       0.2408, -0.4390,  0.1352, -0.3517,  0.1768, -0.3240, -0.2258, -0.1144,\n",
       "                      -0.3800, -0.2748, -0.2808,  0.2227, -0.1037, -0.3944,  0.1578,  0.3119,\n",
       "                      -0.2355, -0.3717, -0.5803, -0.2746, -0.0925, -0.0393, -0.5913, -0.4207,\n",
       "                       0.1402, -0.1821,  0.0326, -0.7484,  0.2376,  0.1280, -0.2705,  0.1210,\n",
       "                      -0.2845, -0.2135,  0.1354, -0.2010,  0.0609, -0.0114, -0.3672, -0.4510,\n",
       "                       0.0901, -0.3160,  0.2423, -0.2559, -0.3056, -0.4918, -0.2245, -0.3194,\n",
       "                      -0.2537,  0.1699, -0.5919, -0.0405, -0.6068, -0.2940, -0.3170,  0.1127,\n",
       "                      -0.1386,  0.1755, -0.0250,  0.4755,  0.0318, -0.0816, -0.0110, -0.5398,\n",
       "                       0.0347, -0.0947,  0.1399, -0.3450, -0.2967,  0.2307, -0.4730, -0.0644,\n",
       "                      -0.4020, -0.0971, -0.1406, -0.1208, -0.1115, -0.2876,  0.0220,  0.1042,\n",
       "                      -0.4741, -0.1383, -0.1865, -0.1791, -0.5303, -0.0822, -0.2400, -0.3493,\n",
       "                       0.1037, -0.5975, -0.3138,  0.0633, -0.2278, -0.0230, -0.3051, -0.0199,\n",
       "                      -0.4422,  0.0121, -0.3634, -0.0271, -0.3066, -0.0898, -0.6294, -0.2865,\n",
       "                       0.2028, -0.1344,  0.1706, -0.1188, -0.3917, -0.1337, -0.1342, -0.5667,\n",
       "                      -0.1593, -0.1545, -0.0347, -0.1459,  0.0150,  0.1459, -0.0292, -0.3597,\n",
       "                       0.4080, -0.2494, -0.4317, -0.2105, -0.5330, -0.5907, -0.1260, -0.3224,\n",
       "                      -0.1587, -0.2175,  0.2205, -0.0139, -0.2110, -0.1898,  0.2518, -0.2912,\n",
       "                      -0.1022, -0.1232, -0.3344, -0.3225, -0.2100,  0.1173, -0.0602, -0.1043,\n",
       "                       0.0287, -0.3227,  0.0188,  0.1177, -0.2071, -0.1552, -0.1862, -0.4654,\n",
       "                       0.4410, -0.1282, -0.1692,  0.1764, -0.0081, -0.1268,  0.3432,  0.7929,\n",
       "                      -0.3496, -0.1919, -0.2077, -0.0440,  0.0200, -0.2991, -0.5055, -0.1854,\n",
       "                      -0.7176, -0.3276,  0.2033, -0.6874, -0.4794,  0.1810, -0.0986,  0.2123,\n",
       "                      -0.0543, -0.2296, -0.0892, -0.4562, -0.7094,  0.3779, -0.5837, -0.2689,\n",
       "                      -0.1863, -0.0575,  0.5007, -0.3161, -0.0378, -0.3322,  0.5332, -0.0213,\n",
       "                       0.2107,  0.1498,  0.0781,  0.0287,  0.0412, -0.1199,  0.0571,  0.2358,\n",
       "                       0.2397, -0.3381, -0.0770, -0.0315, -0.1340, -0.0022, -0.2589,  0.3256,\n",
       "                      -0.1378, -0.2502,  0.2082, -0.3975, -0.3425, -0.0265,  0.2737,  0.1342,\n",
       "                      -0.0821, -0.3269, -0.3530, -0.0679, -0.0918,  0.3192, -0.1148,  0.0782,\n",
       "                      -0.0188,  0.4898,  0.1017,  0.3949, -0.0238, -0.2474, -0.4102, -0.0218,\n",
       "                       0.2475, -0.2642, -0.0139, -0.1695,  0.4628,  0.0373,  0.0384, -0.0272,\n",
       "                       0.2064,  0.2817, -0.0199, -0.0934,  0.4634,  0.0568, -0.1969,  0.0161,\n",
       "                      -0.1667, -0.0595, -0.3375, -0.1487, -0.1163, -0.3890, -0.1156,  0.1550,\n",
       "                       0.2096,  0.1515,  0.1490,  0.3216, -0.1663,  0.2716, -0.3064, -0.1257,\n",
       "                      -0.1428, -0.1352, -0.6601, -0.0772, -0.4226, -0.2112, -0.0061,  0.1109,\n",
       "                      -0.0804,  0.1936,  0.0755,  0.0504, -0.5767, -0.6381, -0.2318,  0.0677,\n",
       "                      -0.2667, -0.0083,  0.0666, -0.0710, -0.5112, -0.0144, -0.2382, -0.2865,\n",
       "                      -0.2357, -0.5921, -0.2443,  0.1828,  0.0032,  0.3467, -0.4340, -0.1053,\n",
       "                       0.1526,  0.0313, -0.1081,  0.0368, -0.0436, -0.1173,  0.0341, -0.2397,\n",
       "                      -0.0173, -0.4229, -0.4672, -0.2148, -0.1551, -0.1105,  0.2761,  0.0679,\n",
       "                      -0.3812, -0.4753, -0.0904,  0.1667,  0.4796, -0.1531,  0.1340, -0.3399,\n",
       "                      -0.0780, -0.0547,  0.0064, -0.5221, -0.2807,  0.0481, -0.0069,  0.0606,\n",
       "                       0.0783, -0.1272,  0.1604, -0.3703, -0.2066,  0.5175,  0.3427,  0.1255,\n",
       "                      -0.0928,  0.0467, -0.0316,  0.1106, -0.0928, -0.2513,  0.1078,  0.4311,\n",
       "                      -0.3329,  0.3844,  0.0719,  0.0440, -0.2575,  0.2838,  0.0241,  0.0111,\n",
       "                      -0.1715, -0.1790, -0.3079, -0.3387, -0.2943, -0.0571, -0.2370,  0.0104,\n",
       "                      -0.2682, -0.4948,  0.2271, -0.2952])),\n",
       "             ('BN6.running_var',\n",
       "              tensor([0.0849, 0.0559, 0.0650, 0.0642, 0.0563, 0.0699, 0.0817, 0.0715, 0.0737,\n",
       "                      0.0797, 0.0547, 0.0612, 0.0575, 0.0847, 0.0704, 0.0655, 0.0671, 0.0801,\n",
       "                      0.0598, 0.0681, 0.0757, 0.0631, 0.0762, 0.0551, 0.0861, 0.0547, 0.0546,\n",
       "                      0.0607, 0.0689, 0.0617, 0.0690, 0.0663, 0.0530, 0.0618, 0.0616, 0.0742,\n",
       "                      0.0762, 0.0528, 0.0624, 0.0652, 0.0552, 0.0527, 0.0731, 0.0755, 0.0700,\n",
       "                      0.0861, 0.0638, 0.0696, 0.0713, 0.0806, 0.0474, 0.0607, 0.0661, 0.0685,\n",
       "                      0.0806, 0.0784, 0.0531, 0.0729, 0.0546, 0.0675, 0.0562, 0.0776, 0.0595,\n",
       "                      0.0776, 0.0588, 0.0635, 0.0812, 0.0762, 0.0682, 0.0779, 0.0450, 0.1305,\n",
       "                      0.0839, 0.0705, 0.0643, 0.0560, 0.0717, 0.0616, 0.0724, 0.0647, 0.0537,\n",
       "                      0.0688, 0.0781, 0.0617, 0.0935, 0.0731, 0.0776, 0.0884, 0.0694, 0.0664,\n",
       "                      0.0528, 0.0678, 0.0787, 0.0780, 0.0833, 0.0798, 0.0673, 0.0681, 0.0565,\n",
       "                      0.0577, 0.0703, 0.0719, 0.0981, 0.0709, 0.0918, 0.0694, 0.0702, 0.0689,\n",
       "                      0.0763, 0.0703, 0.0806, 0.0734, 0.0589, 0.0613, 0.0810, 0.0609, 0.0583,\n",
       "                      0.0584, 0.0760, 0.0704, 0.0742, 0.0648, 0.0689, 0.0586, 0.0654, 0.0584,\n",
       "                      0.0494, 0.0530, 0.0614, 0.0504, 0.0603, 0.0977, 0.0834, 0.0695, 0.0707,\n",
       "                      0.0916, 0.0769, 0.0951, 0.0732, 0.0638, 0.0769, 0.0724, 0.0793, 0.0557,\n",
       "                      0.0719, 0.0615, 0.0473, 0.0742, 0.0590, 0.0524, 0.0555, 0.0819, 0.0773,\n",
       "                      0.1142, 0.0647, 0.0684, 0.0708, 0.0614, 0.0531, 0.0761, 0.0639, 0.0526,\n",
       "                      0.0560, 0.0554, 0.0708, 0.0723, 0.0687, 0.0558, 0.0785, 0.0631, 0.0822,\n",
       "                      0.0483, 0.0764, 0.0645, 0.0573, 0.0697, 0.0599, 0.0611, 0.0706, 0.0634,\n",
       "                      0.0669, 0.0612, 0.0593, 0.0759, 0.0527, 0.0539, 0.0562, 0.0860, 0.0578,\n",
       "                      0.0579, 0.0595, 0.0697, 0.0669, 0.0928, 0.0778, 0.0825, 0.0952, 0.0652,\n",
       "                      0.0782, 0.0705, 0.0570, 0.0597, 0.0764, 0.0619, 0.0593, 0.0889, 0.0533,\n",
       "                      0.0909, 0.0871, 0.0524, 0.0638, 0.0597, 0.0616, 0.0597, 0.0460, 0.0616,\n",
       "                      0.0666, 0.1051, 0.0793, 0.0460, 0.0682, 0.0819, 0.0829, 0.0695, 0.0662,\n",
       "                      0.0612, 0.0546, 0.0631, 0.0618, 0.0708, 0.0601, 0.0608, 0.1009, 0.0613,\n",
       "                      0.0591, 0.0744, 0.0630, 0.0675, 0.0656, 0.0509, 0.0766, 0.0585, 0.0840,\n",
       "                      0.0699, 0.0850, 0.0593, 0.0635, 0.0649, 0.0523, 0.0609, 0.0811, 0.0520,\n",
       "                      0.0583, 0.0850, 0.0541, 0.0705, 0.0791, 0.0704, 0.0675, 0.0666, 0.0525,\n",
       "                      0.0578, 0.0785, 0.0796, 0.0509, 0.0722, 0.0801, 0.0977, 0.0664, 0.0710,\n",
       "                      0.0800, 0.0518, 0.0472, 0.0731, 0.0712, 0.0621, 0.0659, 0.0563, 0.0879,\n",
       "                      0.0689, 0.0630, 0.0923, 0.0434, 0.0694, 0.0549, 0.1008, 0.1002, 0.0636,\n",
       "                      0.0888, 0.0624, 0.0700, 0.1033, 0.0522, 0.0790, 0.0677, 0.0817, 0.0735,\n",
       "                      0.0589, 0.1030, 0.0702, 0.0968, 0.0519, 0.0698, 0.0547, 0.0681, 0.0674,\n",
       "                      0.0533, 0.0750, 0.0706, 0.0782, 0.0759, 0.0576, 0.0528, 0.0841, 0.0765,\n",
       "                      0.0624, 0.0749, 0.0756, 0.0556, 0.0657, 0.0643, 0.0602, 0.0666, 0.0719,\n",
       "                      0.0686, 0.0615, 0.0685, 0.0607, 0.0552, 0.0678, 0.0611, 0.1078, 0.0532,\n",
       "                      0.0613, 0.0802, 0.0643, 0.0731, 0.0621, 0.0558, 0.0672, 0.0547, 0.0534,\n",
       "                      0.0480, 0.0845, 0.0616, 0.0637, 0.0833, 0.0507, 0.0575, 0.0653, 0.0500,\n",
       "                      0.0645, 0.0457, 0.0654, 0.0653, 0.0740, 0.0728, 0.0533, 0.0561, 0.0790,\n",
       "                      0.0716, 0.0728, 0.0543, 0.0615, 0.0786, 0.0592, 0.0679, 0.0862, 0.0562,\n",
       "                      0.0496, 0.0570, 0.0673, 0.0661, 0.0819, 0.0705, 0.0623, 0.0729, 0.0748,\n",
       "                      0.0633, 0.0585, 0.1145, 0.0734, 0.0428, 0.0538, 0.0676, 0.0511, 0.0760,\n",
       "                      0.0466, 0.1022, 0.0621, 0.0635, 0.0522, 0.0846, 0.0773, 0.0731, 0.0847,\n",
       "                      0.0664, 0.0786, 0.0646, 0.0583, 0.0680, 0.0599, 0.0540, 0.0560, 0.0665,\n",
       "                      0.0599, 0.0435, 0.0762, 0.0625, 0.0466, 0.0710, 0.0516, 0.0662, 0.1039,\n",
       "                      0.0642, 0.0597, 0.0778, 0.0474, 0.0486, 0.0481, 0.0714, 0.0692, 0.0639,\n",
       "                      0.0670, 0.0557, 0.0529, 0.0569, 0.0840, 0.0664, 0.0568, 0.0707, 0.0645,\n",
       "                      0.0618, 0.0611, 0.0695, 0.0764, 0.0600, 0.0474, 0.0628, 0.0716, 0.0657,\n",
       "                      0.0994, 0.0734, 0.0795, 0.0735, 0.0608, 0.0943, 0.0675, 0.0814, 0.0533,\n",
       "                      0.0652, 0.0689, 0.0863, 0.0640, 0.0693, 0.0661, 0.0684, 0.0577, 0.0714,\n",
       "                      0.0526, 0.0850, 0.0578, 0.0824, 0.0655, 0.0794, 0.0658, 0.0624, 0.0588,\n",
       "                      0.0593, 0.0758, 0.0780, 0.0667, 0.0642, 0.0531, 0.0753, 0.0765, 0.0862,\n",
       "                      0.0539, 0.0826, 0.0665, 0.0688, 0.0597, 0.0706, 0.0783, 0.0528, 0.0749,\n",
       "                      0.0709, 0.0786, 0.0708, 0.0714, 0.0753, 0.0627, 0.0709, 0.0768, 0.0742,\n",
       "                      0.0731, 0.0741, 0.0676, 0.0632, 0.0605])),\n",
       "             ('BN6.num_batches_tracked', tensor(600)),\n",
       "             ('x_bar_layer.weight',\n",
       "              tensor([[ 0.0617,  0.0412,  0.0360,  ...,  0.0697,  0.0026, -0.0233],\n",
       "                      [-0.0038,  0.0494,  0.0188,  ...,  0.0003,  0.0279,  0.0296],\n",
       "                      [-0.0652,  0.0211, -0.0231,  ...,  0.0171, -0.0702,  0.0446],\n",
       "                      ...,\n",
       "                      [-0.0483, -0.0525, -0.0591,  ..., -0.0289, -0.1091,  0.0342],\n",
       "                      [ 0.0256, -0.0194,  0.0454,  ..., -0.0007, -0.0309, -0.0306],\n",
       "                      [-0.0826, -0.0803, -0.0063,  ...,  0.0100,  0.0352,  0.0452]])),\n",
       "             ('x_bar_layer.bias',\n",
       "              tensor([-0.0427,  0.0175, -0.0279,  ...,  0.0361, -0.0472, -0.0017]))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('../02-Data/Controls/controls_pre_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72906b29",
   "metadata": {},
   "source": [
    "4. Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b01f6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import h5py\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "from scipy.linalg import norm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "def load_graph(dataset, k):\n",
    "    if k:\n",
    "        path = '{}'.format(dataset, k)\n",
    "\n",
    "    else:\n",
    "        path = '{}'.format(dataset)\n",
    "\n",
    "    data = np.loadtxt('{}'.format(dataset))\n",
    "    n, _ = data.shape\n",
    "\n",
    "    idx = np.array([i for i in range(n)], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(path, dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(n, n), dtype=np.float32)\n",
    "\n",
    "    # Construct a symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = normalize(adj)\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    return adj\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    # Row-normalize sparse matrix\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    # Convert a scipy sparse matrix to a torch sparse tensor.\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "class load_data(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x = np.loadtxt('{}'.format(dataset), dtype=float)\n",
    "        self.y = np.loadtxt('{}'.format(dataset), dtype=int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.x[idx])), \\\n",
    "               torch.from_numpy(np.array(self.y[idx])), \\\n",
    "               torch.from_numpy(np.array(idx))\n",
    "\n",
    "\n",
    "# def cluster_acc(y_true, y_pred):\n",
    "#     y_true = y_true.astype(np.int64)\n",
    "#     assert y_pred.size == y_true.size\n",
    "#     D = max(y_pred.max(), y_true.max()) + 1\n",
    "#     w = np.zeros((D, D), dtype=np.int64)\n",
    "#     for i in range(y_pred.size):\n",
    "#         w[y_pred[i], y_true[i]] += 1\n",
    "# #     from scipy.optimize import linear_sum_assignment\n",
    "#     from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "#     ind = linear_assignment(w.max() - w)\n",
    "#     return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "\n",
    "        self.degenerated_to_sgd = degenerated_to_sgd\n",
    "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
    "            for param in params:\n",
    "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
    "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n",
    "                        buffer=[[None, None, None] for _ in range(10)])\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = group['buffer'][int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt(\n",
    "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                    N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    elif self.degenerated_to_sgd:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = -1\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "                elif step_size > 0:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "\n",
    "        self.degenerated_to_sgd = degenerated_to_sgd\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    step_size = group['lr'] * math.sqrt(\n",
    "                        (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "                elif self.degenerated_to_sgd:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup=0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup=warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "\n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class RAdam_4step(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, update_all=False,\n",
    "                 additional_four=False):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.update_all = update_all  # whether update the first 4 steps\n",
    "        self.additional_four = additional_four  # whether use additional 4 steps for SGD\n",
    "        self.buffer = [[None, None] for ind in range(10)]\n",
    "        super(RAdam_4step, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam_4step, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam_4step does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state[\n",
    "                        'step'] = -4 if self.additional_four else 0  # since this exp requires exactly 4 step, it is hard coded\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                if state['step'] > 0:\n",
    "\n",
    "                    state_step = state['step'] + 4 if self.additional_four else state[\n",
    "                        'step']  # since this exp requires exactly 4 step, it is hard coded\n",
    "\n",
    "                    buffered = self.buffer[int(state_step % 10)]\n",
    "                    if state_step == buffered[0]:\n",
    "                        step_size = buffered[1]\n",
    "                    else:\n",
    "                        buffered[0] = state_step\n",
    "                        beta2_t = beta2 ** state['step']\n",
    "\n",
    "                        if state['step'] > 4:  # since this exp requires exactly 4 step, it is hard coded\n",
    "                            N_sma_max = 2 / (1 - beta2) - 1\n",
    "                            N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                            step_size = group['lr'] * math.sqrt(\n",
    "                                (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (\n",
    "                                                    1 - beta1 ** state_step)\n",
    "                        elif self.update_all:\n",
    "                            step_size = group['lr'] / (1 - beta1 ** state_step)\n",
    "                        else:\n",
    "                            step_size = 0\n",
    "                        buffered[1] = step_size\n",
    "\n",
    "                    if state['step'] > 4:  # since this exp requires exactly 4 step, it is hard coded\n",
    "                        if group['weight_decay'] != 0:\n",
    "                            p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                        denom = (exp_avg_sq.sqrt() / math.sqrt(1 - beta2 ** state_step)).add_(group['eps'])\n",
    "                        p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                        p.data.copy_(p_data_fp32)\n",
    "                    elif self.update_all:\n",
    "                        if group['weight_decay'] != 0:\n",
    "                            p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                        denom = (exp_avg_sq.sqrt() / math.sqrt(1 - beta2 ** state_step))\n",
    "                        p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                        p.data.copy_(p_data_fp32)\n",
    "                else:\n",
    "                    state_step = state['step'] + 4 if self.additional_four else state[\n",
    "                        'step']  # since this exp requires exactly 4 step, it is hard coded\n",
    "\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * 0.1, p_data_fp32)\n",
    "\n",
    "                    step_size = 0.1 / (1 - beta1 ** state_step)\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c08f9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle, os, numbers\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "# TODO: Fix this\n",
    "class AnnSequence:\n",
    "    def __init__(self, matrix, batch_size, sf=None):\n",
    "        self.matrix = matrix\n",
    "        if sf is None:\n",
    "            self.size_factors = np.ones((self.matrix.shape[0], 1),\n",
    "                                        dtype=np.float32)\n",
    "        else:\n",
    "            self.size_factors = sf\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.matrix[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_sf = self.size_factors[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        # return an (X, Y) pair\n",
    "        return {'count': batch, 'size_factors': batch_sf}, batch\n",
    "\n",
    "\n",
    "def read_dataset(adata, transpose=False, test_split=False, copy=False):\n",
    "    if isinstance(adata, sc.AnnData):\n",
    "        if copy:\n",
    "            adata = adata.copy()\n",
    "    elif isinstance(adata, str):\n",
    "        adata = sc.read(adata)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    norm_error = 'Make sure that the dataset (adata.X) contains unnormalized count data.'\n",
    "    assert 'n_count' not in adata.obs, norm_error\n",
    "\n",
    "    if adata.X.size < 50e6:  # check if adata.X is integer only if array is small\n",
    "        if sp.sparse.issparse(adata.X):\n",
    "            assert (adata.X.astype(float) != adata.X).nnz == 0, norm_error\n",
    "        else:\n",
    "            assert np.all(adata.X.astype(float) == adata.X), norm_error\n",
    "\n",
    "    if transpose: adata = adata.transpose()\n",
    "\n",
    "    if test_split:\n",
    "        train_idx, test_idx = train_test_split(np.arange(adata.n_obs), test_size=0.1, random_state=42)\n",
    "        spl = pd.Series(['train'] * adata.n_obs)\n",
    "        spl.iloc[test_idx] = 'test'\n",
    "        adata.obs['DCA_split'] = spl.values\n",
    "    else:\n",
    "        adata.obs['DCA_split'] = 'train'\n",
    "\n",
    "    adata.obs['DCA_split'] = adata.obs['DCA_split'].astype('category')\n",
    "    print('### Autoencoder: Successfully preprocessed {} genes and {} cells.'.format(adata.n_vars, adata.n_obs))\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "def normalize(adata, filter_min_counts=True, size_factors=True, normalize_input=True, logtrans_input=True):\n",
    "    if filter_min_counts:\n",
    "        sc.pp.filter_genes(adata, min_counts=1)\n",
    "        sc.pp.filter_cells(adata, min_counts=1)\n",
    "\n",
    "    if size_factors or normalize_input or logtrans_input:\n",
    "        adata.raw = adata.copy()\n",
    "    else:\n",
    "        adata.raw = adata\n",
    "\n",
    "    if size_factors:\n",
    "        sc.pp.normalize_per_cell(adata)\n",
    "        adata.obs['size_factors'] = adata.obs.n_counts / np.median(adata.obs.n_counts)\n",
    "    else:\n",
    "        adata.obs['size_factors'] = 1.0\n",
    "\n",
    "    if logtrans_input:\n",
    "        sc.pp.log1p(adata)\n",
    "\n",
    "    if normalize_input:\n",
    "        sc.pp.scale(adata)\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "def read_genelist(filename):\n",
    "    genelist = list(set(open(filename, 'rt').read().strip().split('\\n')))\n",
    "    assert len(genelist) > 0, 'No genes detected in genelist file'\n",
    "    print('### Autoencoder: Subset of {} genes will be denoised.'.format(len(genelist)))\n",
    "\n",
    "    return genelist\n",
    "\n",
    "\n",
    "def write_text_matrix(matrix, filename, rownames=None, colnames=None, transpose=False):\n",
    "    if transpose:\n",
    "        matrix = matrix.T\n",
    "        rownames, colnames = colnames, rownames\n",
    "\n",
    "    pd.DataFrame(matrix, index=rownames, columns=colnames).to_csv(filename,\n",
    "                                                                  sep='\\t',\n",
    "                                                                  index=(rownames is not None),\n",
    "                                                                  header=(colnames is not None),\n",
    "                                                                  float_format='%.6f')\n",
    "\n",
    "def read_pickle(inputfile):\n",
    "    return pickle.load(open(inputfile, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "06f2977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ZINBLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ZINBLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x, mean, disp, pi, scale_factor=1.0,    ridge_lambda=0.0):\n",
    "        eps = 1e-10\n",
    "        scale_factor = scale_factor[:, None]\n",
    "        mean = mean * scale_factor\n",
    "        \n",
    "        t1 = torch.lgamma(disp+eps) + torch.lgamma(x+1.0) - torch.lgamma(x+disp+eps)\n",
    "        t2 = (disp+x) * torch.log(1.0 + (mean/(disp+eps))) + (x * (torch.log(disp+eps) - torch.log(mean+eps)))\n",
    "        nb_final = t1 + t2\n",
    "\n",
    "        nb_case = nb_final - torch.log(1.0-pi+eps)\n",
    "        zero_nb = torch.pow(disp/(disp+mean+eps), disp)\n",
    "        zero_case = -torch.log(pi + ((1.0-pi)*zero_nb)+eps)\n",
    "        result = torch.where(torch.le(x, 1e-8), zero_case, nb_case)\n",
    "        \n",
    "        if ridge_lambda > 0:\n",
    "            ridge = ridge_lambda*torch.square(pi)\n",
    "            result += ridge\n",
    "        result = torch.mean(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, sigma=0):\n",
    "        super(GaussianNoise, self).__init__()\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x = x + self.sigma * torch.randn_like(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MeanAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanAct, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(torch.exp(x), min=1e-5, max=1e6)\n",
    "\n",
    "class DispAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DispAct, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(F.softplus(x), min=1e-4, max=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5d0d3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class GNNLayer(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GNNLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        # When passing through the network layer, the input and output variances are the same\n",
    "        # including forward propagation and backward propagation\n",
    "\n",
    "    def forward(self, features, adj, active=True):\n",
    "        support = torch.mm(features, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if active:\n",
    "            output = F.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "605bfa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import h5py\n",
    "import scanpy as sc\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from time import time as get_time\n",
    "import sys\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n",
    "                 n_input, n_z1, n_z2, n_z3):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.enc_1 = Linear(n_input, n_enc_1)\n",
    "        self.BN1 = nn.BatchNorm1d(n_enc_1)\n",
    "        self.enc_2 = Linear(n_enc_1, n_enc_2)\n",
    "        self.BN2 = nn.BatchNorm1d(n_enc_2)\n",
    "        self.enc_3 = Linear(n_enc_2, n_enc_3)\n",
    "        self.BN3 = nn.BatchNorm1d(n_enc_3)\n",
    "\n",
    "        self.z1_layer = Linear(n_enc_3, n_z1)\n",
    "        self.BN4 = nn.BatchNorm1d(n_z1)\n",
    "        self.z2_layer = Linear(n_z1, n_z2)\n",
    "        self.BN5 = nn.BatchNorm1d(n_z2)\n",
    "        self.z3_layer = Linear(n_z2, n_z3)\n",
    "        self.BN6 = nn.BatchNorm1d(n_z3)\n",
    "\n",
    "        self.dec_1 = Linear(n_z3, n_dec_1)\n",
    "        self.BN7 = nn.BatchNorm1d(n_dec_1)\n",
    "        self.dec_2 = Linear(n_dec_1, n_dec_2)\n",
    "        self.BN8 = nn.BatchNorm1d(n_dec_2)\n",
    "        self.dec_3 = Linear(n_dec_2, n_dec_3)\n",
    "        self.BN9 = nn.BatchNorm1d(n_dec_3)\n",
    "        self.x_bar_layer = Linear(n_dec_3, n_input)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_h1 = F.relu(self.BN1(self.enc_1(x)))\n",
    "        enc_h2 = F.relu(self.BN2(self.enc_2(enc_h1)))\n",
    "        enc_h3 = F.relu(self.BN3(self.enc_3(enc_h2)))\n",
    "\n",
    "        z1 = self.BN4(self.z1_layer(enc_h3))\n",
    "        z2 = self.BN5(self.z2_layer(z1))\n",
    "        z3 = self.BN6(self.z3_layer(z2))\n",
    "\n",
    "        dec_h1 = F.relu(self.BN7(self.dec_1(z3)))\n",
    "        dec_h2 = F.relu(self.BN8(self.dec_2(dec_h1)))\n",
    "        dec_h3 = F.relu(self.BN9(self.dec_3(dec_h2)))\n",
    "        x_bar = self.x_bar_layer(dec_h3)\n",
    "\n",
    "        return x_bar, enc_h1, enc_h2, enc_h3, z3, z2, z1, dec_h3\n",
    "\n",
    "\n",
    "class SDCN(nn.Module):\n",
    "    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n",
    "                 n_input, n_z1, n_z2, n_z3, n_clusters, v=1):\n",
    "        super(SDCN, self).__init__()\n",
    "        self.ae = AE(\n",
    "            n_enc_1=n_enc_1,\n",
    "            n_enc_2=n_enc_2,\n",
    "            n_enc_3=n_enc_3,\n",
    "\n",
    "            n_dec_1=n_dec_1,\n",
    "            n_dec_2=n_dec_2,\n",
    "            n_dec_3=n_dec_3,\n",
    "\n",
    "            n_input=n_input,\n",
    "            n_z1=n_z1,\n",
    "            n_z2=n_z2,\n",
    "            n_z3=n_z3,\n",
    "        )\n",
    "        \n",
    "#         self.ae.load_state_dict(torch.load(args.pretrain_path, map_location='cpu'))\n",
    "        torch.load(args.pretrain_path, map_location='cpu')\n",
    "        self.gnn_1 = GNNLayer(n_input, n_enc_1)\n",
    "        self.gnn_2 = GNNLayer(n_enc_1, n_enc_2)\n",
    "        self.gnn_3 = GNNLayer(n_enc_2, n_enc_3)\n",
    "        self.gnn_4 = GNNLayer(n_enc_3, n_z1)\n",
    "        self.gnn_5 = GNNLayer(n_z1, n_z2)\n",
    "        self.gnn_6 = GNNLayer(n_z2, n_z3)\n",
    "        self.gnn_7 = GNNLayer(n_z3, n_clusters)\n",
    "\n",
    "        # cluster layer\n",
    "        self.cluster_layer = Parameter(torch.Tensor(n_clusters, n_z3))\n",
    "        torch.nn.init.xavier_normal_(self.cluster_layer.data)\n",
    "        self._dec_mean = nn.Sequential(nn.Linear(n_dec_3, n_input), MeanAct())\n",
    "        self._dec_disp = nn.Sequential(nn.Linear(n_dec_3, n_input), DispAct())\n",
    "        self._dec_pi = nn.Sequential(nn.Linear(n_dec_3, n_input), nn.Sigmoid())\n",
    "        # degree\n",
    "        self.v = v\n",
    "        self.zinb_loss = ZINBLoss().cuda()\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # DNN Module\n",
    "        x_bar, tra1, tra2, tra3, z3, z2, z1, dec_h3 = self.ae(x)\n",
    "\n",
    "        sigma = 0.5\n",
    "        # GCN Module\n",
    "        h = self.gnn_1(x, adj)\n",
    "        h = self.gnn_2((1 - sigma) * h + sigma * tra1, adj)\n",
    "        h = self.gnn_3((1 - sigma) * h + sigma * tra2, adj)\n",
    "        h = self.gnn_4((1 - sigma) * h + sigma * tra3, adj)\n",
    "        h = self.gnn_5((1 - sigma) * h + sigma * z1, adj)\n",
    "        h = self.gnn_6((1 - sigma) * h + sigma * z2, adj)\n",
    "        h = self.gnn_7((1 - sigma) * h + sigma * z3, adj, active=False)\n",
    "\n",
    "        predict = F.softmax(h, dim=1)\n",
    "\n",
    "        _mean = self._dec_mean(dec_h3)\n",
    "        _disp = self._dec_disp(dec_h3)\n",
    "        _pi = self._dec_pi(dec_h3)\n",
    "        zinb_loss = self.zinb_loss\n",
    "\n",
    "        q = 1.0 / (1.0 + torch.sum(torch.pow(z3.unsqueeze(1) - self.cluster_layer, 2), 2) / self.v)\n",
    "        q = q.pow((self.v + 1.0) / 2.0)\n",
    "        q = (q.t() / torch.sum(q, 1)).t()\n",
    "\n",
    "        return x_bar, q, predict, z3, _mean, _disp, _pi, zinb_loss\n",
    "\n",
    "\n",
    "\n",
    "def target_distribution(q):\n",
    "\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.t() / weight.sum(1)).t()\n",
    "\n",
    "\n",
    "def train_sdcn(dataset, X_raw, sf):\n",
    "    global p\n",
    "    model = SDCN(\n",
    "                 n_enc_1=args.n_enc_1,\n",
    "                 n_enc_2=args.n_enc_2,\n",
    "                 n_enc_3=args.n_enc_3,\n",
    "                 n_dec_1=args.n_dec_1,\n",
    "                 n_dec_2=args.n_dec_2,\n",
    "                 n_dec_3=args.n_dec_3,\n",
    "                 n_input=args.n_input,\n",
    "                 n_z1=args.n_z1,\n",
    "                 n_z2=args.n_z2,\n",
    "                 n_z3=args.n_z3,\n",
    "                 n_clusters=args.n_clusters,\n",
    "                 v=1).to(device)\n",
    "    print(model)\n",
    "    # optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "    optimizer = RAdam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    adj = load_graph(args.graph, args.k)\n",
    "    print(args.k)\n",
    "    adj = adj\n",
    "\n",
    "\n",
    "    data = torch.Tensor(dataset.x).to(device)\n",
    "    y = dataset.y\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, _, _, z, _, _, _ = model.ae(data)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=args.n_clusters, n_init=args.n_init)\n",
    "    y_pred = kmeans.fit_predict(z.data.cpu().numpy())\n",
    "    y_pred_last = y_pred\n",
    "    model.cluster_layer.data = torch.tensor(kmeans.cluster_centers_).to(device)\n",
    "#     eva(y, y_pred, 0)\n",
    "    eva(sf, y_pred, 0)\n",
    "\n",
    "    for epoch in range(Para[2]):\n",
    "        if epoch % 1 == 0:\n",
    "            _, tmp_q, pred, _, _, _, _, _ = model(data, adj)\n",
    "            tmp_q = tmp_q.data\n",
    "            p = target_distribution(tmp_q)\n",
    "\n",
    "            res1 = tmp_q.cpu().numpy().argmax(1)  # Q\n",
    "            res2 = pred.data.cpu().numpy().argmax(1)  # Z\n",
    "            res3 = p.data.cpu().numpy().argmax(1)  # P\n",
    "            # eva(y, res1, str(epoch) + 'Q')\n",
    "            # eva(y, res2, str(epoch) + 'Z')\n",
    "            # eva(y, res3, str(epoch) + 'P')\n",
    "            eva(y, res2, epoch)\n",
    "\n",
    "\n",
    "        x_bar, q, pred, z, meanbatch, dispbatch, pibatch, zinb_loss = model(data, adj)\n",
    "\n",
    "        binary_crossentropy_loss = F.binary_cross_entropy(q, p)\n",
    "        ce_loss = F.kl_div(pred.log(), p, reduction='batchmean')\n",
    "        re_loss = F.mse_loss(x_bar, data)\n",
    "        X_raw = torch.tensor(X_raw).cuda()\n",
    "        sf = torch.tensor(sf).cuda()\n",
    "\n",
    "        zinb_loss = zinb_loss(X_raw, meanbatch, dispbatch, pibatch, sf)\n",
    "        loss = Balance_para[0] * binary_crossentropy_loss + Balance_para[1] * ce_loss + Balance_para[2] * re_loss +Balance_para[3] * zinb_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    time_start = get_time()\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='train',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ebc71766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/c6_fdc5s1gj9kwgvmg4_4gmc0000gn/T/ipykernel_39775/1353073617.py:73: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  self.y = np.loadtxt('{}'.format(dataset), dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDCN(\n",
      "  (ae): AE(\n",
      "    (enc_1): Linear(in_features=21209, out_features=1000, bias=True)\n",
      "    (BN1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc_2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (BN2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc_3): Linear(in_features=1000, out_features=4000, bias=True)\n",
      "    (BN3): BatchNorm1d(4000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (z1_layer): Linear(in_features=4000, out_features=2000, bias=True)\n",
      "    (BN4): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (z2_layer): Linear(in_features=2000, out_features=500, bias=True)\n",
      "    (BN5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (z3_layer): Linear(in_features=500, out_features=10, bias=True)\n",
      "    (BN6): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec_1): Linear(in_features=10, out_features=4000, bias=True)\n",
      "    (BN7): BatchNorm1d(4000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec_2): Linear(in_features=4000, out_features=1000, bias=True)\n",
      "    (BN8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec_3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (BN9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (x_bar_layer): Linear(in_features=1000, out_features=21209, bias=True)\n",
      "  )\n",
      "  (gnn_1): GNNLayer()\n",
      "  (gnn_2): GNNLayer()\n",
      "  (gnn_3): GNNLayer()\n",
      "  (gnn_4): GNNLayer()\n",
      "  (gnn_5): GNNLayer()\n",
      "  (gnn_6): GNNLayer()\n",
      "  (gnn_7): GNNLayer()\n",
      "  (_dec_mean): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=21209, bias=True)\n",
      "    (1): MeanAct()\n",
      "  )\n",
      "  (_dec_disp): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=21209, bias=True)\n",
      "    (1): DispAct()\n",
      "  )\n",
      "  (_dec_pi): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=21209, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (zinb_loss): ZINBLoss()\n",
      ")\n",
      "None\n",
      "0 :acc 0.1839 , nmi 0.0243 , ari 0.0090 , f1 0.1012\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "addmm: Argument #3 (dense): Expected dim 0 size 51050, got 5105",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [361]\u001b[0m, in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m dataset1 \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mTensor(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mTensor(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mTensor(sf))\n\u001b[1;32m     64\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset1, batch_size\u001b[38;5;241m=\u001b[39mPara[\u001b[38;5;241m0\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mtrain_sdcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m time \u001b[38;5;241m=\u001b[39m get_time() \u001b[38;5;241m-\u001b[39m time_start\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Time：\u001b[39m\u001b[38;5;124m\"\u001b[39m, time)\n",
      "Input \u001b[0;32mIn [231]\u001b[0m, in \u001b[0;36mtrain_sdcn\u001b[0;34m(dataset, X_raw, sf)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Para[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 180\u001b[0m         _, tmp_q, pred, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m         tmp_q \u001b[38;5;241m=\u001b[39m tmp_q\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    182\u001b[0m         p \u001b[38;5;241m=\u001b[39m target_distribution(tmp_q)\n",
      "File \u001b[0;32m~/mambaforge/envs/AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [231]\u001b[0m, in \u001b[0;36mSDCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m    110\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# GCN Module\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn_2((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m sigma) \u001b[38;5;241m*\u001b[39m h \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m tra1, adj)\n\u001b[1;32m    114\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn_3((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m sigma) \u001b[38;5;241m*\u001b[39m h \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m tra2, adj)\n",
      "File \u001b[0;32m~/mambaforge/envs/AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36mGNNLayer.forward\u001b[0;34m(self, features, adj, active)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, adj, active\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     support \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m active:\n\u001b[1;32m     16\u001b[0m         output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(output)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: addmm: Argument #3 (dense): Expected dim 0 size 51050, got 5105"
     ]
    }
   ],
   "source": [
    "### Cases:\n",
    "# File = [gene_expresion data file, Graph file, Pre-training file, h5 file]\n",
    "File = ['../02-Data/Cases/cases_X.txt', \"../02-Data/Cases/cases_graph.txt\", \n",
    "        '../02-Data/Cases/cases_pre_train.pkl', \"../02-Data/Cases/cases.h5ad\"]\n",
    "# model_para = [n_enc_1(n_dec_3), n_enc_2(n_dec_2), n_enc_3(n_dec_1), n_cluster, n_init]\n",
    "model_para = [1000, 1000, 4000]\n",
    "# Para = [batch_size, lr, epoch]\n",
    "Para = [2048, 1e-4, 80]\n",
    "# Cluster_para = [n_cluster, n_z1, n_z2, n_z3, n_input, n_init]\n",
    "Cluster_para = [7, 2000, 500, 10, 21209, 20]\n",
    "# Balance_para = [binary_crossentropy_loss, ce_loss, re_loss, zinb_loss, balance]\n",
    "Balance_para = [0.1, 0.01, 1, 0.1, 0.5]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--name', type=str, default=File[0])\n",
    "parser.add_argument('--graph', type=str, default=File[1])\n",
    "parser.add_argument('--pretrain_path', type=str, default=File[2])\n",
    "parser.add_argument('--n_enc_1', default=model_para[0], type=int)\n",
    "parser.add_argument('--n_enc_2', default=model_para[1], type=int)\n",
    "parser.add_argument('--n_enc_3', default=model_para[2], type=int)\n",
    "parser.add_argument('--n_dec_1', default=model_para[2], type=int)\n",
    "parser.add_argument('--n_dec_2', default=model_para[1], type=int)\n",
    "parser.add_argument('--n_dec_3', default=model_para[0], type=int)\n",
    "\n",
    "parser.add_argument('--k', type=int, default=None)\n",
    "parser.add_argument('--lr', type=float, default=Para[1])\n",
    "\n",
    "parser.add_argument('--n_clusters', default=Cluster_para[0], type=int)\n",
    "parser.add_argument('--n_z1', default=Cluster_para[1], type=int)\n",
    "parser.add_argument('--n_z2', default=Cluster_para[2], type=int)\n",
    "parser.add_argument('--n_z3', default=Cluster_para[3], type=int)\n",
    "parser.add_argument('--n_input', type=int, default=Cluster_para[4])\n",
    "parser.add_argument('--n_init', type=int, default=Cluster_para[5])\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = torch.cuda.is_available()\n",
    "print(\"use cuda: {}\".format(args.cuda))\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "args.pretrain_path = File[2]\n",
    "dataset = load_data(args.name)\n",
    "\n",
    "# data_mat = h5py.File(File[3], \"r+\")\n",
    "# x = np.array(data_mat['X'])\n",
    "# y = np.array(data_mat['obs']['seurat_clusters'])\n",
    "# adata = sc.AnnData(x)\n",
    "adata = sc.read_h5ad(\"../02-Data/Cases/cases.h5ad\")\n",
    "adata.obs['Group'] = y\n",
    "# adata = read_dataset(adata,\n",
    "#                      transpose=False,\n",
    "#                      test_split=False,\n",
    "#                      copy=True)\n",
    "\n",
    "# adata = normalize(adata,\n",
    "#                   size_factors=True,\n",
    "#                   normalize_input=True,\n",
    "#                   logtrans_input=True)\n",
    "X = adata.X\n",
    "X_raw = adata.raw\n",
    "sf = adata.obs['Group']\n",
    "dataset1 = TensorDataset(torch.Tensor(X.shape[0]), torch.Tensor(X.shape[0]), torch.Tensor(sf))\n",
    "dataloader = DataLoader(dataset1, batch_size=Para[0], shuffle=True)\n",
    "train_sdcn(dataset, X_raw, sf)\n",
    "\n",
    "time = get_time() - time_start\n",
    "print(\"Running Time：\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d36f6c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/c6_fdc5s1gj9kwgvmg4_4gmc0000gn/T/ipykernel_39775/1353073617.py:73: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  self.y = np.loadtxt('{}'.format(dataset), dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDCN(\n",
      "  (ae): AE(\n",
      "    (enc_1): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (BN1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc_2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (BN2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc_3): Linear(in_features=1000, out_features=4000, bias=True)\n",
      "    (BN3): BatchNorm1d(4000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (z1_layer): Linear(in_features=4000, out_features=2000, bias=True)\n",
      "    (BN4): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (z2_layer): Linear(in_features=2000, out_features=500, bias=True)\n",
      "    (BN5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (z3_layer): Linear(in_features=500, out_features=10, bias=True)\n",
      "    (BN6): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec_1): Linear(in_features=10, out_features=4000, bias=True)\n",
      "    (BN7): BatchNorm1d(4000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec_2): Linear(in_features=4000, out_features=1000, bias=True)\n",
      "    (BN8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec_3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (BN9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (x_bar_layer): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  )\n",
      "  (gnn_1): GNNLayer()\n",
      "  (gnn_2): GNNLayer()\n",
      "  (gnn_3): GNNLayer()\n",
      "  (gnn_4): GNNLayer()\n",
      "  (gnn_5): GNNLayer()\n",
      "  (gnn_6): GNNLayer()\n",
      "  (gnn_7): GNNLayer()\n",
      "  (_dec_mean): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "    (1): MeanAct()\n",
      "  )\n",
      "  (_dec_disp): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "    (1): DispAct()\n",
      "  )\n",
      "  (_dec_pi): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (zinb_loss): ZINBLoss()\n",
      ")\n",
      "None\n",
      "0 :acc 0.2416 , nmi 0.0927 , ari 0.0624 , f1 0.1551\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "addmm: Argument #3 (dense): Expected dim 0 size 15483, got 1548",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [333]\u001b[0m, in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m dataset1 \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mTensor(X), torch\u001b[38;5;241m.\u001b[39mTensor(X), torch\u001b[38;5;241m.\u001b[39mTensor(sf))\n\u001b[1;32m     63\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset1, batch_size\u001b[38;5;241m=\u001b[39mPara[\u001b[38;5;241m0\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtrain_sdcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m time \u001b[38;5;241m=\u001b[39m get_time() \u001b[38;5;241m-\u001b[39m time_start\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Time：\u001b[39m\u001b[38;5;124m\"\u001b[39m, time)\n",
      "Input \u001b[0;32mIn [231]\u001b[0m, in \u001b[0;36mtrain_sdcn\u001b[0;34m(dataset, X_raw, sf)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Para[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 180\u001b[0m         _, tmp_q, pred, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m         tmp_q \u001b[38;5;241m=\u001b[39m tmp_q\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    182\u001b[0m         p \u001b[38;5;241m=\u001b[39m target_distribution(tmp_q)\n",
      "File \u001b[0;32m~/mambaforge/envs/AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [231]\u001b[0m, in \u001b[0;36mSDCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m    110\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# GCN Module\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn_2((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m sigma) \u001b[38;5;241m*\u001b[39m h \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m tra1, adj)\n\u001b[1;32m    114\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn_3((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m sigma) \u001b[38;5;241m*\u001b[39m h \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m tra2, adj)\n",
      "File \u001b[0;32m~/mambaforge/envs/AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36mGNNLayer.forward\u001b[0;34m(self, features, adj, active)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, adj, active\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     support \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m active:\n\u001b[1;32m     16\u001b[0m         output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(output)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: addmm: Argument #3 (dense): Expected dim 0 size 15483, got 1548"
     ]
    }
   ],
   "source": [
    "### Controls:\n",
    "# File = [gene_expresion data file, Graph file, Pre-training file, h5 file]\n",
    "File = ['../02-Data/Controls/controls_X.txt', \"../02-Data/Controls/controls_graph.txt\", \n",
    "        '../02-Data/Controls/controls_pre_train.pkl', \"../02-Data/Controls/controls.h5ad\"]\n",
    "# model_para = [n_enc_1(n_dec_3), n_enc_2(n_dec_2), n_enc_3(n_dec_1), n_cluster, n_init]\n",
    "model_para = [1000, 1000, 4000]\n",
    "# Para = [batch_size, lr, epoch]\n",
    "Para = [2048, 1e-4, 80]\n",
    "# Cluster_para = [n_cluster, n_z1, n_z2, n_z3, n_input, n_init]\n",
    "Cluster_para = [7, 2000, 500, 10, 2000, 20]\n",
    "# Balance_para = [binary_crossentropy_loss, ce_loss, re_loss, zinb_loss, balance]\n",
    "Balance_para = [0.1, 0.01, 1, 0.1, 0.5]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--name', type=str, default=File[0])\n",
    "parser.add_argument('--graph', type=str, default=File[1])\n",
    "parser.add_argument('--pretrain_path', type=str, default=File[2])\n",
    "parser.add_argument('--n_enc_1', default=model_para[0], type=int)\n",
    "parser.add_argument('--n_enc_2', default=model_para[1], type=int)\n",
    "parser.add_argument('--n_enc_3', default=model_para[2], type=int)\n",
    "parser.add_argument('--n_dec_1', default=model_para[2], type=int)\n",
    "parser.add_argument('--n_dec_2', default=model_para[1], type=int)\n",
    "parser.add_argument('--n_dec_3', default=model_para[0], type=int)\n",
    "\n",
    "parser.add_argument('--k', type=int, default=None)\n",
    "parser.add_argument('--lr', type=float, default=Para[1])\n",
    "\n",
    "parser.add_argument('--n_clusters', default=Cluster_para[0], type=int)\n",
    "parser.add_argument('--n_z1', default=Cluster_para[1], type=int)\n",
    "parser.add_argument('--n_z2', default=Cluster_para[2], type=int)\n",
    "parser.add_argument('--n_z3', default=Cluster_para[3], type=int)\n",
    "parser.add_argument('--n_input', type=int, default=Cluster_para[4])\n",
    "parser.add_argument('--n_init', type=int, default=Cluster_para[5])\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = torch.cuda.is_available()\n",
    "print(\"use cuda: {}\".format(args.cuda))\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "args.pretrain_path = File[2]\n",
    "dataset = load_data(args.name)\n",
    "\n",
    "data_mat = h5py.File(File[3], \"r+\")\n",
    "x = np.array(data_mat['X'])\n",
    "y = np.array(data_mat['obs']['seurat_clusters'])\n",
    "adata = sc.AnnData(x)\n",
    "adata.obs['Group'] = y\n",
    "# adata = read_dataset(adata,\n",
    "#                      transpose=False,\n",
    "#                      test_split=False,\n",
    "#                      copy=True)\n",
    "\n",
    "# adata = normalize(adata,\n",
    "#                   size_factors=True,\n",
    "#                   normalize_input=True,\n",
    "#                   logtrans_input=True)\n",
    "X = adata.X\n",
    "# X_raw = adata.raw\n",
    "sf = adata.obs['Group']\n",
    "dataset1 = TensorDataset(torch.Tensor(X), torch.Tensor(X), torch.Tensor(sf))\n",
    "dataloader = DataLoader(dataset1, batch_size=Para[0], shuffle=True)\n",
    "train_sdcn(dataset, X_raw, sf)\n",
    "\n",
    "time = get_time() - time_start\n",
    "print(\"Running Time：\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b497afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 09:25:36.158031: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408ece5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
